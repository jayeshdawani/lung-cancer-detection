diff --git a/include/caffe/filler.hpp b/include/caffe/filler.hpp
index dad9ad4..13a4027 100644
--- a/include/caffe/filler.hpp
+++ b/include/caffe/filler.hpp
@@ -189,8 +189,8 @@ class MSRAFiller : public Filler<Dtype> {
       : Filler<Dtype>(param) {}
   virtual void Fill(Blob<Dtype>* blob) {
     CHECK(blob->count());
-    int fan_in = blob->count() / blob->num();
-    int fan_out = blob->count() / blob->channels();
+    int fan_in = blob->count() / blob->shape(0);
+    int fan_out = blob->count() / blob->shape(1);
     Dtype n = fan_in;  // default to fan_in
     if (this->filler_param_.variance_norm() ==
         FillerParameter_VarianceNorm_AVERAGE) {
diff --git a/include/caffe/layer.hpp b/include/caffe/layer.hpp
index 10f353f..ec06b1a 100644
--- a/include/caffe/layer.hpp
+++ b/include/caffe/layer.hpp
@@ -19,6 +19,10 @@ namespace boost { class mutex; }
 
 namespace caffe {
 
+// forward declaration of Net (apply_deformation_layer needs a back
+// reference pointer to it)
+template<typename Dtype> class Net;
+
 /**
  * @brief An interface for the units of computation which can be composed into a
  *        Net.
@@ -38,7 +42,7 @@ class Layer {
    * layer.
    */
   explicit Layer(const LayerParameter& param)
-    : layer_param_(param), is_shared_(false) {
+    : layer_param_(param), parent_net_(0), is_shared_(false) {
       // Set phase and copy blobs (if there are any).
       phase_ = param.phase();
       if (layer_param_.blobs_size() > 0) {
@@ -316,6 +320,22 @@ class Layer {
     param_propagate_down_[param_id] = value;
   }
 
+ /**
+   * @brief get the pointer to the parent network that holds this layer
+   * (needed by apply_deformation_layer)
+   */
+  inline const Net<Dtype>* parent_net() const {
+    CHECK_NOTNULL( parent_net_);
+    return parent_net_;
+  }
+
+  /**
+   * @brief set the pointer to the parent network that holds this layer
+   * (needed by apply_deformation_layer)
+   */
+  inline void set_parent_net( const Net<Dtype>* net) {
+    parent_net_ = net;
+  }
 
  protected:
   /** The protobuf that stores the layer parameters */
@@ -331,6 +351,10 @@ class Layer {
    *  the objective function. */
   vector<Dtype> loss_;
 
+  /** Backreference to the parent network that holds this layer
+   * (needed by apply_deformation_layer) */
+  const Net<Dtype>* parent_net_;
+
   /** @brief Using the CPU device, compute the layer output. */
   virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) = 0;
diff --git a/include/caffe/layers/apply_deformation_layer.hpp b/include/caffe/layers/apply_deformation_layer.hpp
new file mode 100644
index 0000000..43835e2
--- /dev/null
+++ b/include/caffe/layers/apply_deformation_layer.hpp
@@ -0,0 +1,50 @@
+#ifndef APPLY_DEFORMATION_LAYER_HPP_
+#define APPLY_DEFORMATION_LAYER_HPP_
+
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "caffe/blob.hpp"
+#include "caffe/common.hpp"
+#include "caffe/layer.hpp"
+#include "caffe/net.hpp"
+
+namespace caffe {
+
+/**
+ * @brief Deforms an image with a given deformation field
+ *
+ * TODO(dox): thorough documentation for Forward, Backward, and proto params.
+ */
+template <typename Dtype>
+class ApplyDeformationLayer : public Layer<Dtype> {
+ public:
+  explicit ApplyDeformationLayer(const LayerParameter& param)
+      : Layer<Dtype>(param) {}
+  virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual void Reshape(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+
+  virtual inline const char* type() const { return "ApplyDeformation"; }
+
+  /// @brief image, and deformation field
+  virtual inline int ExactNumBottomBlobs() const { return 2; }
+  /// @brief deformed image
+  virtual inline int ExactNumTopBlobs() const { return 1; }
+
+ protected:
+  virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual void Backward_cpu(const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
+
+  int n_spatial_axes_;
+  int n_deform_comps_;
+};
+
+
+}  // namespace caffe
+
+#endif  // APPLY_DEFORMATION_LAYER_HPP_
diff --git a/include/caffe/layers/concat_layer.hpp b/include/caffe/layers/concat_layer.hpp
index a157024..a6a049f 100644
--- a/include/caffe/layers/concat_layer.hpp
+++ b/include/caffe/layers/concat_layer.hpp
@@ -80,6 +80,7 @@ class ConcatLayer : public Layer<Dtype> {
   int num_concats_;
   int concat_input_size_;
   int concat_axis_;
+  bool needs_cropping_;
 };
 
 }  // namespace caffe
diff --git a/include/caffe/layers/create_deformation_layer.hpp b/include/caffe/layers/create_deformation_layer.hpp
new file mode 100644
index 0000000..300913c
--- /dev/null
+++ b/include/caffe/layers/create_deformation_layer.hpp
@@ -0,0 +1,80 @@
+#ifndef CREATE_DEFORMATION_LAYER_HPP_
+#define CREATE_DEFORMATION_LAYER_HPP_
+
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "caffe/blob.hpp"
+#include "caffe/common.hpp"
+#include "caffe/layer.hpp"
+#include "caffe/net.hpp"
+
+namespace caffe {
+
+/**
+ * @brief Provides random deformation fields to the Net. Use this as
+ * input with ApplyDeformationLayer for data augmentation
+ *
+ * TODO(dox): thorough documentation for Forward and proto params.
+ */
+template <typename Dtype>
+class CreateDeformationLayer : public Layer<Dtype> {
+ public:
+  explicit CreateDeformationLayer(const LayerParameter& param)
+      : Layer<Dtype>(param) {}
+  virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  // Data layers have no bottoms, so reshaping is trivial.
+  virtual void Reshape(const vector<Blob<Dtype>*>& bottom,
+                       const vector<Blob<Dtype>*>& top);
+
+  virtual inline const char* type() const { return "CreateDeformation"; }
+  virtual inline int MinBottomBlobs() const { return 0; }
+  virtual inline int MaxBottomBlobs() const { return 1; }
+  virtual inline int MinTopBlobs() const { return 1; }
+
+ protected:
+  virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual void Backward_cpu(const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {}
+  virtual void Backward_gpu(const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {}
+
+  Dtype* create_bspline_kernels(int nb);
+
+  void cubic_bspline_interpolation(
+    const Dtype* in, int in_n_lines, int in_n_elem,
+    int in_stride_lines, int in_stride_elem,
+    Dtype* out, int out_n_elem, int out_stride_lines, int out_stride_elem,
+    const Dtype* b0123, int nb) ;
+
+  int batch_size_;
+  int n_spatial_axes_;
+  int n_deform_comps_;
+
+  bool do_elastic_trafo_;
+  int grid_spacing_x_;
+  int grid_spacing_y_;
+  int grid_spacing_z_;
+  Dtype* bkernel_x_;
+  Dtype* bkernel_y_;
+  Dtype* bkernel_z_;
+  Dtype* rdispl_;
+  vector<int> rdispl_shape_;
+  Dtype* tmp1_;
+  vector<int> tmp1_shape_;
+  Dtype* tmp2_;
+  vector<int> tmp2_shape_;
+  float voxel_relsize_z_;
+  vector<float> rot_from_;
+  vector<float> rot_to_;
+  vector<float> offset_from_;
+  vector<float> offset_to_;
+  vector<int> mirror_flag_;
+};
+
+}  // namespace caffe
+
+#endif  // CREATE_DEFORMATION_LAYER_HPP_
diff --git a/include/caffe/layers/cudnn_deconv_layer.hpp b/include/caffe/layers/cudnn_deconv_layer.hpp
new file mode 100644
index 0000000..9d19ecd
--- /dev/null
+++ b/include/caffe/layers/cudnn_deconv_layer.hpp
@@ -0,0 +1,72 @@
+#ifndef CAFFE_CUDNN_DECONV_LAYER_HPP_
+#define CAFFE_CUDNN_DECONV_LAYER_HPP_
+
+#include <vector>
+
+#include "caffe/blob.hpp"
+#include "caffe/layer.hpp"
+#include "caffe/proto/caffe.pb.h"
+
+#include "caffe/layers/deconv_layer.hpp"
+
+namespace caffe {
+
+#ifdef USE_CUDNN
+/*
+ * @brief cuDNN implementation of DeconvolutionLayer.
+ *        Fallback to DeconvolutionLayer for CPU mode.
+ *
+ * cuDNN accelerates convolution through forward kernels for filtering and bias
+ * plus backward kernels for the gradient w.r.t. the filters, biases, and
+ * inputs. Caffe + cuDNN further speeds up the computation through forward
+ * parallelism across groups and backward parallelism across gradients.
+ *
+ * The CUDNN engine does not have memory overhead for matrix buffers. For many
+ * input and filter regimes the CUDNN engine is faster than the CAFFE engine,
+ * but for fully-convolutional models and large inputs the CAFFE engine can be
+ * faster as long as it fits in memory.
+*/
+template <typename Dtype>
+class CuDNNDeconvolutionLayer : public DeconvolutionLayer<Dtype> {
+ public:
+  explicit CuDNNDeconvolutionLayer(const LayerParameter& param)
+      : DeconvolutionLayer<Dtype>(param), handles_setup_(false) {}
+  virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual void Reshape(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual ~CuDNNDeconvolutionLayer();
+
+ protected:
+  virtual void Forward_gpu(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual void Backward_gpu(const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
+
+  bool handles_setup_;
+  cudnnHandle_t* handle_;
+  cudaStream_t*  stream_;
+
+  // algorithms for forward and backwards convolutions
+  cudnnConvolutionFwdAlgo_t *fwd_algo_;
+  cudnnConvolutionBwdFilterAlgo_t *bwd_filter_algo_;
+  cudnnConvolutionBwdDataAlgo_t *bwd_data_algo_;
+
+  vector<cudnnTensorDescriptor_t> bottom_descs_, top_descs_;
+  cudnnTensorDescriptor_t    bias_desc_;
+  cudnnFilterDescriptor_t      filter_desc_;
+  vector<cudnnConvolutionDescriptor_t> conv_descs_;
+  int bottom_offset_, top_offset_, bias_offset_;
+
+  size_t *workspace_fwd_sizes_;
+  size_t *workspace_bwd_data_sizes_;
+  size_t *workspace_bwd_filter_sizes_;
+  size_t workspaceSizeInBytes;  // size of underlying storage
+  void *workspaceData;  // underlying storage
+  void **workspace;  // aliases into workspaceData
+};
+#endif
+
+}  // namespace caffe
+
+#endif  // CAFFE_CUDNN_DECONV_LAYER_HPP_
diff --git a/include/caffe/layers/hdf5_data_layer.hpp b/include/caffe/layers/hdf5_data_layer.hpp
index b04cf8e..96dd827 100644
--- a/include/caffe/layers/hdf5_data_layer.hpp
+++ b/include/caffe/layers/hdf5_data_layer.hpp
@@ -29,9 +29,9 @@ class HDF5DataLayer : public Layer<Dtype> {
       const vector<Blob<Dtype>*>& top);
   // Data layers should be shared by multiple solvers in parallel
   virtual inline bool ShareInParallel() const { return true; }
-  // Data layers have no bottoms, so reshaping is trivial.
+  // Reshaping according to loaded HDF5 shape (could vary during training)
   virtual void Reshape(const vector<Blob<Dtype>*>& bottom,
-      const vector<Blob<Dtype>*>& top) {}
+      const vector<Blob<Dtype>*>& top);
 
   virtual inline const char* type() const { return "HDF5Data"; }
   virtual inline int ExactNumBottomBlobs() const { return 0; }
@@ -50,6 +50,9 @@ class HDF5DataLayer : public Layer<Dtype> {
 
   std::vector<std::string> hdf_filenames_;
   unsigned int num_files_;
+  std::vector<std::vector<hsize_t> > dataset_shapes_;
+  bool files_have_consistent_shapes_;
+  bool hdf_blobs_divisible_by_batch_size_;
   unsigned int current_file_;
   hsize_t current_row_;
   std::vector<shared_ptr<Blob<Dtype> > > hdf_blobs_;
diff --git a/include/caffe/layers/hdf5_output_layer.hpp b/include/caffe/layers/hdf5_output_layer.hpp
index 487d08f..17f4244 100644
--- a/include/caffe/layers/hdf5_output_layer.hpp
+++ b/include/caffe/layers/hdf5_output_layer.hpp
@@ -10,11 +10,11 @@
 #include "caffe/layer.hpp"
 #include "caffe/proto/caffe.pb.h"
 
-namespace caffe {
-
 #define HDF5_DATA_DATASET_NAME "data"
 #define HDF5_DATA_LABEL_NAME "label"
 
+namespace caffe {
+
 /**
  * @brief Write blobs to disk as HDF5 files.
  *
@@ -24,7 +24,7 @@ template <typename Dtype>
 class HDF5OutputLayer : public Layer<Dtype> {
  public:
   explicit HDF5OutputLayer(const LayerParameter& param)
-      : Layer<Dtype>(param), file_opened_(false) {}
+      : Layer<Dtype>(param), file_iter_(0) {}
   virtual ~HDF5OutputLayer();
   virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top);
@@ -35,8 +35,7 @@ class HDF5OutputLayer : public Layer<Dtype> {
       const vector<Blob<Dtype>*>& top) {}
 
   virtual inline const char* type() const { return "HDF5Output"; }
-  // TODO: no limit on the number of blobs
-  virtual inline int ExactNumBottomBlobs() const { return 2; }
+  virtual inline int MinBottomBlobs() const { return 1; }
   virtual inline int ExactNumTopBlobs() const { return 0; }
 
   inline std::string file_name() const { return file_name_; }
@@ -50,13 +49,11 @@ class HDF5OutputLayer : public Layer<Dtype> {
       const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
   virtual void Backward_gpu(const vector<Blob<Dtype>*>& top,
       const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
-  virtual void SaveBlobs();
+  virtual void SaveBlobs(const vector<Blob<Dtype>*>& bottom, bool is_GPU_data);
 
-  bool file_opened_;
   std::string file_name_;
-  hid_t file_id_;
-  Blob<Dtype> data_blob_;
-  Blob<Dtype> label_blob_;
+  std::vector<std::string> dset_names_;
+  int file_iter_;
 };
 
 }  // namespace caffe
diff --git a/include/caffe/layers/pooling_layer.hpp b/include/caffe/layers/pooling_layer.hpp
index f4d6803..a377bc2 100644
--- a/include/caffe/layers/pooling_layer.hpp
+++ b/include/caffe/layers/pooling_layer.hpp
@@ -44,12 +44,24 @@ class PoolingLayer : public Layer<Dtype> {
   virtual void Backward_gpu(const vector<Blob<Dtype>*>& top,
       const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
 
-  int kernel_h_, kernel_w_;
-  int stride_h_, stride_w_;
-  int pad_h_, pad_w_;
+  /// @brief The spatial dimensions of a filter kernel.
+  Blob<int> kernel_shape_;
+  /// @brief The spatial dimensions of the stride.
+  Blob<int> stride_;
+  /// @brief The spatial dimensions of the padding.
+  Blob<int> pad_;
+  /// @brief The spatial dimensions of the input.
+  Blob<int> input_shape_;
+  /// @brief The spatial dimensions of the output.
+  Blob<int> output_shape_;
+
+  int num_spatial_axes_;
+  int bottom_dim_;
+  int top_dim_;
+
+  int channel_axis_;
   int channels_;
-  int height_, width_;
-  int pooled_height_, pooled_width_;
+  int num_;
   bool global_pooling_;
   Blob<Dtype> rand_idx_;
   Blob<int> max_idx_;
diff --git a/include/caffe/layers/softmax_loss_layer.hpp b/include/caffe/layers/softmax_loss_layer.hpp
index f07e8a0..4343238 100644
--- a/include/caffe/layers/softmax_loss_layer.hpp
+++ b/include/caffe/layers/softmax_loss_layer.hpp
@@ -59,10 +59,14 @@ class SoftmaxWithLossLayer : public LossLayer<Dtype> {
       const vector<Blob<Dtype>*>& top);
 
   virtual inline const char* type() const { return "SoftmaxWithLoss"; }
+  virtual inline int ExactNumBottomBlobs() const { return -1; }
+  virtual inline int MinBottomBlobs() const { return 2; }
+  virtual inline int MaxBottomBlobs() const { return 3; }
   virtual inline int ExactNumTopBlobs() const { return -1; }
   virtual inline int MinTopBlobs() const { return 1; }
   virtual inline int MaxTopBlobs() const { return 2; }
 
+
  protected:
   virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top);
diff --git a/include/caffe/layers/value_augmentation_layer.hpp b/include/caffe/layers/value_augmentation_layer.hpp
new file mode 100644
index 0000000..6a37752
--- /dev/null
+++ b/include/caffe/layers/value_augmentation_layer.hpp
@@ -0,0 +1,110 @@
+#ifndef VALUE_AUGMENTATION_LAYER_HPP_
+#define VALUE_AUGMENTATION_LAYER_HPP_
+
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "caffe/blob.hpp"
+#include "caffe/common.hpp"
+#include "caffe/layer.hpp"
+#include "caffe/layers/neuron_layer.hpp"
+
+namespace caffe {
+
+/**
+ * @brief Data augmentation by mapping the values. The layer provides
+ * a contrast increse/decrease by using a smooth monotoning mapping.
+ */
+template <typename Dtype>
+class ValueAugmentationLayer : public NeuronLayer<Dtype> {
+ public:
+  /**
+   * @param param provides ValueAugmentationParameter value_augmentation_param,
+   *     with ValueAugmentationLayer options:
+   *
+   *     - black_from, black_to range from which to uniformly sample the
+   *                            value mapped to black (i.e. zero)
+   *
+   *     - white_from, white_to range from which to uniformly sample the
+   *                            value mapped to white (i.e. one)
+   *
+   *     - slope_min, slope_max range from which to uniformly sample the slopes
+   *
+   *     - n_control_point_insertions determines the number of different slopes
+   */
+  explicit ValueAugmentationLayer(const LayerParameter& param)
+    : NeuronLayer<Dtype>(param) {}
+
+  void CreateLinearInterpExtrapMatrix(
+    int n_in,  Dtype dx_in,
+    int n_out, Dtype dx_out,
+    int n_extrapol,
+    Dtype* lin_mat);
+
+  virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom,
+                          const vector<Blob<Dtype>*>& top);
+
+  virtual inline const char* type() const { return "ValueAugmentation"; }
+
+  std::vector<Dtype> random_lut_controlpoints(
+    Dtype black_from, Dtype black_to,
+    Dtype white_from, Dtype white_to,
+    Dtype slope_min,  Dtype slope_max,
+    int n_control_point_insertions);
+
+  std::vector<Dtype> dense_lut(const std::vector<Dtype>& lut_control_points);
+
+  void apply_lut(const std::vector<Dtype>& lut,
+                 const Dtype* in_data, Dtype* out_data, size_t count);
+
+ protected:
+
+  /**
+   * @param bottom input Blob vector (length 1)
+   *   -# @f$ (N \times C \times H \times W) @f$
+   *      the inputs @f$ x @f$
+   * @param top output Blob vector (length 1)
+   *   -# @f$ (N \times C \times H \times W) @f$
+   *      the computed outputs @f$
+   *        y = f(x),
+   *      @f$
+   */
+  virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom,
+                           const vector<Blob<Dtype>*>& top);
+
+  /**
+   * @brief Dummy function -- no gradients yet
+   *
+   * @param top output Blob vector (length 1), providing the error gradient with
+   *      respect to the outputs
+   *   -# @f$ (N \times C \times H \times W) @f$
+   *      containing error gradients @f$ \frac{\partial E}{\partial y} @f$
+   *      with respect to computed outputs @f$ y @f$
+   * @param propagate_down see Layer::Backward.
+   * @param bottom input Blob vector (length 1)
+   *   -# @f$ (N \times C \times H \times W) @f$
+   *      the inputs @f$ x @f$; Backward fills their diff with
+   *      gradients @f$
+   *        \frac{\partial E}{\partial x} = ...
+   *      @f$ if propagate_down[0]
+   */
+  virtual void Backward_cpu(const vector<Blob<Dtype>*>& top,
+                            const vector<bool>& propagate_down,
+                            const vector<Blob<Dtype>*>& bottom);
+
+  Dtype  black_from_;
+  Dtype  black_to_;
+  Dtype  white_from_;
+  Dtype  white_to_;
+  Dtype  slope_min_;
+  Dtype  slope_max_;
+  int    n_control_points_;
+  int    n_control_point_insertions_;
+  int    lut_size_;
+  Blob<Dtype> interpol_mat_;
+};
+
+} // namespace cafff
+
+#endif // VALUE_AUGMENTATION_LAYER_HPP_
diff --git a/include/caffe/layers/value_transformation_layer.hpp b/include/caffe/layers/value_transformation_layer.hpp
new file mode 100644
index 0000000..dce2de7
--- /dev/null
+++ b/include/caffe/layers/value_transformation_layer.hpp
@@ -0,0 +1,78 @@
+#ifndef CAFFE_VALUE_TRANSFORMATION_LAYER_
+#define CAFFE_VALUE_TRANSFORMATION_LAYER_
+
+#include "caffe/blob.hpp"
+#include "caffe/layer.hpp"
+#include "caffe/proto/caffe.pb.h"
+
+#include "caffe/layers/neuron_layer.hpp"
+
+namespace caffe {
+
+/**
+ * @brief Channel-wise affine intensity value transformation
+ *    @f$ y_c = \alpha_c ( x_c + \beta_c ) @f$
+ */
+template <typename Dtype>
+class ValueTransformationLayer : public NeuronLayer<Dtype> {
+ public:
+  /**
+   * @param param provides ValueTransformationParameter
+   *     value_augmentation_param, with ValueTransformationLayer options:
+   *
+   *   - offset (\b optional, vectorial (1|#channels), default 0) @f$\beta@f$.
+   *          Add the given constant value(s) to the channels of the bottom
+   *          blob. If one value is given, it will be added to all channels,
+   *          otherwise the number of given values must equal the number of
+   *          channels and the corresponding individual channel offset is
+   *          applied.
+   *   - scale (\b optional, vectorial (1|#channels), default 1) @f$\alpha@f$.
+   *          Scale the channels of the bottom blob with the given scale
+   *          factor(s). If one value is given it will be used for all
+   *          channels, otherwise the number of given values must equal the
+   *          number of channels and the corresponding individual channel
+   *          scale factors are applied.
+   *
+   *   The scale and offset are given, first the offset is applied and the
+   *   result scaled.
+   */
+  explicit ValueTransformationLayer(const LayerParameter& param)
+      : NeuronLayer<Dtype>(param) {}
+
+
+  virtual void LayerSetUp(const vector<Blob<Dtype>*>& bottom,
+                          const vector<Blob<Dtype>*>& top);
+
+  virtual inline const char* type() const { return "ValueTransformation"; }
+
+ protected:
+
+  /**
+   * @param bottom input Blob vector (length 1)
+   *   -# @f$ (N \times C \times H \times W) @f$
+   *      the inputs @f$ x @f$
+   * @param top output Blob vector (length 1)
+   *   -# @f$ (N \times C \times H \times W) @f$
+   *      the computed outputs @f$
+   *        y_c = \alpha_c (x + \beta_c)
+   *      @f$
+   */
+  virtual void Forward_cpu(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+  virtual void Forward_gpu(const vector<Blob<Dtype>*>& bottom,
+      const vector<Blob<Dtype>*>& top);
+
+  /**
+   * @brief Dummy function -- no gradients yet
+   */
+  virtual void Backward_cpu(const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
+  virtual void Backward_gpu(const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom);
+
+  std::vector<Dtype> _offset, _scale;
+};
+
+}  // namespace caffe
+
+#endif  // CAFFE_VALUE_TRANSFORMATION_LAYER_
diff --git a/include/caffe/util/cudnn.hpp b/include/caffe/util/cudnn.hpp
index a7d8dbb..efbeaff 100644
--- a/include/caffe/util/cudnn.hpp
+++ b/include/caffe/util/cudnn.hpp
@@ -3,6 +3,7 @@
 #ifdef USE_CUDNN
 
 #include <cudnn.h>
+#include <vector>
 
 #include "caffe/common.hpp"
 #include "caffe/proto/caffe.pb.h"
@@ -69,11 +70,26 @@ inline void createTensor4dDesc(cudnnTensorDescriptor_t* desc) {
 }
 
 template <typename Dtype>
+inline void createTensorDesc(cudnnTensorDescriptor_t* desc) {
+  CUDNN_CHECK(cudnnCreateTensorDescriptor(desc));
+}
+
+template <typename Dtype>
 inline void setTensor4dDesc(cudnnTensorDescriptor_t* desc,
     int n, int c, int h, int w,
     int stride_n, int stride_c, int stride_h, int stride_w) {
   CUDNN_CHECK(cudnnSetTensor4dDescriptorEx(*desc, dataType<Dtype>::type,
-        n, c, h, w, stride_n, stride_c, stride_h, stride_w));
+              n, c, h, w, stride_n, stride_c, stride_h, stride_w));
+}
+
+template <typename Dtype>
+inline void setTensorNdDesc(cudnnTensorDescriptor_t* desc,
+    std::vector<int> shape,
+    std::vector<int> stride) {
+  CHECK_EQ(shape.size(), stride.size()) <<
+      "Dimensions of shape and stride don't match !";
+  CUDNN_CHECK(cudnnSetTensorNdDescriptor(*desc, dataType<Dtype>::type,
+              shape.size(), shape.data(), stride.data()));
 }
 
 template <typename Dtype>
@@ -84,7 +100,17 @@ inline void setTensor4dDesc(cudnnTensorDescriptor_t* desc,
   const int stride_c = h * stride_h;
   const int stride_n = c * stride_c;
   setTensor4dDesc<Dtype>(desc, n, c, h, w,
-                         stride_n, stride_c, stride_h, stride_w);
+      stride_n, stride_c, stride_h, stride_w);
+}
+
+template <typename Dtype>
+inline void setTensorNdDesc(cudnnTensorDescriptor_t* desc,
+    std::vector<int> shape) {
+  std::vector<int> stride(shape.size(), 1);
+  for (int i = stride.size()-2; i >= 0; --i) {
+    stride[i] = shape[i+1] * stride[i+1];
+  }
+  setTensorNdDesc<Dtype>(desc, shape, stride);
 }
 
 template <typename Dtype>
@@ -101,6 +127,20 @@ inline void createFilterDesc(cudnnFilterDescriptor_t* desc,
 }
 
 template <typename Dtype>
+inline void createNdFilterDesc(cudnnFilterDescriptor_t* desc,
+    std::vector<int> shape) {
+  CUDNN_CHECK(cudnnCreateFilterDescriptor(desc));
+  cudnnTensorFormat_t tensor_format;
+#if CUDNN_VERSION_MIN(5, 0, 0)
+  CUDNN_CHECK(cudnnSetFilterNdDescriptor(*desc, dataType<Dtype>::type,
+              tensor_format, shape.size(), shape.data()));
+#else
+  CUDNN_CHECK(cudnnSetFilterNdDescriptor_v4(*desc, dataType<Dtype>::type,
+              tensor_format, shape.size(), shape.data()));
+#endif
+}
+
+template <typename Dtype>
 inline void createConvolutionDesc(cudnnConvolutionDescriptor_t* conv) {
   CUDNN_CHECK(cudnnCreateConvolutionDescriptor(conv));
 }
@@ -110,7 +150,33 @@ inline void setConvolutionDesc(cudnnConvolutionDescriptor_t* conv,
     cudnnTensorDescriptor_t bottom, cudnnFilterDescriptor_t filter,
     int pad_h, int pad_w, int stride_h, int stride_w) {
   CUDNN_CHECK(cudnnSetConvolution2dDescriptor(*conv,
-      pad_h, pad_w, stride_h, stride_w, 1, 1, CUDNN_CROSS_CORRELATION));
+              pad_h, pad_w, stride_h, stride_w, 1, 1, CUDNN_CROSS_CORRELATION));
+}
+
+template <typename Dtype>
+inline void setNdConvolutionDesc(cudnnConvolutionDescriptor_t* conv,
+    cudnnTensorDescriptor_t bottom, cudnnFilterDescriptor_t filter,
+    std::vector<int> pad, std::vector<int> stride) {
+  int nbDims;
+  std::vector<int> shape(pad.size()+2);
+  cudnnDataType_t cudnn_type;
+  cudnnTensorFormat_t tensor_format;
+#if CUDNN_VERSION_MIN(5, 0, 0)
+
+  cudnnGetFilterNdDescriptor(filter, shape.size(), &cudnn_type,
+              &tensor_format, &nbDims, shape.data());
+#else
+  cudnnGetFilterNdDescriptor_v4(filter, shape.size(), &cudnn_type,
+              &tensor_format, &nbDims, shape.data());
+#endif
+  CHECK_EQ(nbDims, pad.size()+2) <<
+      "Dimensions of filters and pad don't match !";
+  CHECK_EQ(nbDims, stride.size()+2) <<
+      "Dimensions of filters and stride don't match !";
+  std::vector<int> upscale(pad.size(), 1);
+  CUDNN_CHECK(cudnnSetConvolutionNdDescriptor(*conv,
+              pad.size(), pad.data(), stride.data(), upscale.data(),
+              CUDNN_CROSS_CORRELATION, cudnn_type));
 }
 
 template <typename Dtype>
@@ -138,6 +204,36 @@ inline void createPoolingDesc(cudnnPoolingDescriptor_t* pool_desc,
 }
 
 template <typename Dtype>
+inline void createNdPoolingDesc(cudnnPoolingDescriptor_t* pool_desc,
+    PoolingParameter_PoolMethod poolmethod, cudnnPoolingMode_t* mode,
+    std::vector<int> shape, std::vector<int> pad, std::vector<int> stride) {
+  CHECK_EQ(shape.size(), pad.size()) <<
+      "Dimensions of shape and pad don't match !";
+  CHECK_EQ(shape.size(), stride.size()) <<
+      "Dimensions of shape and stride don't match !";
+  switch (poolmethod) {
+  case PoolingParameter_PoolMethod_MAX:
+    *mode = CUDNN_POOLING_MAX;
+    break;
+  case PoolingParameter_PoolMethod_AVE:
+    *mode = CUDNN_POOLING_AVERAGE_COUNT_INCLUDE_PADDING;
+    break;
+  default:
+    LOG(FATAL) << "Unknown pooling method.";
+  }
+  CUDNN_CHECK(cudnnCreatePoolingDescriptor(pool_desc));
+#if CUDNN_VERSION_MIN(5, 0, 0)
+  CUDNN_CHECK(cudnnSetPoolingNdDescriptor(*pool_desc, *mode,
+               CUDNN_PROPAGATE_NAN, shape.size(), shape.data(),
+               pad.data(), stride.data()));
+#else
+  CUDNN_CHECK(cudnnSetPoolingNdDescriptor_v4(*pool_desc, *mode,
+              CUDNN_PROPAGATE_NAN, shape.size(), shape.data(), pad.data(),
+              stride.data()));
+#endif
+}
+
+template <typename Dtype>
 inline void createActivationDescriptor(cudnnActivationDescriptor_t* activ_desc,
     cudnnActivationMode_t mode) {
   CUDNN_CHECK(cudnnCreateActivationDescriptor(activ_desc));
diff --git a/include/caffe/util/hdf5.hpp b/include/caffe/util/hdf5.hpp
index ce568c5..b84b75f 100644
--- a/include/caffe/util/hdf5.hpp
+++ b/include/caffe/util/hdf5.hpp
@@ -27,6 +27,9 @@ void hdf5_save_nd_dataset(
 
 int hdf5_load_int(hid_t loc_id, const string& dataset_name);
 void hdf5_save_int(hid_t loc_id, const string& dataset_name, int i);
+std::vector<int> hdf5_load_int_vec(hid_t loc_id, const string &dataset_name);
+void hdf5_save_int_vec(
+    hid_t loc_id, const string &dataset_name, std::vector<int> vec);
 string hdf5_load_string(hid_t loc_id, const string& dataset_name);
 void hdf5_save_string(hid_t loc_id, const string& dataset_name,
                       const string& s);
@@ -34,6 +37,8 @@ void hdf5_save_string(hid_t loc_id, const string& dataset_name,
 int hdf5_get_num_links(hid_t loc_id);
 string hdf5_get_name_by_idx(hid_t loc_id, int idx);
 
+std::vector<hsize_t> hdf5_get_dataset_shape(
+    hid_t file_id, const char* dataset_name);
 }  // namespace caffe
 
 #endif   // CAFFE_UTIL_HDF5_H_
diff --git a/include/caffe/util/math_functions.hpp b/include/caffe/util/math_functions.hpp
index 6f6d3fe..5503aa6 100644
--- a/include/caffe/util/math_functions.hpp
+++ b/include/caffe/util/math_functions.hpp
@@ -37,6 +37,13 @@ template <typename Dtype>
 void caffe_copy(const int N, const Dtype *X, Dtype *Y);
 
 template <typename Dtype>
+void caffe_copy_subarray(const Dtype* src_p, const vector<int>& src_shape,
+                         Dtype*       trg_p, const vector<int>& trg_shape,
+                         const vector<int>& src_offset,
+                         const vector<int>& copy_shape,
+                         const vector<int>& trg_offset);
+
+template <typename Dtype>
 void caffe_set(const int N, const Dtype alpha, Dtype *X);
 
 inline void caffe_memset(const size_t N, const int alpha, void* X) {
@@ -85,6 +92,18 @@ void caffe_rng_bernoulli(const int n, const Dtype p, int* r);
 template <typename Dtype>
 void caffe_rng_bernoulli(const int n, const Dtype p, unsigned int* r);
 
+// Returns a random index using an arbitrary cummulative density
+// function. You might want to use caffe_cpu_cumsum() to create this
+// cdf from a given probability density function.
+template <typename Dtype>
+size_t caffe_randi_arbitrary_cdf(const size_t n, const Dtype* cdf);
+
+// Returns a random 3D position using an arbitrary cummulative density
+// function.
+template <typename Dtype>
+void caffe_rand_pos_arbitrary_cdf(const Dtype* cdf, int nz, int ny, int nx,
+                                  int* z, int* y, int* x);
+
 template <typename Dtype>
 void caffe_exp(const int n, const Dtype* a, Dtype* y);
 
@@ -105,6 +124,11 @@ Dtype caffe_cpu_strided_dot(const int n, const Dtype* x, const int incx,
 template <typename Dtype>
 Dtype caffe_cpu_asum(const int n, const Dtype* x);
 
+// Returns the cummulative sums of the elements of vector x
+// i.e. y[i] = sum_{j=0...i} x[j]
+template <typename Dtype>
+void caffe_cpu_cumsum(const size_t n, const Dtype* x, Dtype* y);
+
 // the branchless, type-safe version from
 // http://stackoverflow.com/questions/1903954/is-there-a-standard-sign-function-signum-sgn-in-c-c
 template<typename Dtype>
diff --git a/include/caffe/util/vector_helper.hpp b/include/caffe/util/vector_helper.hpp
new file mode 100644
index 0000000..a27e210
--- /dev/null
+++ b/include/caffe/util/vector_helper.hpp
@@ -0,0 +1,951 @@
+#ifndef CAFFE_VECTOR_HELPERS_HPP_
+#define CAFFE_VECTOR_HELPERS_HPP_
+
+#include <vector>
+#include <sstream>
+#include <iomanip>
+#include "caffe/util/math_functions.hpp"
+
+namespace caffe {
+using std::vector;
+
+template< typename T>
+std::string toString(vector<T> v) {
+  std::ostringstream oss;
+  for (int i = 0; i < v.size(); ++i) {
+    if( i == 0) { oss << "("; } else { oss << ","; }
+    oss << v[i];
+  }
+  oss << ")";
+  return oss.str();
+}
+
+template< typename T>
+std::string toString(vector<T> v, int precision) {
+  std::ostringstream oss;
+  oss << std::setprecision(precision);
+  for (int i = 0; i < v.size(); ++i) {
+    if( i == 0) { oss << "("; } else { oss << ","; }
+    oss << v[i];
+  }
+  oss << ")";
+  return oss.str();
+}
+
+inline
+std::string toString(const int* v, int n) {
+  std::ostringstream oss;
+  for (int i = 0; i < n; ++i) {
+    if (i == 0) { oss << "("; } else { oss << ","; }
+    oss << v[i];
+  }
+  oss << ")";
+  return oss.str();
+}
+
+inline
+std::string toString(const float* v, int n) {
+  std::ostringstream oss;
+  for (int i = 0; i < n; ++i) {
+    if (i == 0) { oss << "("; } else { oss << ","; }
+    oss << v[i];
+  }
+  oss << ")";
+  return oss.str();
+}
+
+inline
+std::string toString(const double* v, int n) {
+  std::ostringstream oss;
+  for (int i = 0; i < n; ++i) {
+    if (i == 0) { oss << "("; } else { oss << ","; }
+    oss << v[i];
+  }
+  oss << ")";
+  return oss.str();
+}
+
+template< typename T>
+std::string Array2DtoString(
+    const T* v, int ny, int nx, float precision = 1e-5) {
+  std::ostringstream oss;
+  int i = 0;
+  for (int y = 0; y < ny; ++y) {
+    for (int x = 0; x < nx; ++x) {
+      float u = v[i];
+      u = floor(u / precision + 0.5) * precision;
+      oss << u << ",";
+      ++i;
+    }
+    oss << "\n";
+  }
+  return oss.str();
+}
+
+inline
+vector<int> make_int_vect(int v0) {
+  vector<int> vec(1);
+  vec[0] = v0;
+  return vec;
+}
+
+inline
+vector<int> make_int_vect(int v0, int v1) {
+  vector<int> vec(2);
+  vec[0] = v0;
+  vec[1] = v1;
+  return vec;
+}
+
+inline
+vector<int> make_int_vect(int v0, int v1, int v2) {
+  vector<int> vec(3);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  return vec;
+}
+
+inline
+vector<int> make_int_vect(int v0, int v1, int v2, int v3) {
+  vector<int> vec(4);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  return vec;
+}
+
+inline
+vector<int> make_int_vect(int v0, int v1, int v2, int v3, int v4) {
+  vector<int> vec(5);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  vec[4] = v4;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0) {
+  vector<T> vec(1);
+  vec[0] = v0;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1) {
+  vector<T> vec(2);
+  vec[0] = v0;
+  vec[1] = v1;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2) {
+  vector<T> vec(3);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2, T v3) {
+  vector<T> vec(4);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2, T v3, T v4) {
+  vector<T> vec(5);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  vec[4] = v4;
+  return vec;
+}
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2, T v3, T v4, T v5) {
+  vector<T> vec(6);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  vec[4] = v4;
+  vec[5] = v5;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2, T v3, T v4, T v5, T v6, T v7, T v8) {
+  vector<T> vec(9);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  vec[4] = v4;
+  vec[5] = v5;
+  vec[6] = v6;
+  vec[7] = v7;
+  vec[8] = v8;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2, T v3, T v4, T v5, T v6, T v7,
+                         T v8, T v9, T v10, T v11) {
+  vector<T> vec(12);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  vec[4] = v4;
+  vec[5] = v5;
+  vec[6] = v6;
+  vec[7] = v7;
+  vec[8] = v8;
+  vec[9] = v9;
+  vec[10] = v10;
+  vec[11] = v11;
+  return vec;
+}
+
+template<typename T>
+inline
+vector<T> make_vec( T v0, T v1, T v2, T v3, T v4, T v5, T v6, T v7,
+                         T v8, T v9, T v10, T v11, T v12, T v13, T v14, T v15) {
+  vector<T> vec(16);
+  vec[0] = v0;
+  vec[1] = v1;
+  vec[2] = v2;
+  vec[3] = v3;
+  vec[4] = v4;
+  vec[5] = v5;
+  vec[6] = v6;
+  vec[7] = v7;
+  vec[8] = v8;
+  vec[9] = v9;
+  vec[10] = v10;
+  vec[11] = v11;
+  vec[12] = v12;
+  vec[13] = v13;
+  vec[14] = v14;
+  vec[15] = v15;
+  return vec;
+}
+
+
+template<typename T>
+inline
+vector<T> m_shift3D( T s1, T s2, T s3, const vector<T>& M)  {
+  vector<T> A = make_vec<T>(1,0,0,s1,
+                            0,1,0,s2,
+                            0,0,1,s3,
+                            0,0,0,1);
+  vector<T> B(16);
+  caffe_cpu_gemm<T>(CblasNoTrans, CblasNoTrans,
+                    4, 4, 4, 1, A.data(), M.data(), 0, B.data());
+  return B;
+}
+
+template<typename T>
+inline
+vector<T> m_scale3D( T s1, T s2, T s3, const vector<T>& M)  {
+  vector<T> A = make_vec<T>(s1,0,0,0,
+                            0,s2,0,0,
+                            0,0,s3,0,
+                            0,0,0, 1);
+  vector<T> B(16);
+  caffe_cpu_gemm<T>(CblasNoTrans, CblasNoTrans,
+                    4, 4, 4, 1, A.data(), M.data(), 0, B.data());
+  return B;
+}
+
+template<typename T>
+inline
+vector<T> m_rotate3D( T phi1, T phi2, T phi3, const vector<T>& M)  {
+  T sina = sin( phi1 / 180 * M_PI);
+  T cosa = cos( phi1 / 180 * M_PI);
+  vector<T> rotateAroundZ = make_vec<T>(
+      1,   0,     0,    0,
+      0,   cosa, -sina, 0,
+      0,   sina, cosa,  0,
+      0,   0,     0,    1);
+
+
+  sina = sin( phi2 / 180 * M_PI);
+  cosa = cos( phi2 / 180 * M_PI);
+  vector<T> rotateAroundY = make_vec<T>(
+      cosa,  0,  -sina, 0,
+      0,     1,   0,    0,
+      sina,  0,   cosa, 0,
+      0,     0,     0,  1);
+
+
+  sina = sin( phi3 / 180 * M_PI);
+  cosa = cos( phi3 / 180 * M_PI);
+  vector<T> rotateAroundX = make_vec<T>(
+      cosa, -sina, 0, 0,
+      sina, cosa,  0, 0,
+      0,    0,     1, 0,
+      0,    0,     0, 1);
+
+  vector<T> A(16);
+  vector<T> B(16);
+  caffe_cpu_gemm<T>(CblasNoTrans, CblasNoTrans, 4, 4, 4, 1,
+                    rotateAroundZ.data(), M.data(), 0, A.data());
+  caffe_cpu_gemm<T>(CblasNoTrans, CblasNoTrans, 4, 4, 4, 1,
+                    rotateAroundY.data(), A.data(), 0, B.data());
+  caffe_cpu_gemm<T>(CblasNoTrans, CblasNoTrans, 4, 4, 4, 1,
+                    rotateAroundX.data(), B.data(), 0, A.data());
+  return A;
+}
+
+// Example for N=5
+// index: -8 -7 -6 -5 -4 -3 -2 -1  0  1  2  3  4  5  6  7  8  9 10 11 12
+// value:  0  1  2  3  4  3  2  1  0  1  2  3  4  3  2  1  0  1  2  3  4
+inline
+int mirrorAtBorder( int i, int N) {
+  if( i >= 0 && i < N) return i;
+  if( N == 1) return 0;
+  int i2 = abs(i) % (N*2-2);
+  if( i2 >= N) {
+    i2 = (N*2-2) - i2;
+  }
+  return i2;
+}
+
+template< typename T>
+inline
+T linear2D_zeropad( const T* data, int ny, int nx, float y, float x) {
+  const int iy = floor(y);
+  const int ix = floor(x);
+  const float fy = y - iy;
+  const float fx = x - ix;
+
+  const bool validx0 = (ix >= 0 && ix < nx);
+  const bool validy0 = (iy >= 0 && iy < ny);
+  const bool validx1 = (ix+1 >= 0 && ix+1 < nx);
+  const bool validy1 = (iy+1 >= 0 && iy+1 < ny);
+
+  const T* p = data + iy * nx + ix;
+  const float a00 = (validy0 && validx0)? p[     0] : 0;
+  const float a01 = (validy0 && validx1)? p[     1] : 0;
+  const float a10 = (validy1 && validx0)? p[nx    ] : 0;
+  const float a11 = (validy1 && validx1)? p[nx + 1] : 0;
+
+  return (1 - fy) * (1 - fx) * a00
+      +  (1 - fy) * (    fx) * a01
+      +  (    fy) * (1 - fx) * a10
+      +  (    fy) * (    fx) * a11;
+}
+
+
+template< typename T>
+inline
+T linear2D_mirror( const T* data, int ny, int nx, float y, float x) {
+  const int iy = floor(y);
+  const int ix = floor(x);
+  const float fy = y - iy;
+  const float fx = x - ix;
+
+  const int iy0 = mirrorAtBorder( iy    , ny);
+  const int ix0 = mirrorAtBorder( ix    , nx);
+  const int iy1 = mirrorAtBorder( iy + 1, ny);
+  const int ix1 = mirrorAtBorder( ix + 1, nx);
+
+  return (1 - fy) * (1 - fx) * data[iy0 * nx + ix0]
+      +  (1 - fy) * (    fx) * data[iy0 * nx + ix1]
+      +  (    fy) * (1 - fx) * data[iy1 * nx + ix0]
+      +  (    fy) * (    fx) * data[iy1 * nx + ix1];
+}
+
+
+template< typename T>
+inline
+T linear3D_zeropad( const T* data, int nz, int ny, int nx,
+                     float z, float y, float x) {
+  const int iz = floor(z);
+  const int iy = floor(y);
+  const int ix = floor(x);
+  const float fz = z - iz;
+  const float fy = y - iy;
+  const float fx = x - ix;
+
+
+  const bool validz0 = (iz >= 0 && iz < nz);
+  const bool validy0 = (iy >= 0 && iy < ny);
+  const bool validx0 = (ix >= 0 && ix < nx);
+  const bool validz1 = (iz+1 >= 0 && iz+1 < nz);
+  const bool validy1 = (iy+1 >= 0 && iy+1 < ny);
+  const bool validx1 = (ix+1 >= 0 && ix+1 < nx);
+
+
+  int nxy = nx * ny;
+  const T* p = data + iz * nxy + iy * nx + ix;
+  const float a000 = (validz0 && validy0 && validx0)? p[  0 +  0 + 0] : 0;
+  const float a001 = (validz0 && validy0 && validx1)? p[  0 +  0 + 1] : 0;
+  const float a010 = (validz0 && validy1 && validx0)? p[  0 + nx + 0] : 0;
+  const float a011 = (validz0 && validy1 && validx1)? p[  0 + nx + 1] : 0;
+  const float a100 = (validz1 && validy0 && validx0)? p[nxy +  0 + 0] : 0;
+  const float a101 = (validz1 && validy0 && validx1)? p[nxy +  0 + 1] : 0;
+  const float a110 = (validz1 && validy1 && validx0)? p[nxy + nx + 0] : 0;
+  const float a111 = (validz1 && validy1 && validx1)? p[nxy + nx + 1] : 0;
+
+  return (1 - fz) * (1 - fy) * (1 - fx) * a000
+      +  (1 - fz) * (1 - fy) * (    fx) * a001
+      +  (1 - fz) * (    fy) * (1 - fx) * a010
+      +  (1 - fz) * (    fy) * (    fx) * a011
+      +  (    fz) * (1 - fy) * (1 - fx) * a100
+      +  (    fz) * (1 - fy) * (    fx) * a101
+      +  (    fz) * (    fy) * (1 - fx) * a110
+      +  (    fz) * (    fy) * (    fx) * a111;
+}
+
+
+template< typename T>
+inline
+T linear3D_mirror( const T* data, int nz, int ny, int nx,
+                     float z, float y, float x) {
+  const int iz = floor(z);
+  const int iy = floor(y);
+  const int ix = floor(x);
+  const float fz = z - iz;
+  const float fy = y - iy;
+  const float fx = x - ix;
+
+  const int iz0 = mirrorAtBorder( iz    , nz);
+  const int iy0 = mirrorAtBorder( iy    , ny);
+  const int ix0 = mirrorAtBorder( ix    , nx);
+  const int iz1 = mirrorAtBorder( iz + 1, nz);
+  const int iy1 = mirrorAtBorder( iy + 1, ny);
+  const int ix1 = mirrorAtBorder( ix + 1, nx);
+
+  return (1 - fz) * (1 - fy) * (1 - fx) * data[(iz0 * ny + iy0) * nx + ix0]
+      +  (1 - fz) * (1 - fy) * (    fx) * data[(iz0 * ny + iy0) * nx + ix1]
+      +  (1 - fz) * (    fy) * (1 - fx) * data[(iz0 * ny + iy1) * nx + ix0]
+      +  (1 - fz) * (    fy) * (    fx) * data[(iz0 * ny + iy1) * nx + ix1]
+      +  (    fz) * (1 - fy) * (1 - fx) * data[(iz1 * ny + iy0) * nx + ix0]
+      +  (    fz) * (1 - fy) * (    fx) * data[(iz1 * ny + iy0) * nx + ix1]
+      +  (    fz) * (    fy) * (1 - fx) * data[(iz1 * ny + iy1) * nx + ix0]
+      +  (    fz) * (    fy) * (    fx) * data[(iz1 * ny + iy1) * nx + ix1];
+}
+
+template< typename T>
+inline
+T nearest2D_zeropad( const T* data, int ny, int nx, float y, float x) {
+  const int iy = floor(y + 0.5);
+  const int ix = floor(x + 0.5);
+  return (ix >= 0 && ix < nx
+	  && iy >= 0 && iy < ny)?  data[ iy * nx + ix] : 0;
+}
+
+template< typename T>
+inline
+T nearest2D_mirror( const T* data, int ny, int nx, float y, float x) {
+  const int iy = mirrorAtBorder(floor(y + 0.5), ny);
+  const int ix = mirrorAtBorder(floor(x + 0.5), nx);
+  return data[ iy * nx + ix];
+}
+
+template< typename T>
+inline
+T nearest3D_zeropad( const T* data, int nz, int ny, int nx,
+             float z, float y, float x) {
+  const int iz = floor(z + 0.5);
+  const int iy = floor(y + 0.5);
+  const int ix = floor(x + 0.5);
+  return (ix >= 0 && ix < nx
+	  && iy >= 0 && iy < ny
+	  && iz >= 0 && iz < nz)?
+    data[ iz * ny * nx + iy * nx + ix] : 0;
+}
+
+template< typename T>
+inline
+T nearest3D_mirror( const T* data, int nz, int ny, int nx,
+             float z, float y, float x) {
+  const int iz = mirrorAtBorder(floor(z + 0.5), nz);
+  const int iy = mirrorAtBorder(floor(y + 0.5), ny);
+  const int ix = mirrorAtBorder(floor(x + 0.5), nx);
+  return data[ iz * ny * nx + iy * nx + ix];
+}
+
+
+template< typename T, typename Functor>
+inline
+void transform2D(const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+                 const T* def,int defNb,            int defNz, int defNy, int defNx,
+                 T* out,      int outNb, int outNc, int outNz, int outNy, int outNx,
+                 Functor Interpolator) {
+  CHECK_EQ(inNb, defNb) << "in and deform must have same batch size";
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_GE(defNz, outNz);
+  CHECK_GE(defNy, outNy);
+  CHECK_GE(defNx, outNx);
+  CHECK_EQ((defNz - outNz) % 2, 0);
+  CHECK_EQ((defNy - outNy) % 2, 0);
+  CHECK_EQ((defNx - outNx) % 2, 0);
+
+  const int offsZ = (defNz - outNz) / 2;
+  const int offsY = (defNy - outNy) / 2;
+  const int offsX = (defNx - outNx) / 2;
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      for (int z = 0; z < outNz; ++z) {
+        const T* inSlice  = in  + ((n * inNc  + c) * inNz  + z) * inNy  * inNx;
+        const T* defSlice = def + ( n * defNz + z + offsZ) * defNy * defNx * 2;
+        T*       outP     = out + ((n * outNc + c) * outNz + z) * outNy * outNx;
+        for (int y = 0; y < outNy; ++y) {
+          const T* defP = defSlice + ((y + offsY) * defNx + offsX) * 2;
+          for( int x = 0; x < outNx; ++x) {
+            *outP = Interpolator( inSlice, inNy, inNx, defP[0], defP[1]);
+            ++outP;
+            defP += 2;
+          }
+        }
+      }
+    }
+  }
+}
+
+
+template< typename T, typename Functor>
+inline
+void transform2D_offset(const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+                 const T* def,int defNb,            int defNz, int defNy, int defNx,
+				 int offsetY, int offsetX,
+                 T* out,      int outNb, int outNc, int outNz, int outNy, int outNx,
+                 Functor Interpolator) {
+  CHECK_EQ(inNb, defNb) << "in and deform must have same batch size";
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_LE(defNz, outNz);
+  CHECK_LE(defNy, outNy);
+  CHECK_LE(defNx, outNx);
+  CHECK_EQ((defNz - outNz) % 2, 0);
+  CHECK_EQ((defNy - outNy) % 2, 0);
+  CHECK_EQ((defNx - outNx) % 2, 0);
+
+  const int offsZ = (defNz - outNz) / 2;
+  const int offsY = (defNy - outNy) / 2;
+  const int offsX = (defNx - outNx) / 2;
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      for (int z = 0; z < outNz; ++z) {
+        const T* inSlice  = in  + ((n * inNc  + c) * inNz  + z) * inNy  * inNx;
+        const T* defSlice = def + ( n * defNz + z + offsZ) * defNy * defNx * 2;
+        T*       outP     = out + ((n * outNc + c) * outNz + z) * outNy * outNx;
+        for (int y = 0; y < outNy; ++y) {
+          const T* defP = defSlice + ((y + offsY) * defNx + offsX) * 2;
+          for( int x = 0; x < outNx; ++x) {
+            *outP = Interpolator( inSlice, inNy, inNx, defP[0]+offsetY, defP[1]+offsetX);
+            ++outP;
+            defP += 2;
+          }
+        }
+      }
+    }
+  }
+}
+
+
+template< typename T>
+inline
+void flip2D_x(const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+			  T* out,      int outNb, int outNc, int outNz, int outNy, int outNx) {
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_EQ(inNz, outNz) << "in and out must have same number of elements in z";
+  CHECK_EQ(inNy, outNy) << "in and out must have same number of elements in y";
+  CHECK_EQ(inNx, outNx) << "in and out must have same number of elements in x";
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      for (int z = 0; z < outNz; ++z) {
+        const T* inSlice  = in  + ((n * inNc  + c) * inNz  + z) * inNy  * inNx;
+        T*       outP     = out + ((n * outNc + c) * outNz + z) * outNy * outNx;
+        for (int y = 0; y < outNy; ++y) {
+		  const T* inP = inSlice + (y * inNx) + inNx - 1;
+          for( int x = 0; x < outNx; ++x) {
+            *outP = *inP;
+            ++outP;
+			--inP;
+          }
+        }
+      }
+    }
+  }
+}
+
+
+template< typename T>
+inline
+void flip2D_y(const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+			  T* out,      int outNb, int outNc, int outNz, int outNy, int outNx) {
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_EQ(inNz, outNz) << "in and out must have same number of elements in z";
+  CHECK_EQ(inNy, outNy) << "in and out must have same number of elements in y";
+  CHECK_EQ(inNx, outNx) << "in and out must have same number of elements in x";
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      for (int z = 0; z < outNz; ++z) {
+        const T* inSlice  = in  + ((n * inNc  + c) * inNz  + z) * inNy  * inNx;
+        T*       outP     = out + ((n * outNc + c) * outNz + z) * outNy * outNx;
+        for (int y = 0; y < outNy; ++y) {
+		  const T* inP = inSlice + ((outNy - y - 1) * inNx);
+          for( int x = 0; x < outNx; ++x) {
+            *outP = *inP;
+            ++outP;
+			++inP;
+          }
+        }
+      }
+    }
+  }
+}
+
+
+template< typename T>
+inline
+void flip2D_xy(const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+			   T* out,      int outNb, int outNc, int outNz, int outNy, int outNx) {
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_EQ(inNz, outNz) << "in and out must have same number of elements in z";
+  CHECK_EQ(inNy, outNy) << "in and out must have same number of elements in y";
+  CHECK_EQ(inNx, outNx) << "in and out must have same number of elements in x";
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      for (int z = 0; z < outNz; ++z) {
+        const T* inSlice  = in  + ((n * inNc  + c) * inNz  + z) * inNy  * inNx;
+        T*       outP     = out + ((n * outNc + c) * outNz + z) * outNy * outNx;
+        for (int y = 0; y < outNy; ++y) {
+		  const T* inP = inSlice + ((outNy - y - 1) * inNx) + inNx - 1;
+          for( int x = 0; x < outNx; ++x) {
+            *outP = *inP;
+            ++outP;
+			--inP;
+          }
+        }
+      }
+    }
+  }
+}
+
+
+template< typename T, typename Functor>
+inline
+void transform3D(const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+                 const T* def,int defNb,            int defNz, int defNy, int defNx,
+                 T* out,      int outNb, int outNc, int outNz, int outNy, int outNx,
+                 Functor Interpolator) {
+  CHECK_EQ(inNb, defNb) << "in and deform must have same batch size";
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_GE(defNz, outNz);
+  CHECK_GE(defNy, outNy);
+  CHECK_GE(defNx, outNx);
+  CHECK_EQ((defNz - outNz) % 2, 0);
+  CHECK_EQ((defNy - outNy) % 2, 0);
+  CHECK_EQ((defNx - outNx) % 2, 0);
+
+  const int offsZ = (defNz - outNz) / 2;
+  const int offsY = (defNy - outNy) / 2;
+  const int offsX = (defNx - outNx) / 2;
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      const T* inBlock  = in  + (n * inNc  + c) * inNz * inNy  * inNx;
+      const T* defBlock = def + (n * defNz + offsZ) * defNy * defNx * 3;
+      T*       outP     = out + (n * outNc + c) * outNz * outNy * outNx;
+      for (int z = 0; z < outNz; ++z) {
+        const T* defSlice = defBlock + z * defNy * defNx * 3;
+        for (int y = 0; y < outNy; ++y) {
+          const T* defP = defSlice + ((y + offsY) * defNx + offsX) * 3;
+          for( int x = 0; x < outNx; ++x) {
+            *outP = Interpolator( inBlock, inNz, inNy, inNx, defP[0], defP[1], defP[2]);
+            ++outP;
+            defP += 3;
+          }
+        }
+      }
+    }
+  }
+}
+
+template< typename T, typename Functor>
+inline
+void transform3D_offset(
+    const T* in, int inNb,  int inNc,  int inNz,  int inNy,  int inNx,
+    const T* def,int defNb,            int defNz, int defNy, int defNx,
+                                       int dZ,    int dY,    int dX,
+    T* out,      int outNb, int outNc, int outNz, int outNy, int outNx,
+    Functor Interpolator) {
+  CHECK_EQ(inNb, defNb) << "in and deform must have same batch size";
+  CHECK_EQ(inNb, outNb) << "in and out must have same batch size";
+  CHECK_EQ(inNc, outNc) << "in and out must have same number of channels";
+  CHECK_GE(defNz, outNz);
+  CHECK_GE(defNy, outNy);
+  CHECK_GE(defNx, outNx);
+  CHECK_EQ((defNz - outNz) % 2, 0);
+  CHECK_EQ((defNy - outNy) % 2, 0);
+  CHECK_EQ((defNx - outNx) % 2, 0);
+
+  const int offsZ = (defNz - outNz) / 2;
+  const int offsY = (defNy - outNy) / 2;
+  const int offsX = (defNx - outNx) / 2;
+
+  for (int n = 0; n < outNb; ++n) {
+    for (int c = 0; c < outNc; ++c) {
+      const T* inBlock  = in  + (n * inNc  + c) * inNz * inNy  * inNx;
+      const T* defBlock = def + (n * defNz + offsZ) * defNy * defNx * 3;
+      T*       outP     = out + (n * outNc + c) * outNz * outNy * outNx;
+      for (int z = 0; z < outNz; ++z) {
+        const T* defSlice = defBlock + z * defNy * defNx * 3;
+        for (int y = 0; y < outNy; ++y) {
+          const T* defP = defSlice + ((y + offsY) * defNx + offsX) * 3;
+          for( int x = 0; x < outNx; ++x) {
+            *outP = Interpolator(
+                inBlock, inNz, inNy, inNx,
+                defP[0] + dZ, defP[1] + dY, defP[2] + dX);
+            ++outP;
+            defP += 3;
+          }
+        }
+      }
+    }
+  }
+}
+
+  template<typename TOut, typename TIn>
+  std::vector<TOut> vector_cast(std::vector<TIn> const &vec)
+  {
+    std::vector<TOut> result(vec.size());
+    for (size_t i = 0; i < vec.size(); ++i)
+        result[i] = static_cast<TOut>(vec[i]);
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> floor(std::vector<T> const &vec)
+  {
+    std::vector<T> result(vec.size());
+    for (size_t i = 0; i < vec.size(); ++i) result[i] = std::floor(vec[i]);
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> round(std::vector<T> const &vec)
+  {
+    std::vector<T> result(vec.size());
+    for (size_t i = 0; i < vec.size(); ++i)
+        result[i] = std::floor(vec[i] + 0.5);
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> ceil(std::vector<T> const &vec)
+  {
+    std::vector<T> result(vec.size());
+    for (size_t i = 0; i < vec.size(); ++i) result[i] = std::ceil(vec[i]);
+    return result;
+  }
+
+  template<typename T>
+  T sum(std::vector<T> const &vec)
+  {
+    T result = 0;
+    for (size_t i = 0; i < vec.size(); ++i) result += vec[i];
+    return result;
+  }
+
+  template<typename T>
+  T product(std::vector<T> const &vec)
+  {
+    T result = 1;
+    for (size_t i = 0; i < vec.size(); ++i) result *= vec[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator+(std::vector<T> const &a, std::vector<T> const &b) {
+    CHECK_EQ(a.size(), b.size()) << "Cannot add vectors of different lengths";
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] + b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator+(std::vector<T> const &a, T const &b) {
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] + b;
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator+(T const &a, std::vector<T> const &b) {
+    std::vector<T> result(b.size());
+    for (size_t i = 0; i < b.size(); ++i) result[i] = a + b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator-(std::vector<T> const &a, std::vector<T> const &b) {
+    CHECK_EQ(a.size(), b.size())
+        << "Cannot compute difference of vectors of different lengths";
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] - b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator-(std::vector<T> const &a, T const &b) {
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] - b;
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator-(T const &a, std::vector<T> const &b) {
+    std::vector<T> result(b.size());
+    for (size_t i = 0; i < b.size(); ++i) result[i] = a - b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator*(std::vector<T> const &a, std::vector<T> const &b) {
+    CHECK_EQ(a.size(), b.size())
+        << "Cannot apply elementwise multiplication to vectors of different "
+        << "lengths";
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] * b[i];
+    return result;
+  }
+
+  template<typename T>
+  T dot(std::vector<T> const &a, std::vector<T> const &b) {
+    CHECK_EQ(a.size(), b.size())
+        << "Cannot apply elementwise multiplication to vectors of different "
+        << "lengths";
+    T result = 1;
+    for (size_t i = 0; i < a.size(); ++i) result += a[i] * b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator*(std::vector<T> const &a, T const &b) {
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] * b;
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator*(T const &a, std::vector<T> const &b) {
+    std::vector<T> result(b.size());
+    for (size_t i = 0; i < b.size(); ++i) result[i] = a * b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator/(std::vector<T> const &a, std::vector<T> const &b) {
+    CHECK_EQ(a.size(), b.size())
+        << "Cannot apply elementwise division to vectors of different "
+        << "lengths";
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] / b[i];
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator/(std::vector<T> const &a, T const &b) {
+    std::vector<T> result(a.size());
+    for (size_t i = 0; i < a.size(); ++i) result[i] = a[i] / b;
+    return result;
+  }
+
+  template<typename T>
+  std::vector<T> operator/(T const &a, std::vector<T> const &b) {
+    std::vector<T> result(b.size());
+    for (size_t i = 0; i < b.size(); ++i) result[i] = a / b[i];
+    return result;
+  }
+
+  template<typename T>
+  inline
+  void cropAndFlip(
+      const T* in, int nSamples, int nChannels, std::vector<int> const &inShape,
+      T *out, std::vector<int> const &outShape,
+      std::vector<int> const &offset, std::vector<bool> const &flip,
+      bool padMirror) {
+    CHECK_EQ(inShape.size(), outShape.size())
+        << "in and out must have same dimensionality";
+    CHECK_EQ(offset.size(), outShape.size())
+        << "offset and out must have same dimensionality";
+    CHECK_EQ(flip.size(), outShape.size())
+        << "flip and out must have same dimensionality";
+
+    int nDims = inShape.size();
+    int outSize = product(outShape);
+    std::vector<int> inStrides(nDims, 1);
+    for (int d = nDims - 2; d >= 0; --d)
+        inStrides[d] = inStrides[d + 1] * inShape[d + 1];
+    int inSize = inStrides[0] * inShape[0];
+
+    for (int n = 0; n < nSamples; ++n) {
+      for (int c = 0; c < nChannels; ++c) {
+        const T* inBlock  = in  + (n * nChannels + c) * inSize;
+        T*       outP     = out + (n * nChannels + c) * outSize;
+        for (int i = 0; i < outSize; ++i, ++outP) {
+          const T* inP = inBlock;
+          int tmp = i;
+          bool skip = false;
+          for (int d = nDims - 1; d >= 0 && !skip; --d) {
+            int src = offset[d] +
+                ((flip[d]) ?
+                 (outShape[d] - (tmp % outShape[d]) - 1) : (tmp % outShape[d]));
+            if (src < 0 || src >= inShape[d]) {
+              if (padMirror) {
+                if (src < 0) src = -src;
+                int n = src / (inShape[d] - 1);
+                if (n % 2 == 0) src = src - n * (inShape[d] - 1);
+                else src = (n + 1) * (inShape[d] - 1) - src;
+              }
+              else {
+                *outP = 0;
+                skip = true;
+              }
+            }
+            tmp /= outShape[d];
+            inP += src * inStrides[d];
+          }
+          if (!skip) *outP = *inP;
+        }
+      }
+    }
+  }
+
+}  // namespace caffe
+
+#endif  // CAFFE_VECTOR_HELPERS_HPP_
diff --git a/src/caffe/layer_factory.cpp b/src/caffe/layer_factory.cpp
index e967bd6..e3aa1e5 100644
--- a/src/caffe/layer_factory.cpp
+++ b/src/caffe/layer_factory.cpp
@@ -8,6 +8,7 @@
 #include "caffe/layer.hpp"
 #include "caffe/layer_factory.hpp"
 #include "caffe/layers/conv_layer.hpp"
+#include "caffe/layers/deconv_layer.hpp"
 #include "caffe/layers/lrn_layer.hpp"
 #include "caffe/layers/pooling_layer.hpp"
 #include "caffe/layers/relu_layer.hpp"
@@ -20,6 +21,7 @@
 #include "caffe/layers/cudnn_conv_layer.hpp"
 #include "caffe/layers/cudnn_lcn_layer.hpp"
 #include "caffe/layers/cudnn_lrn_layer.hpp"
+#include "caffe/layers/cudnn_deconv_layer.hpp"
 #include "caffe/layers/cudnn_pooling_layer.hpp"
 #include "caffe/layers/cudnn_relu_layer.hpp"
 #include "caffe/layers/cudnn_sigmoid_layer.hpp"
@@ -36,7 +38,7 @@ namespace caffe {
 // Get convolution layer according to engine.
 template <typename Dtype>
 shared_ptr<Layer<Dtype> > GetConvolutionLayer(
-    const LayerParameter& param) {
+  const LayerParameter& param) {
   ConvolutionParameter conv_param = param.convolution_param();
   ConvolutionParameter_Engine engine = conv_param.engine();
 #ifdef USE_CUDNN
@@ -72,6 +74,45 @@ shared_ptr<Layer<Dtype> > GetConvolutionLayer(
 
 REGISTER_LAYER_CREATOR(Convolution, GetConvolutionLayer);
 
+// Get deconvolution layer according to engine.
+template <typename Dtype>
+shared_ptr<Layer<Dtype> > GetDeconvolutionLayer(
+  const LayerParameter& param) {
+  ConvolutionParameter conv_param = param.convolution_param();
+  ConvolutionParameter_Engine engine = conv_param.engine();
+#ifdef USE_CUDNN
+  bool use_dilation = false;
+  for (int i = 0; i < conv_param.dilation_size(); ++i) {
+    if (conv_param.dilation(i) > 1) {
+      use_dilation = true;
+    }
+  }
+#endif
+  if (engine == ConvolutionParameter_Engine_DEFAULT) {
+    engine = ConvolutionParameter_Engine_CAFFE;
+#ifdef USE_CUDNN
+    if (!use_dilation) {
+      engine = ConvolutionParameter_Engine_CUDNN;
+    }
+#endif
+  }
+  if (engine == ConvolutionParameter_Engine_CAFFE) {
+    return shared_ptr<Layer<Dtype> >(new DeconvolutionLayer<Dtype>(param));
+#ifdef USE_CUDNN
+  } else if (engine == ConvolutionParameter_Engine_CUDNN) {
+    if (use_dilation) {
+      LOG(FATAL) << "CuDNN doesn't support the dilated convolution at Layer "
+                 << param.name();
+    }
+    return shared_ptr<Layer<Dtype> >(new CuDNNDeconvolutionLayer<Dtype>(param));
+#endif
+  } else {
+    LOG(FATAL) << "Layer " << param.name() << " has unknown engine.";
+  }
+}
+
+REGISTER_LAYER_CREATOR(Deconvolution, GetDeconvolutionLayer);
+
 // Get pooling layer according to engine.
 template <typename Dtype>
 shared_ptr<Layer<Dtype> > GetPoolingLayer(const LayerParameter& param) {
diff --git a/src/caffe/layers/apply_deformation_layer.cpp b/src/caffe/layers/apply_deformation_layer.cpp
new file mode 100644
index 0000000..93435b7
--- /dev/null
+++ b/src/caffe/layers/apply_deformation_layer.cpp
@@ -0,0 +1,176 @@
+#include <vector>
+
+#include "caffe/layers/apply_deformation_layer.hpp"
+#include "caffe/util/vector_helper.hpp"
+
+namespace caffe {
+
+template <typename Dtype>
+void ApplyDeformationLayer<Dtype>::LayerSetUp(
+    const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
+  CHECK_EQ(1, top.size());
+  Reshape(bottom, top);
+}
+
+template <typename Dtype>
+void ApplyDeformationLayer<Dtype>::Reshape(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  CHECK_EQ(top.size(), 1);
+  CHECK_EQ(bottom.size(), 2);
+  CHECK_GE(bottom[1]->num_axes(), 4);
+  CHECK_LE(bottom[1]->num_axes(), 5);
+  CHECK_GE(bottom[1]->shape(-1), 2);
+  CHECK_LE(bottom[1]->shape(-1), 3);
+
+  const ApplyDeformationParameter& param =
+      this->layer_param_.apply_deformation_param();
+
+  std::string shapeBlobName = param.output_shape_from();
+
+  if(shapeBlobName == "") {
+    // get output shape from deformation field
+    std::vector<int> outShape = bottom[0]->shape();
+    outShape[2] = bottom[1]->shape(1);
+    outShape[3] = bottom[1]->shape(2);
+    if( bottom[0]->num_axes() == 5 && bottom[1]->num_axes() == 5) {
+      outShape[4] = bottom[1]->shape(3);
+    }
+    top[0]->Reshape( outShape);
+  } else {
+    // search for blob in list all blob names
+    // (the blob_by_name map is not initialized yet)
+    //
+    //    std::cout << "searching for " << shapeBlobName << std::endl;
+    int blobIdx = -1;
+    for( int i = 0; i < this->parent_net()->blob_names().size(); ++i) {
+      // std::cout << "blob " << i << " with name " << this->parent_net()->blob_names()[i] << std::endl;
+      if(  this->parent_net()->blob_names()[i] == shapeBlobName) {
+        blobIdx = i;
+        break;
+      }
+    }
+    if( blobIdx == -1) {
+      LOG(WARNING) << "output_shape_from: Unknown blob name " << shapeBlobName;
+      CHECK( false);
+    }
+    // get output shape from other blob
+    // find blob by name
+    const shared_ptr<Blob<Dtype> > shapeBlob =
+        this->parent_net()->blobs()[blobIdx];
+    std::vector<int> outShape = shapeBlob->shape();
+    outShape[0] = bottom[0]->shape(0);
+    outShape[1] = bottom[0]->shape(1);
+    top[0]->Reshape( outShape);
+  }
+  if (bottom[1]->num_axes() == 4) {
+    n_spatial_axes_ = 2;
+    n_deform_comps_ = 2;
+  } else {
+    n_spatial_axes_ = 3;
+    n_deform_comps_ = bottom[1]->shape(4);
+  }
+}
+
+template <typename Dtype>
+void ApplyDeformationLayer<Dtype>::Forward_cpu(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  const ApplyDeformationParameter& param =
+      this->layer_param_.apply_deformation_param();
+
+  const Dtype* in = bottom[0]->cpu_data();
+  int inNb  = bottom[0]->shape(0);
+  const int inNc  = bottom[0]->shape(1);
+  const int inNz  = (n_spatial_axes_ == 2)? 1 : bottom[0]->shape(-3);
+  const int inNy  = bottom[0]->shape(-2);
+  const int inNx  = bottom[0]->shape(-1);
+
+  const Dtype* def = bottom[1]->cpu_data();
+  const int defNb  = bottom[1]->shape(0);
+  const int defNz  = (n_spatial_axes_ == 2)? 1 : bottom[1]->shape(-4);
+  const int defNy  = bottom[1]->shape(-3);
+  const int defNx  = bottom[1]->shape(-2);
+
+  Dtype* out      = top[0]->mutable_cpu_data();
+  const int outNb = top[0]->shape(0);
+  const int outNc = top[0]->shape(1);
+  const int outNz = (n_spatial_axes_ == 2)? 1 : top[0]->shape(-3);
+  const int outNy = top[0]->shape(-2);
+  const int outNx = top[0]->shape(-1);
+
+  if (n_deform_comps_ == 2
+      && param.interpolation() == "linear"
+      && param.extrapolation() == "mirror") {
+    transform2D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, linear2D_mirror<Dtype>);
+  } else if (n_deform_comps_ == 2
+             && param.interpolation() == "linear"
+             && param.extrapolation() == "zero") {
+    transform2D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, linear2D_zeropad<Dtype>);
+  } else if (n_deform_comps_ == 2
+             && param.interpolation() == "nearest"
+             && param.extrapolation() == "mirror") {
+    transform2D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, nearest2D_mirror<Dtype>);
+  } else if (n_deform_comps_ == 2
+             && param.interpolation() == "nearest"
+             && param.extrapolation() == "zero") {
+    transform2D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, nearest2D_zeropad<Dtype>);
+  } else if (n_deform_comps_ == 3
+      && param.interpolation() == "linear"
+      && param.extrapolation() == "mirror") {
+    transform3D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, linear3D_mirror<Dtype>);
+  } else if (n_deform_comps_ == 3
+             && param.interpolation() == "linear"
+             && param.extrapolation() == "zero") {
+    transform3D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, linear3D_zeropad<Dtype>);
+  } else if (n_deform_comps_ == 3
+             && param.interpolation() == "nearest"
+             && param.extrapolation() == "mirror") {
+    transform3D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, nearest3D_mirror<Dtype>);
+  } else if (n_deform_comps_ == 3
+             && param.interpolation() == "nearest"
+             && param.extrapolation() == "zero") {
+    transform3D(
+        in,   inNb,  inNc,  inNz,  inNy,  inNx,
+        def, defNb,        defNz, defNy, defNx,
+        out, outNb, outNc, outNz, outNy, outNx, nearest3D_zeropad<Dtype>);
+  } else {
+    CHECK(0) << "unsuppported combination: n_deform_comps_=" << n_deform_comps_
+                 << ", interpolation=" << param.interpolation()
+                 << ", exrapolation=" << param.extrapolation();
+  }
+
+}
+
+template <typename Dtype>
+void ApplyDeformationLayer<Dtype>::Backward_cpu(
+    const vector<Blob<Dtype>*>& top,
+    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom){
+ }
+
+INSTANTIATE_CLASS(ApplyDeformationLayer);
+
+REGISTER_LAYER_CLASS(ApplyDeformation);
+
+}  // namespace caffe
diff --git a/src/caffe/layers/concat_layer.cpp b/src/caffe/layers/concat_layer.cpp
index 580bd47..28567e9 100644
--- a/src/caffe/layers/concat_layer.cpp
+++ b/src/caffe/layers/concat_layer.cpp
@@ -1,7 +1,10 @@
+#include <string>
+#include <sstream>
 #include <vector>
 
 #include "caffe/layers/concat_layer.hpp"
 #include "caffe/util/math_functions.hpp"
+#include "caffe/util/vector_helper.hpp"
 
 namespace caffe {
 
@@ -33,43 +36,110 @@ void ConcatLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
   vector<int> top_shape = bottom[0]->shape();
   num_concats_ = bottom[0]->count(0, concat_axis_);
   concat_input_size_ = bottom[0]->count(concat_axis_ + 1);
-  int bottom_count_sum = bottom[0]->count();
   for (int i = 1; i < bottom.size(); ++i) {
     CHECK_EQ(num_axes, bottom[i]->num_axes())
         << "All inputs must have the same #axes.";
     for (int j = 0; j < num_axes; ++j) {
       if (j == concat_axis_) { continue; }
-      CHECK_EQ(top_shape[j], bottom[i]->shape(j))
-          << "All inputs must have the same shape, except at concat_axis.";
+      CHECK_LE(top_shape[j], bottom[i]->shape(j))
+          << "All inputs must have the same or greater shape like the first blob, except at concat_axis.";
     }
-    bottom_count_sum += bottom[i]->count();
     top_shape[concat_axis_] += bottom[i]->shape(concat_axis_);
   }
+  bool shape_changed = (top[0]->shape() != top_shape);
+  needs_cropping_ = false;
   top[0]->Reshape(top_shape);
-  CHECK_EQ(bottom_count_sum, top[0]->count());
   if (bottom.size() == 1) {
     top[0]->ShareData(*bottom[0]);
     top[0]->ShareDiff(*bottom[0]);
+    return;
   }
+
+  // Olaf: compute the borderwidth's for the input blobs
+  // and check whether cropping is needed
+  CHECK_LT( num_axes, 10) << "only 10 axes are supported";
+  for (int i = 0; i < bottom.size(); ++i) {
+    for (int j = 0; j < num_axes; ++j) {
+      if (j == concat_axis_) { continue; }
+      int width_difference = bottom[i]->shape(j) - top_shape[j];
+      if (width_difference != 0)
+      {
+        needs_cropping_ = true;
+
+        int borderwidth = width_difference/2;
+        CHECK_EQ(borderwidth*2, width_difference) <<
+            "width difference must be even! input blob " << i << " axis " << j << " has width " << bottom[i]->shape(j) << " and output blob has width " << top_shape[j] << ". The difference " << width_difference << " is not even.";
+      }
+    }
+  }
+
+  // Olaf: compute the borderwidth's for the input blobs
+  // and check whether cropping is needed
+  CHECK_LT( num_axes, 10) << "only 10 axes are supported";
+  for (int i = 0; i < bottom.size(); ++i) {
+    for (int j = 0; j < num_axes; ++j) {
+      if (j == concat_axis_) { continue; }
+      int width_difference = bottom[i]->shape(j) - top_shape[j];
+      if (width_difference != 0)
+      {
+        needs_cropping_ = true;
+
+        int borderwidth = width_difference/2;
+        CHECK_EQ(borderwidth*2, width_difference) <<
+            "width difference must be even! input blob " << i << " axis " << j << " has width " << bottom[i]->shape(j) << " and output blob has width " << top_shape[j] << ". The difference " << width_difference << " is not even.";
+      }
+    }
+    if (shape_changed && needs_cropping_) {
+      vector<int> outShape( top_shape);
+      outShape[concat_axis_] = bottom[i]->shape(concat_axis_);
+      LOG(INFO) << "bottom blob " << i << " " << toString(bottom[i]->shape())
+                << " will be cropped to " << toString(outShape);
+    }
+  }
+
+
 }
 
 template <typename Dtype>
 void ConcatLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   if (bottom.size() == 1) { return; }
-  Dtype* top_data = top[0]->mutable_cpu_data();
-  int offset_concat_axis = 0;
-  const int top_concat_axis = top[0]->shape(concat_axis_);
-  for (int i = 0; i < bottom.size(); ++i) {
-    const Dtype* bottom_data = bottom[i]->cpu_data();
-    const int bottom_concat_axis = bottom[i]->shape(concat_axis_);
-    for (int n = 0; n < num_concats_; ++n) {
-      caffe_copy(bottom_concat_axis * concat_input_size_,
-          bottom_data + n * bottom_concat_axis * concat_input_size_,
-          top_data + (n * top_concat_axis + offset_concat_axis)
-              * concat_input_size_);
+  if( needs_cropping_ == false) {
+    // original code for concatenation without cropping
+    Dtype* top_data = top[0]->mutable_cpu_data();
+    int offset_concat_axis = 0;
+    const int top_concat_axis = top[0]->shape(concat_axis_);
+    for (int i = 0; i < bottom.size(); ++i) {
+      const Dtype* bottom_data = bottom[i]->cpu_data();
+      const int bottom_concat_axis = bottom[i]->shape(concat_axis_);
+      for (int n = 0; n < num_concats_; ++n) {
+	caffe_copy(bottom_concat_axis * concat_input_size_,
+		   bottom_data + n * bottom_concat_axis * concat_input_size_,
+		   top_data + (n * top_concat_axis + offset_concat_axis)
+		   * concat_input_size_);
+      }
+      offset_concat_axis += bottom_concat_axis;
+    }
+  } else {
+    // concatenation with cropping of input blobs
+    int offset_concat_axis = 0;
+    const int num_axes = bottom[0]->num_axes();
+    for (int i = 0; i < bottom.size(); ++i) {
+      vector<int> bottom_offset(num_axes);
+      for (int j = 0; j < num_axes; ++j) {
+	bottom_offset[j] = (bottom[i]->shape(j) - top[0]->shape(j))/2;
+      }
+      bottom_offset[concat_axis_] = 0;
+      vector<int> copy_shape(num_axes);
+      copy_shape = top[0]->shape();
+      copy_shape[concat_axis_] = bottom[i]->shape(concat_axis_);
+      vector<int> top_offset(num_axes,0);
+      top_offset[concat_axis_] = offset_concat_axis;
+      caffe_copy_subarray( bottom[i]->cpu_data(), bottom[i]->shape(),
+			   top[0]->mutable_cpu_data(), top[0]->shape(),
+			   bottom_offset, copy_shape, top_offset);
+      offset_concat_axis += bottom[i]->shape(concat_axis_);
     }
-    offset_concat_axis += bottom_concat_axis;
   }
 }
 
@@ -77,20 +147,48 @@ template <typename Dtype>
 void ConcatLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
       const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
   if (bottom.size() == 1) { return; }
-  const Dtype* top_diff = top[0]->cpu_diff();
-  int offset_concat_axis = 0;
-  const int top_concat_axis = top[0]->shape(concat_axis_);
-  for (int i = 0; i < bottom.size(); ++i) {
-    const int bottom_concat_axis = bottom[i]->shape(concat_axis_);
-    if (propagate_down[i]) {
-      Dtype* bottom_diff = bottom[i]->mutable_cpu_diff();
-      for (int n = 0; n < num_concats_; ++n) {
-        caffe_copy(bottom_concat_axis * concat_input_size_, top_diff +
-            (n * top_concat_axis + offset_concat_axis) * concat_input_size_,
-            bottom_diff + n * bottom_concat_axis * concat_input_size_);
+  if( needs_cropping_ == false) {
+    // original code for concatenation without cropping
+    const Dtype* top_diff = top[0]->cpu_diff();
+    int offset_concat_axis = 0;
+    const int top_concat_axis = top[0]->shape(concat_axis_);
+    for (int i = 0; i < bottom.size(); ++i) {
+      const int bottom_concat_axis = bottom[i]->shape(concat_axis_);
+      if (propagate_down[i]) {
+	Dtype* bottom_diff = bottom[i]->mutable_cpu_diff();
+	for (int n = 0; n < num_concats_; ++n) {
+	  caffe_copy(bottom_concat_axis * concat_input_size_, top_diff +
+		     (n * top_concat_axis + offset_concat_axis) * concat_input_size_,
+		     bottom_diff + n * bottom_concat_axis * concat_input_size_);
+	}
       }
+      offset_concat_axis += bottom_concat_axis;
+    }
+  } else {
+    // concatenation with cropping
+    int offset_concat_axis = 0;
+    const int num_axes = bottom[0]->num_axes();
+    for (int i = 0; i < bottom.size(); ++i) {
+      // initialize diff blobs to zero (beause gradients are
+      // only available for cropped region)
+      caffe_set(bottom[i]->count(), static_cast<Dtype>(0),
+                bottom[i]->mutable_cpu_diff());
+      // compute offsets and shape of copy region
+      vector<int> bottom_offset(num_axes);
+      for (int j = 0; j < num_axes; ++j) {
+        bottom_offset[j] = (bottom[i]->shape(j) - top[0]->shape(j))/2;
+      }
+      bottom_offset[concat_axis_] = 0;
+      vector<int> copy_shape(num_axes);
+      copy_shape = top[0]->shape();
+      copy_shape[concat_axis_] = bottom[i]->shape(concat_axis_);
+      vector<int> top_offset(num_axes,0);
+      top_offset[concat_axis_] = offset_concat_axis;
+      caffe_copy_subarray( top[0]->cpu_diff(), top[0]->shape(),
+                           bottom[i]->mutable_cpu_diff(), bottom[i]->shape(),
+                           top_offset, copy_shape, bottom_offset);
+      offset_concat_axis += bottom[i]->shape(concat_axis_);
     }
-    offset_concat_axis += bottom_concat_axis;
   }
 }
 
diff --git a/src/caffe/layers/concat_layer.cu b/src/caffe/layers/concat_layer.cu
index a3a0bf6..79a268e 100644
--- a/src/caffe/layers/concat_layer.cu
+++ b/src/caffe/layers/concat_layer.cu
@@ -1,3 +1,4 @@
+#include <string>
 #include <vector>
 
 #include "caffe/layers/concat_layer.hpp"
@@ -24,10 +25,58 @@ __global__ void Concat(const int nthreads, const Dtype* in_data,
   }
 }
 
+
+// Copy (one line per thread) from one array to another, with arbitrary
+// strides in all other dimensions
+template <typename Dtype>
+__global__ void copy_subarray_4D(
+    const int nthreads,    const int shape1, const int shape2, const int shape3,
+    const int src_stride0, const int src_stride1, const int src_stride2,
+    const int dest_stride0, const int dest_stride1, const int dest_stride2,
+    const Dtype* src, Dtype* dest) {
+  CUDA_KERNEL_LOOP(index, nthreads) {
+    int i0 = index / (shape1 * shape2);
+    int r0 = index % (shape1 * shape2);
+    int i1 = r0 / shape2;
+    int i2 = r0 % shape2;
+    int src_start  = i0 * src_stride0  + i1 * src_stride1  + i2 * src_stride2;
+    int dest_start = i0 * dest_stride0 + i1 * dest_stride1 + i2 * dest_stride2;
+    for (int i3 = 0; i3 < shape3; ++i3) {
+        dest[dest_start + i3] = src[src_start + i3];
+    }
+  }
+}
+
+// Copy (one line per thread) from one array to another, with arbitrary
+// strides in all other dimensions
+template <typename Dtype>
+__global__ void copy_subarray_5D(
+    const int nthreads,    const int shape1, const int shape2, const int shape3, const int shape4,
+    const int src_stride0, const int src_stride1, const int src_stride2, const int src_stride3,
+    const int dest_stride0, const int dest_stride1, const int dest_stride2, const int dest_stride3,
+    const Dtype* src, Dtype* dest) {
+  CUDA_KERNEL_LOOP(index, nthreads) {
+    int i0 = index / (shape1 * shape2 * shape3);
+    int r0 = index % (shape1 * shape2 * shape3);
+    int i1 = r0 / (shape2 * shape3);
+    int r1 = r0 % (shape2 * shape3);
+    int i2 = r1 / shape3;
+    int i3 = r1 % shape3;
+    int src_start  = i0 * src_stride0  + i1 * src_stride1  + i2 * src_stride2  + i3 * src_stride3;
+    int dest_start = i0 * dest_stride0 + i1 * dest_stride1 + i2 * dest_stride2 + i3 * dest_stride3;
+    for (int i4 = 0; i4 < shape4; ++i4) {
+        dest[dest_start + i4] = src[src_start + i4];
+    }
+  }
+}
+
+
 template <typename Dtype>
 void ConcatLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   if (bottom.size() == 1) { return; }
+  if( needs_cropping_ == false) {
+    // original code for concatenation without cropping
   Dtype* top_data = top[0]->mutable_gpu_data();
   int offset_concat_axis = 0;
   const int top_concat_axis = top[0]->shape(concat_axis_);
@@ -42,6 +91,74 @@ void ConcatLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
         nthreads, bottom_data, kForward, num_concats_, concat_input_size_,
         top_concat_axis, bottom_concat_axis, offset_concat_axis, top_data);
     offset_concat_axis += bottom_concat_axis;
+    }
+  } else {
+    // concatenation with cropping of input blobs
+    int offset_concat_axis = 0;
+    const int num_axes = bottom[0]->num_axes();
+
+    for (int i = 0; i < bottom.size(); ++i) {
+      // compute offsets and shape of copy region
+      vector<int> bottom_offset(num_axes);
+      for (int j = 0; j < num_axes; ++j) {
+        bottom_offset[j] = (bottom[i]->shape(j) - top[0]->shape(j))/2;
+      }
+      bottom_offset[concat_axis_] = 0;
+      vector<int> copy_shape(num_axes);
+      copy_shape = top[0]->shape();
+      copy_shape[concat_axis_] = bottom[i]->shape(concat_axis_);
+      vector<int> top_offset(num_axes,0);
+      top_offset[concat_axis_] = offset_concat_axis;
+
+      if (num_axes == 4 && concat_axis_ == 1) {
+        // fast code for blobs with 4 axes (2 spatial dims))
+        // one thread per line
+        const int nthreads        = copy_shape[0] * copy_shape[1] * copy_shape[2];
+        const int bottom_stride0  = bottom[i]->shape(1) * bottom[i]->shape(2) * bottom[i]->shape(3);
+        const int bottom_stride1  = bottom[i]->shape(2) * bottom[i]->shape(3);
+        const int bottom_stride2  = bottom[i]->shape(3);
+        const int top_stride0     = top[0]->shape(1) * top[0]->shape(2) * top[0]->shape(3);
+        const int top_stride1     = top[0]->shape(2) * top[0]->shape(3);
+        const int top_stride2     = top[0]->shape(3);
+        const Dtype* bottom_start = bottom[i]->gpu_data() + bottom[i]->offset( bottom_offset);
+        Dtype*       top_start    = top[0]->mutable_gpu_data() + top[0]->offset( top_offset);
+        copy_subarray_4D<Dtype>  // NOLINT_NEXT_LINE(whitespace/operators)
+            <<<CAFFE_GET_BLOCKS(nthreads), CAFFE_CUDA_NUM_THREADS>>>(
+                nthreads,  copy_shape[1], copy_shape[2], copy_shape[3],
+                bottom_stride0,  bottom_stride1,  bottom_stride2,
+                top_stride0,  top_stride1,  top_stride2,
+                bottom_start, top_start);
+      } else {
+	if (num_axes == 5 && concat_axis_ == 1) {
+        // fast code for blobs with 5 axes (3 spatial dims))
+        // one thread per line
+        const int nthreads        = copy_shape[0] * copy_shape[1] * copy_shape[2] * copy_shape[3];
+        const int bottom_stride0  = bottom[i]->shape(1) * bottom[i]->shape(2) * bottom[i]->shape(3)
+	                            * bottom[i]->shape(4);
+        const int bottom_stride1  = bottom[i]->shape(2) * bottom[i]->shape(3) * bottom[i]->shape(4);
+        const int bottom_stride2  = bottom[i]->shape(3) * bottom[i]->shape(4);
+	const int bottom_stride3  = bottom[i]->shape(4);
+        const int top_stride0     = top[0]->shape(1) * top[0]->shape(2) * top[0]->shape(3) * top[0]->shape(4);
+        const int top_stride1     = top[0]->shape(2) * top[0]->shape(3) * top[0]->shape(4);
+        const int top_stride2     = top[0]->shape(3) * top[0]->shape(4);
+	const int top_stride3     = top[0]->shape(4);
+        const Dtype* bottom_start = bottom[i]->gpu_data() + bottom[i]->offset( bottom_offset);
+        Dtype*       top_start    = top[0]->mutable_gpu_data() + top[0]->offset( top_offset);
+        copy_subarray_5D<Dtype>  // NOLINT_NEXT_LINE(whitespace/operators)
+            <<<CAFFE_GET_BLOCKS(nthreads), CAFFE_CUDA_NUM_THREADS>>>(
+	        nthreads,  copy_shape[1], copy_shape[2], copy_shape[3], copy_shape[4],
+                bottom_stride0,  bottom_stride1,  bottom_stride2, bottom_stride3,
+                top_stride0,  top_stride1,  top_stride2, top_stride3,
+                bottom_start, top_start);
+	} else {
+        // slow code for blobs with up to 10 axes
+        caffe_copy_subarray( bottom[i]->gpu_data(), bottom[i]->shape(),
+                             top[0]->mutable_gpu_data(), top[0]->shape(),
+                             bottom_offset, copy_shape, top_offset);
+        }
+      }
+      offset_concat_axis += bottom[i]->shape(concat_axis_);
+    }
   }
 }
 
@@ -49,6 +166,8 @@ template <typename Dtype>
 void ConcatLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
       const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
   if (bottom.size() == 1) { return; }
+  if( needs_cropping_ == false) {
+    // original code for concatenation without cropping
   const Dtype* top_diff = top[0]->gpu_diff();
   int offset_concat_axis = 0;
   const int top_concat_axis = top[0]->shape(concat_axis_);
@@ -65,6 +184,76 @@ void ConcatLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
           top_concat_axis, bottom_concat_axis, offset_concat_axis, bottom_diff);
     }
     offset_concat_axis += bottom_concat_axis;
+    }
+  } else {
+    // concatenation with cropping
+    int offset_concat_axis = 0;
+    const int num_axes = bottom[0]->num_axes();
+    for (int i = 0; i < bottom.size(); ++i) {
+      // initialize diff blobs to zero (beause gradients are
+      // only available for cropped region)
+      caffe_gpu_set(bottom[i]->count(), static_cast<Dtype>(0),
+                    bottom[i]->mutable_gpu_diff());
+      // compute offsets and shape of copy region
+      vector<int> bottom_offset(num_axes);
+      for (int j = 0; j < num_axes; ++j) {
+        bottom_offset[j] = (bottom[i]->shape(j) - top[0]->shape(j))/2;
+      }
+      bottom_offset[concat_axis_] = 0;
+      vector<int> copy_shape(num_axes);
+      copy_shape = top[0]->shape();
+      copy_shape[concat_axis_] = bottom[i]->shape(concat_axis_);
+      vector<int> top_offset(num_axes,0);
+      top_offset[concat_axis_] = offset_concat_axis;
+      if (num_axes == 4 && concat_axis_ == 1) {
+        // fast code for blobs with 4 axes (2 spatial dims))
+        // one thread per line
+        const int nthreads        = copy_shape[0] * copy_shape[1] * copy_shape[2];
+        const int bottom_stride0  = bottom[i]->shape(1) * bottom[i]->shape(2) * bottom[i]->shape(3);
+        const int bottom_stride1  = bottom[i]->shape(2) * bottom[i]->shape(3);
+        const int bottom_stride2  = bottom[i]->shape(3);
+        const int top_stride0     = top[0]->shape(1) * top[0]->shape(2) * top[0]->shape(3);
+        const int top_stride1     = top[0]->shape(2) * top[0]->shape(3);
+        const int top_stride2     = top[0]->shape(3);
+        Dtype*       bottom_start = bottom[i]->mutable_gpu_diff() + bottom[i]->offset( bottom_offset);
+        const Dtype* top_start    = top[0]->gpu_diff() + top[0]->offset( top_offset);
+        copy_subarray_4D<Dtype>  // NOLINT_NEXT_LINE(whitespace/operators)
+            <<<CAFFE_GET_BLOCKS(nthreads), CAFFE_CUDA_NUM_THREADS>>>(
+                nthreads,  copy_shape[1], copy_shape[2], copy_shape[3],
+                top_stride0,  top_stride1,  top_stride2,
+                bottom_stride0,  bottom_stride1,  bottom_stride2,
+                top_start, bottom_start);
+      } else {
+	if (num_axes == 5 && concat_axis_ == 1) {
+        // fast code for blobs with 5 axes (3 spatial dims))
+        // one thread per line
+        const int nthreads        = copy_shape[0] * copy_shape[1] * copy_shape[2] * copy_shape[3];
+        const int bottom_stride0  = bottom[i]->shape(1) * bottom[i]->shape(2) * bottom[i]->shape(3)
+	                            * bottom[i]->shape(4);
+        const int bottom_stride1  = bottom[i]->shape(2) * bottom[i]->shape(3) * bottom[i]->shape(4);
+        const int bottom_stride2  = bottom[i]->shape(3) * bottom[i]->shape(4);
+	const int bottom_stride3  = bottom[i]->shape(4);
+        const int top_stride0     = top[0]->shape(1) * top[0]->shape(2) * top[0]->shape(3) * top[0]->shape(4);
+        const int top_stride1     = top[0]->shape(2) * top[0]->shape(3) * top[0]->shape(4);
+        const int top_stride2     = top[0]->shape(3) * top[0]->shape(4);
+	const int top_stride3     = top[0]->shape(4);
+        Dtype*       bottom_start = bottom[i]->mutable_gpu_diff() + bottom[i]->offset( bottom_offset);
+        const Dtype* top_start    = top[0]->gpu_diff() + top[0]->offset( top_offset);
+        copy_subarray_5D<Dtype>  // NOLINT_NEXT_LINE(whitespace/operators)
+            <<<CAFFE_GET_BLOCKS(nthreads), CAFFE_CUDA_NUM_THREADS>>>(
+		nthreads,  copy_shape[1], copy_shape[2], copy_shape[3], copy_shape[4],
+                top_stride0,  top_stride1,  top_stride2, top_stride3,
+                bottom_stride0,  bottom_stride1,  bottom_stride2, bottom_stride3,
+                top_start, bottom_start);
+	} else {
+        // slow code for blobs with up to 10 axes
+        caffe_copy_subarray( top[0]->gpu_diff(), top[0]->shape(),
+                             bottom[i]->mutable_gpu_diff(), bottom[i]->shape(),
+                             top_offset, copy_shape, bottom_offset);
+        }
+      }
+      offset_concat_axis += bottom[i]->shape(concat_axis_);
+    }
   }
 }
 
diff --git a/src/caffe/layers/create_deformation_layer.cpp b/src/caffe/layers/create_deformation_layer.cpp
new file mode 100644
index 0000000..a3df31c
--- /dev/null
+++ b/src/caffe/layers/create_deformation_layer.cpp
@@ -0,0 +1,621 @@
+#include <vector>
+
+#include "caffe/layers/create_deformation_layer.hpp"
+#include "caffe/util/vector_helper.hpp"
+
+namespace caffe {
+
+template <typename Dtype>
+void CreateDeformationLayer<Dtype>::LayerSetUp(
+    const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
+  const CreateDeformationParameter& param =
+      this->layer_param_.create_deformation_param();
+  CHECK_EQ(1, top.size());
+  CHECK( param.ncomponents() == 2
+         || param.ncomponents() == 3)
+      << "size of last axis (ncomponents) must be "
+      "2 (for 2D deformation vectors) or 3 (for 3D deformation vectors)";
+  if( param.nz() == 0 ) {
+    CHECK( param.ncomponents() == 2)
+        << "size of last axis (ncomponents) must be "
+        "2 for 2D deformation fields";
+  }
+
+  CHECK_LE( param.random_offset_range_from_in_blob_shape()
+            + param.random_offset_range_from_pdf()
+            + (param.random_offset_range_from_ignore_label() > 0), 1) <<
+      "Only one of 'random_offset_range_from_in_blob_shape', 'random_offset_range_from_pdf' or 'random_offset_range_from_ignore_label' can be selected!";
+  //  CHECK( param.has_random_offset_range_from_ignore_label()) << "Not implemented yet";
+
+  batch_size_ = 0;
+  Reshape( bottom, top);
+}
+
+template <typename Dtype>
+void CreateDeformationLayer<Dtype>::Reshape(
+    const vector<Blob<Dtype>*>& bottom,const vector<Blob<Dtype>*>& top) {
+  const CreateDeformationParameter& param =
+      this->layer_param_.create_deformation_param();
+
+  // We only have to reshape the top blob and the internal arrays, if
+  // the batch_size changed
+  int new_batch_size = param.batch_size();
+  if(bottom.size() == 1) {
+    new_batch_size = bottom[0]->shape(0);
+  }
+  if( new_batch_size == batch_size_) return;
+  batch_size_ = new_batch_size;
+
+  // reshape top blob to requested shape
+  vector<int> out_shape;
+  out_shape.push_back(batch_size_);
+  if( param.nz() > 0) out_shape.push_back(param.nz());
+  out_shape.push_back(param.ny());
+  out_shape.push_back(param.nx());
+  out_shape.push_back(param.ncomponents());
+
+  top[0]->Reshape( out_shape);
+
+  n_spatial_axes_ = (param.nz() > 0)? 3 : 2;
+  n_deform_comps_ = param.ncomponents();
+
+  // check if elastic transformation is requested
+  do_elastic_trafo_ = false;
+  if( param.random_elastic_grid_spacing().v_size() > 0) {
+    do_elastic_trafo_ = true;
+    // create the cubic bspline interpolation kernels
+    // for the smooth deformation field
+    if( n_spatial_axes_ == 2) {
+      CHECK_EQ(2, param.random_elastic_grid_spacing().v_size());
+      grid_spacing_z_ = 0;
+      grid_spacing_y_ = param.random_elastic_grid_spacing().v(0);
+      grid_spacing_x_ = param.random_elastic_grid_spacing().v(1);
+      bkernel_z_ = NULL;
+    } else {
+      CHECK_EQ(3, param.random_elastic_grid_spacing().v_size());
+      grid_spacing_z_ = param.random_elastic_grid_spacing().v(0);
+      grid_spacing_y_ = param.random_elastic_grid_spacing().v(1);
+      grid_spacing_x_ = param.random_elastic_grid_spacing().v(2);
+      bkernel_z_ = create_bspline_kernels( grid_spacing_z_);
+    }
+    bkernel_y_ = create_bspline_kernels( grid_spacing_y_);
+    bkernel_x_ = create_bspline_kernels( grid_spacing_x_);
+
+    // setup intermediate arrays for deformation field generation
+    if( n_spatial_axes_ == 2) {
+      int size_y    = top[0]->shape(1);
+      int size_x    = top[0]->shape(2);
+      int ncp_y     = size_y / grid_spacing_y_ + 4;
+      int ncp_x     = size_x / grid_spacing_x_ + 4;
+      rdispl_       = new Dtype[ncp_y * ncp_x];
+      rdispl_shape_ = make_int_vect( ncp_y, ncp_x);
+      tmp1_         = new Dtype[size_y * ncp_x];
+      tmp1_shape_   = make_int_vect( size_y, ncp_x);
+      tmp2_         = NULL;
+    } else {
+      int size_z    = top[0]->shape(1);
+      int size_y    = top[0]->shape(2);
+      int size_x    = top[0]->shape(3);
+      int ncp_z     = size_z / grid_spacing_z_ + 4;
+      int ncp_y     = size_y / grid_spacing_y_ + 4;
+      int ncp_x     = size_x / grid_spacing_x_ + 4;
+      rdispl_       = new Dtype[ncp_z * ncp_y * ncp_x];
+      rdispl_shape_ = make_int_vect( ncp_z, ncp_y, ncp_x);
+      tmp1_         = new Dtype[size_z * ncp_y * ncp_x];
+      tmp1_shape_   = make_int_vect( size_z, ncp_y, ncp_x);
+      tmp2_         = new Dtype[size_z * size_y * ncp_x];
+      tmp2_shape_   = make_int_vect( size_z, size_y, ncp_x);
+    }
+  }
+
+  // get the relative element_size in z-direction. Needed for rotation
+  voxel_relsize_z_ = param.voxel_relsize_z();
+
+  // get the range for the rotation angles
+  //
+  if( param.random_rotate_from().v_size() > 0) {
+    if( n_deform_comps_ == 2) {
+      // 2 component displacement
+      CHECK_EQ(1, param.random_rotate_from().v_size()) << "for 2 components "
+          "the rotation angle must be a single scalar";
+      CHECK_EQ(1, param.random_rotate_to().v_size()) << "for 2 components "
+          "the rotation angle must be a single scalar";
+      rot_from_ = make_vec<float>(param.random_rotate_from().v(0), 0, 0);
+      rot_to_   = make_vec<float>(param.random_rotate_to().v(0), 0, 0);
+    } else {
+      // 3 component displacement
+      CHECK_EQ(3, param.random_rotate_from().v_size()) << "for 3 components "
+          "the rotation angle must be a 3 component vector";
+      CHECK_EQ(3, param.random_rotate_to().v_size()) << "for 3 components "
+          "the rotation angle must be a 3 component vector";
+      rot_from_ = make_vec<float>(param.random_rotate_from().v(0),
+                                  param.random_rotate_from().v(1),
+                                  param.random_rotate_from().v(2));
+      rot_to_   = make_vec<float>(param.random_rotate_to().v(0),
+                                  param.random_rotate_to().v(1),
+                                  param.random_rotate_to().v(2));
+    }
+  } else {
+    rot_from_ = make_vec<float>(0, 0, 0);
+    rot_to_   = make_vec<float>(0, 0, 0);
+  }
+
+  // get the range for the offsets
+  //
+  if( param.random_offset_from().v_size() > 0) {
+    if( n_deform_comps_ == 2) {
+      // 2 component displacement
+      CHECK_EQ(2, param.random_offset_from().v_size()) << "for 2 components "
+          "the offset must be a 2 component vector";
+      CHECK_EQ(2, param.random_offset_to().v_size()) << "for 2 components "
+          "the offset must be a 2 component vector";
+      offset_from_ = make_vec<float>(0,
+                                     param.random_offset_from().v(0),
+                                     param.random_offset_from().v(1));
+      offset_to_   = make_vec<float>(0,
+                                     param.random_offset_to().v(0),
+                                     param.random_offset_to().v(1));
+    } else {
+      // 3 component displacement
+      CHECK_EQ(3, param.random_offset_from().v_size()) << "for 3 components "
+          "the offset must be a 3 component vector";
+      CHECK_EQ(3, param.random_offset_to().v_size()) << "for 2 components "
+          "the offset must be a 3 component vector";
+      offset_from_ = make_vec<float>(param.random_offset_from().v(0),
+                                     param.random_offset_from().v(1),
+                                     param.random_offset_from().v(2));
+      offset_to_   = make_vec<float>(param.random_offset_to().v(0),
+                                     param.random_offset_to().v(1),
+                                     param.random_offset_to().v(2));
+    }
+  } else {
+    offset_from_ = make_vec<float>(0, 0, 0);
+    offset_to_   = make_vec<float>(0, 0, 0);
+  }
+
+
+  // get the random mirror flags
+  //
+  if( param.random_mirror_flag().v_size() > 0) {
+    if( n_deform_comps_ == 2) {
+      // 2 component displacement
+      CHECK_EQ(2, param.random_mirror_flag().v_size()) << "for 2 components "
+          "the mirror flag must be a 2 component vector";
+      mirror_flag_ = make_vec<int>(0,
+                                   param.random_mirror_flag().v(0),
+                                   param.random_mirror_flag().v(1));
+    } else {
+      // 3 component displacement
+      CHECK_EQ(3,  param.random_mirror_flag().v_size()) << "for 3 components "
+          "the mirror flag must be a 3 component vector";
+      mirror_flag_ = make_vec<int>(param.random_mirror_flag().v(0),
+                                   param.random_mirror_flag().v(1),
+                                   param.random_mirror_flag().v(2));
+    }
+  } else {
+    mirror_flag_ = make_vec<int>(0, 0, 0);
+  }
+
+
+}
+
+template <typename Dtype>
+void CreateDeformationLayer<Dtype>::Forward_cpu(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  const CreateDeformationParameter& param =
+      this->layer_param_.create_deformation_param();
+  //  std::cout << "CreateDeformationLayer<Dtype>::Forward_cpu\n";
+
+  if( do_elastic_trafo_) {
+    if (n_spatial_axes_ == 2) {
+      const int top_ny    = top[0]->shape(1);
+      const int top_nx    = top[0]->shape(2);
+      const int top_ncomp = top[0]->shape(3);
+      for (int n = 0; n < top[0]->shape(0); ++n) {
+        for (int c = 0; c < top_ncomp; ++c) {
+          //          std::cout << "n=" << n << ", c=" << c <<std::endl;
+          // create random displacements on grid
+          caffe_rng_gaussian(
+              rdispl_shape_[0] * rdispl_shape_[1],
+              Dtype(0), Dtype(param.random_elastic_deform_magnitude().v(c)),
+              rdispl_);
+          // scale up in y direction with bspline kernel
+          cubic_bspline_interpolation(
+              rdispl_, rdispl_shape_[1], rdispl_shape_[0],
+              1, rdispl_shape_[1],
+              tmp1_, tmp1_shape_[0],
+              1, tmp1_shape_[1],
+              bkernel_y_, grid_spacing_y_);
+          // scale up in x direction with bspline kernel
+          cubic_bspline_interpolation(
+              tmp1_, tmp1_shape_[0], tmp1_shape_[1],
+              tmp1_shape_[1], 1,
+              top[0]->mutable_cpu_data() + top[0]->offset(make_int_vect(n,0,0,c)),
+              top_nx,
+              top_nx * top_ncomp, top_ncomp,
+              bkernel_x_, grid_spacing_x_);
+        }
+        // add the unit transform
+        Dtype* p = top[0]->mutable_cpu_data()
+            + top[0]->offset(make_int_vect(n,0,0,0));
+        for (int y = 0; y < top_ny; ++y) {
+          for (int x = 0; x < top_nx; ++x) {
+            p[0] += y;
+            p[1] += x;
+            p += 2;
+          }
+        }
+
+      }
+    } else {
+      const int top_nz    = top[0]->shape(1);
+      const int top_ny    = top[0]->shape(2);
+      const int top_nx    = top[0]->shape(3);
+      const int top_ncomp = top[0]->shape(4);
+      for (int n = 0; n < top[0]->shape(0); ++n) {
+        for( int c = 0; c < top_ncomp; ++c) {
+          //         std::cout << "n=" << n << ", c=" << c <<std::endl;
+          // create random displacements on grid
+          caffe_rng_gaussian(
+              rdispl_shape_[0] * rdispl_shape_[1] * rdispl_shape_[2],
+              Dtype(0), Dtype(param.random_elastic_deform_magnitude().v(c)),
+              rdispl_);
+          //
+          // scale up in z direction with bspline kernel
+          const Dtype* in      = rdispl_;
+          int in_n_lines       = rdispl_shape_[1] * rdispl_shape_[2];
+          int in_n_elem        = rdispl_shape_[0];
+          int in_stride_lines  = 1;
+          int in_stride_elem   = rdispl_shape_[1] * rdispl_shape_[2];
+          Dtype* out           = tmp1_;
+          int out_n_elem       = tmp1_shape_[0];
+          int out_stride_lines = 1;
+          int out_stride_elem  = tmp1_shape_[1] * tmp1_shape_[2];
+          cubic_bspline_interpolation(
+              in, in_n_lines, in_n_elem, in_stride_lines, in_stride_elem,
+              out, out_n_elem, out_stride_lines, out_stride_elem,
+              bkernel_z_, grid_spacing_z_);
+          //
+          // scale up in y direction with bspline kernel
+          for (int z = 0; z < top_nz; ++z) {
+            in               = tmp1_ + z * (tmp1_shape_[1] * tmp1_shape_[2]);
+            in_n_lines       = tmp1_shape_[2];
+            in_n_elem        = tmp1_shape_[1];
+            in_stride_lines  = 1;
+            in_stride_elem   = tmp1_shape_[2];
+            out              = tmp2_ + z * (tmp2_shape_[1] * tmp2_shape_[2]);
+            out_n_elem       = tmp2_shape_[1];
+            out_stride_lines = 1;
+            out_stride_elem  = tmp2_shape_[2];
+            cubic_bspline_interpolation(
+                in, in_n_lines, in_n_elem, in_stride_lines, in_stride_elem,
+                out, out_n_elem, out_stride_lines, out_stride_elem,
+                bkernel_y_, grid_spacing_y_);
+          }
+          // scale up in x direction with bspline kernel
+          in               = tmp2_;
+          in_n_lines       = tmp2_shape_[0] * tmp2_shape_[1];
+          in_n_elem        = tmp2_shape_[2];
+          in_stride_lines  = tmp2_shape_[2];
+          in_stride_elem   = 1;
+          out              = top[0]->mutable_cpu_data()
+              + top[0]->offset(make_int_vect(n,0,0,0,c));
+          out_n_elem       = top_nx;
+          out_stride_lines = top_nx * top_ncomp;
+          out_stride_elem  = top_ncomp;
+          //        std::cout << "scale in x-direction\n"
+          //            "offset: " << top[0]->offset(make_int_vect(n,0,0,0,c)) << "\n";
+          cubic_bspline_interpolation(
+              in, in_n_lines, in_n_elem, in_stride_lines, in_stride_elem,
+              out, out_n_elem, out_stride_lines, out_stride_elem,
+              bkernel_x_, grid_spacing_x_);
+        }
+        // add the unit transform
+        Dtype* p = top[0]->mutable_cpu_data()
+            + top[0]->offset(make_int_vect(n,0,0,0,0));
+        for (int z = 0; z < top_nz; ++z) {
+          for (int y = 0; y < top_ny; ++y) {
+            for (int x = 0; x < top_nx; ++x) {
+              p[0] += z;
+              p[1] += y;
+              p[2] += x;
+              p += 3;
+            }
+          }
+        }
+      }
+    }
+  } else {
+    // no elastic trafo requested. Fill deformation field with
+    // identity transform
+    if( n_spatial_axes_ == 2) {
+      // 2D, 2 component deformation field
+      Dtype* p = top[0]->mutable_cpu_data();
+      for (int n = 0; n < top[0]->shape(0); ++n) {
+        for (int y = 0; y < top[0]->shape(1); ++y) {
+          for (int x = 0; x < top[0]->shape(2); ++x) {
+            p[0] = y;
+            p[1] = x;
+            p += 2;
+          }
+        }
+      }
+    } else {
+      if (n_deform_comps_ == 2) {
+        // 3D, 2 component deformation field
+        Dtype* p = top[0]->mutable_cpu_data();
+        for (int n = 0; n < top[0]->shape(0); ++n) {
+          for (int z = 0; z < top[0]->shape(1); ++z) {
+            for (int y = 0; y < top[0]->shape(2); ++y) {
+              for (int x = 0; x < top[0]->shape(3); ++x) {
+                p[0] = y;
+                p[1] = x;
+                p += 2;
+              }
+            }
+          }
+        }
+      } else {
+        // 3D, 3 component deformation field
+        Dtype* p = top[0]->mutable_cpu_data();
+        for (int n = 0; n < top[0]->shape(0); ++n) {
+          for (int z = 0; z < top[0]->shape(1); ++z) {
+            for (int y = 0; y < top[0]->shape(2); ++y) {
+              for (int x = 0; x < top[0]->shape(3); ++x) {
+                p[0] = z;
+                p[1] = y;
+                p[2] = x;
+                p += 3;
+              }
+            }
+          }
+        }
+      }
+    }
+  }
+
+  // find out the bottom shape
+  int bottom_nz = 1;
+  int bottom_ny = 1;
+  int bottom_nx = 1;
+
+  if( bottom.size() == 0) {
+    // If bottom shape is unkown, we assume the same shape as for top
+    if (n_spatial_axes_ == 2) {
+      bottom_ny = top[0]->shape(1);
+      bottom_nx = top[0]->shape(2);
+    } else {
+      bottom_nz = top[0]->shape(1);
+      bottom_ny = top[0]->shape(2);
+      bottom_nx = top[0]->shape(3);
+    }
+  } else {
+    // if a bottom blob is there. Take its shape
+    if (n_spatial_axes_ == 2) {
+      bottom_ny = bottom[0]->shape(2);
+      bottom_nx = bottom[0]->shape(3);
+    } else {
+      bottom_nz = bottom[0]->shape(2);
+      bottom_ny = bottom[0]->shape(3);
+      bottom_nx = bottom[0]->shape(4);
+    }
+  }
+
+  // top shape for convenience
+  int top_nz = 1;
+  int top_ny = 1;
+  int top_nx = 1;
+  if (n_spatial_axes_ == 2) {
+    top_ny = top[0]->shape(1);
+    top_nx = top[0]->shape(2);
+  } else {
+    top_nz = top[0]->shape(1);
+    top_ny = top[0]->shape(2);
+    top_nx = top[0]->shape(3);
+  }
+
+
+  // for all images in the batch
+  for (int batchIdx = 0; batchIdx < top[0]->shape(0); ++batchIdx) {
+    // create the 4x4 transformation matrix (homgogenous coordinates)
+    // first draw the random rotation angle, offset and mirrorfactor
+    vector<float> angle(3);
+    vector<float> offset(3);
+    vector<float> mirrorfactor(3);
+    for (int i = 0; i < 3; ++i) {
+      caffe_rng_uniform( 1, rot_from_[i], rot_to_[i], &angle[i]);
+      caffe_rng_uniform( 1, offset_from_[i], offset_to_[i], &offset[i]);
+      if( mirror_flag_[i] == 1) {
+        int b;
+        caffe_rng_bernoulli( 1, 0.5, &b);
+        mirrorfactor[i] = (b==0)? -1 : 1;
+      } else {
+        mirrorfactor[i] = 1;
+      }
+    }
+
+    // if a offset sampling from input shape is requested, do it
+    if( param.random_offset_range_from_in_blob_shape()) {
+      int z = caffe_rng_rand() % bottom_nz;
+      int y = caffe_rng_rand() % bottom_ny;
+      int x = caffe_rng_rand() % bottom_nx;
+
+      offset[0] += z - float(bottom_nz - 1) / 2;
+      offset[1] += y - float(bottom_ny - 1) / 2;
+      offset[2] += x - float(bottom_nx - 1) / 2;
+      //std::cout << "offset " << toString(offset) << std::endl;
+    }
+
+    // if a probability map for offsets is given, use it to sample an
+    // offset
+    if( param.random_offset_range_from_pdf()) {
+      size_t pdf_size = bottom[0]->count() / bottom[0]->shape(0);
+      const Dtype* pdf = bottom[0]->cpu_data() + batchIdx * pdf_size;
+
+      std::vector<Dtype> cdf(pdf_size);
+      caffe_cpu_cumsum( pdf_size, pdf, cdf.data());
+      int x, y, z;
+      caffe_rand_pos_arbitrary_cdf( cdf.data(), bottom_nz, bottom_ny, bottom_nx,
+                                    &z, &y, &x);
+      offset[0] += z - float(bottom_nz - 1) / 2;
+      offset[1] += y - float(bottom_ny - 1) / 2;
+      offset[2] += x - float(bottom_nx - 1) / 2;
+      //  std::cout << "offset " << toString(offset) << std::endl;
+   }
+
+    // if a label map for offsets is given, use non-ignore labels to
+    // sample an offset
+    if( param.random_offset_range_from_ignore_label() > 0) {
+      size_t labels_size = bottom[0]->count() / bottom[0]->shape(0);
+      const Dtype* labels = bottom[0]->cpu_data() + batchIdx * labels_size;
+      int ignore_label = param.random_offset_range_from_ignore_label();
+
+      // compute cummulative sum of non-ignore-label-pdf
+      std::vector<Dtype> cdf(labels_size);
+      Dtype cumsum = 0;
+      for (size_t i = 0; i < labels_size; ++i) {
+        cumsum += (int(labels[i]) != ignore_label);
+        cdf[i] = cumsum;
+      }
+      //     std::cout << "cumsum = " << cumsum << std::endl;
+      int x, y, z;
+      caffe_rand_pos_arbitrary_cdf( cdf.data(), bottom_nz, bottom_ny, bottom_nx,
+                                    &z, &y, &x);
+      offset[0] += z - float(bottom_nz - 1) / 2;
+      offset[1] += y - float(bottom_ny - 1) / 2;
+      offset[2] += x - float(bottom_nx - 1) / 2;
+      //  std::cout << "offset " << toString(offset) << std::endl;
+   }
+
+    // start with the unit matrix
+    vector<float> M = make_vec<float>(
+        1,0,0,0,
+        0,1,0,0,
+        0,0,1,0,
+        0,0,0,1);
+
+    // shift target center to origin
+    M = m_shift3D<float>( -float(top_nz) / 2,
+                          -float(top_ny) / 2,
+                          -float(top_nx) / 2, M);
+
+    // scale to cubic voxels
+    M = m_scale3D<float>( voxel_relsize_z_, 1, 1, M);
+
+    // do the rotation
+    M = m_rotate3D<float>( angle[0], angle[1], angle[2], M);
+
+    // scale back to original voxel size
+    M = m_scale3D<float>( 1.0/voxel_relsize_z_, 1, 1, M);
+
+    // shift origin to src center
+    M = m_shift3D<float>( float(bottom_nz) / 2,
+                          float(bottom_ny) / 2,
+                          float(bottom_nx) / 2, M);
+
+    // apply the offset
+    M = m_shift3D<float>( offset[0], offset[1], offset[2], M);
+
+    //    std::cout << "resulting matrix:\n" << Array2DtoString( M.data(), 4, 4);
+
+
+    // transform all deformation vectors with the resulting matrix
+    size_t out_data_size = top[0]->count() / top[0]->shape(0);
+    Dtype* out_data = top[0]->mutable_cpu_data() + batchIdx * out_data_size;
+    if (n_deform_comps_ == 2) {
+      float a11 = M[5]; float a12 = M[6];  float b1 = M[7];
+      float a21 = M[9]; float a22 = M[10]; float b2 = M[11];
+      Dtype* p = out_data;
+      size_t n_vectors = out_data_size / 2;
+      for (int i = 0; i < n_vectors; ++i) {
+        float v1 = a11*p[0] + a12*p[1] + b1;
+        float v2 = a21*p[0] + a22*p[1] + b2;
+        p[0] = v1;
+        p[1] = v2;
+        p += 2;
+      }
+    } else {
+      float a11 = M[0]; float a12 = M[1]; float a13 = M[2]; float b1 = M[3];
+      float a21 = M[4]; float a22 = M[5]; float a23 = M[6]; float b2 = M[7];
+      float a31 = M[8]; float a32 = M[9]; float a33 = M[10]; float b3 = M[11];
+      Dtype* p = out_data;
+      size_t n_vectors = out_data_size / 3;
+      for (int i = 0; i < n_vectors; ++i) {
+        float v1 = a11*p[0] + a12*p[1] + a13*p[2] + b1;
+        float v2 = a21*p[0] + a22*p[1] + a23*p[2] + b2;
+        float v3 = a31*p[0] + a32*p[1] + a33*p[2] + b3;
+        p[0] = v1;
+        p[1] = v2;
+        p[2] = v3;
+        p += 3;
+      }
+    }
+  }
+
+}
+
+template <typename Dtype>
+Dtype* CreateDeformationLayer<Dtype>::create_bspline_kernels(int nb) {
+  Dtype* b0123 = new Dtype[4*nb];
+  Dtype* b0 = b0123;
+  Dtype* b1 = b0123 + nb;
+  Dtype* b2 = b0123 + 2 * nb;
+  Dtype* b3 = b0123 + 3 * nb;
+
+  for (int i = 0; i < nb; ++i) {
+    Dtype x = Dtype(i) / nb;
+    b0[i] = 1./6 * ( - x*x*x +  3*x*x - 3*x + 1);
+    b1[i] = 1./6 * ( 3*x*x*x + -6*x*x       + 4);
+    b2[i] = 1./6 * (-3*x*x*x +  3*x*x + 3*x + 1);
+    b3[i] = 1./6 * x*x*x;
+  }
+  return b0123;
+}
+
+
+template <typename Dtype>
+void CreateDeformationLayer<Dtype>::cubic_bspline_interpolation(
+    const Dtype* in, int in_n_lines, int in_n_elem,
+    int in_stride_lines, int in_stride_elem,
+    Dtype* out, int out_n_elem, int out_stride_lines, int out_stride_elem,
+    const Dtype* b0123, int nb) {
+  const Dtype* b0 = b0123;
+  const Dtype* b1 = b0123 + nb;
+  const Dtype* b2 = b0123 + 2 * nb;
+  const Dtype* b3 = b0123 + 3 * nb;
+//  std::cout << "cubic_bspline_interpolation() \n"
+//      << "in_n_lines,      " << in_n_lines << std::endl
+//      << "in_n_elem,       " << in_n_elem << std::endl
+//      << "in_stride_lines, " << in_stride_lines << std::endl
+//      << "in_stride_elem,  " << in_stride_elem << std::endl
+//      << "out_n_elem,      " << out_n_elem << std::endl
+//      << "out_stride_lines," << out_stride_lines << std::endl
+//      << "out_stride_elem, " << out_stride_elem << std::endl
+//      << "nb               " << nb               << std::endl;
+  for (int line_i = 0; line_i < in_n_lines; ++line_i) {
+    int out_elem_i = 0;
+    for (int elem_i = 0; elem_i < in_n_elem - 3; ++elem_i) {
+      int in_offs = line_i * in_stride_lines + elem_i * in_stride_elem;
+      Dtype w0 = in[in_offs];
+      Dtype w1 = in[in_offs + in_stride_elem];
+      Dtype w2 = in[in_offs + 2 * in_stride_elem];
+      Dtype w3 = in[in_offs + 3 * in_stride_elem];
+      Dtype* out_p = out + line_i * out_stride_lines
+          + elem_i * (out_stride_elem * nb);
+      for( int i = 0; i < nb && out_elem_i < out_n_elem; ++i, ++out_elem_i) {
+        *out_p =  w0 * b0[i] + w1 * b1[i] + w2 * b2[i] + w3 * b3[i];
+        out_p += out_stride_elem;
+      }
+    }
+  }
+}
+
+
+
+
+INSTANTIATE_CLASS(CreateDeformationLayer);
+
+REGISTER_LAYER_CLASS(CreateDeformation);
+
+}  // namespace caffe
diff --git a/src/caffe/layers/cudnn_conv_layer.cpp b/src/caffe/layers/cudnn_conv_layer.cpp
index 1987fb0..7562e05 100644
--- a/src/caffe/layers/cudnn_conv_layer.cpp
+++ b/src/caffe/layers/cudnn_conv_layer.cpp
@@ -59,20 +59,22 @@ void CuDNNConvolutionLayer<Dtype>::LayerSetUp(
   bias_offset_ = (this->num_output_ / this->group_);
 
   // Create filter descriptor.
-  const int* kernel_shape_data = this->kernel_shape_.cpu_data();
-  const int kernel_h = kernel_shape_data[0];
-  const int kernel_w = kernel_shape_data[1];
-  cudnn::createFilterDesc<Dtype>(&filter_desc_,
-      this->num_output_ / this->group_, this->channels_ / this->group_,
-      kernel_h, kernel_w);
+  vector<int> kernel_shape(this->kernel_shape_.shape(0) + 2);
+  int* kernel_shape_data = this->kernel_shape_.mutable_cpu_data();
+  for (int d = 0; d < kernel_shape.size() - 2; d++) {
+      kernel_shape[d + 2] = kernel_shape_data[d];
+  }
+  kernel_shape[0] = this->num_output_ / this->group_;
+  kernel_shape[1] = this->channels_ / this->group_;
+  cudnn::createNdFilterDesc<Dtype>(&filter_desc_,kernel_shape);
 
   // Create tensor descriptor(s) for data and corresponding convolution(s).
   for (int i = 0; i < bottom.size(); i++) {
     cudnnTensorDescriptor_t bottom_desc;
-    cudnn::createTensor4dDesc<Dtype>(&bottom_desc);
+    cudnn::createTensorDesc<Dtype>(&bottom_desc);
     bottom_descs_.push_back(bottom_desc);
     cudnnTensorDescriptor_t top_desc;
-    cudnn::createTensor4dDesc<Dtype>(&top_desc);
+    cudnn::createTensorDesc<Dtype>(&top_desc);
     top_descs_.push_back(top_desc);
     cudnnConvolutionDescriptor_t conv_desc;
     cudnn::createConvolutionDesc<Dtype>(&conv_desc);
@@ -81,7 +83,7 @@ void CuDNNConvolutionLayer<Dtype>::LayerSetUp(
 
   // Tensor descriptor for bias.
   if (this->bias_term_) {
-    cudnn::createTensor4dDesc<Dtype>(&bias_desc_);
+    cudnn::createTensorDesc<Dtype>(&bias_desc_);
   }
 
   handles_setup_ = true;
@@ -91,41 +93,48 @@ template <typename Dtype>
 void CuDNNConvolutionLayer<Dtype>::Reshape(
     const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
   ConvolutionLayer<Dtype>::Reshape(bottom, top);
+/*
   CHECK_EQ(2, this->num_spatial_axes_)
       << "CuDNNConvolution input must have 2 spatial axes "
       << "(e.g., height and width). "
       << "Use 'engine: CAFFE' for general ND convolution.";
+*/
   bottom_offset_ = this->bottom_dim_ / this->group_;
   top_offset_ = this->top_dim_ / this->group_;
-  const int height = bottom[0]->shape(this->channel_axis_ + 1);
-  const int width = bottom[0]->shape(this->channel_axis_ + 2);
-  const int height_out = top[0]->shape(this->channel_axis_ + 1);
-  const int width_out = top[0]->shape(this->channel_axis_ + 2);
-  const int* pad_data = this->pad_.cpu_data();
-  const int pad_h = pad_data[0];
-  const int pad_w = pad_data[1];
-  const int* stride_data = this->stride_.cpu_data();
-  const int stride_h = stride_data[0];
-  const int stride_w = stride_data[1];
 
   // Specify workspace limit for kernels directly until we have a
   // planning strategy and a rewrite of Caffe's GPU memory mangagement
   size_t workspace_limit_bytes = 8*1024*1024;
 
   for (int i = 0; i < bottom.size(); i++) {
-    cudnn::setTensor4dDesc<Dtype>(&bottom_descs_[i],
-        this->num_,
-        this->channels_ / this->group_, height, width,
-        this->channels_ * height * width,
-        height * width, width, 1);
-    cudnn::setTensor4dDesc<Dtype>(&top_descs_[i],
-        this->num_,
-        this->num_output_ / this->group_, height_out, width_out,
-        this->num_output_ * this->out_spatial_dim_,
-        this->out_spatial_dim_, width_out, 1);
-    cudnn::setConvolutionDesc<Dtype>(&conv_descs_[i], bottom_descs_[i],
-        filter_desc_, pad_h, pad_w,
-        stride_h, stride_w);
+    vector<int> bottom_shape(bottom[i]->shape());
+    bottom_shape[1] /= this->group_; // set channel_axis_ instead of 1
+    vector<int> bottom_tensor_stride(bottom[i]->shape().size(), 1);
+    for (int j = bottom[i]->shape().size()-2; j >= 0; --j) {
+        bottom_tensor_stride[j] = bottom[i]->shape()[j+1] * bottom_tensor_stride[j
+            +1];
+    }
+    cudnn::setTensorNdDesc<Dtype>(&bottom_descs_[i],bottom_shape,bottom_tensor_stride);
+    vector<int> top_shape(top[i]->shape());
+    top_shape[1] /= this->group_; // set channel_axis_ instead of 1
+    vector<int> top_tensor_stride(top[i]->shape().size(), 1);
+    for (int j = top[i]->shape().size()-2; j >= 0; --j) {
+        top_tensor_stride[j] = top[i]->shape()[j+1] * top_tensor_stride[j
+            +1];
+    }
+    cudnn::setTensorNdDesc<Dtype>(&top_descs_[i],top_shape,top_tensor_stride);
+    vector<int> pad_shape(this->pad_.count());
+    int* pad_shape_data = this->pad_.mutable_cpu_data();
+    for (int d = 0; d < pad_shape.size(); d++) {
+        pad_shape[d] = pad_shape_data[d];
+    }
+    vector<int> stride_shape(this->stride_.count());
+    int* stride_shape_data = this->stride_.mutable_cpu_data();
+    for (int d = 0; d < stride_shape.size(); d++) {
+        stride_shape[d] = stride_shape_data[d];
+    }
+    cudnn::setNdConvolutionDesc<Dtype>(&conv_descs_[i], bottom_descs_[i],
+                                      filter_desc_, pad_shape, stride_shape);
 
     // choose forward and backward algorithms + workspace(s)
     CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(handle_[0],
@@ -226,8 +235,9 @@ void CuDNNConvolutionLayer<Dtype>::Reshape(
 
   // Tensor descriptor for bias.
   if (this->bias_term_) {
-    cudnn::setTensor4dDesc<Dtype>(&bias_desc_,
-        1, this->num_output_ / this->group_, 1, 1);
+      vector<int> bias_shape(top[0]->shape().size(),1);
+      bias_shape[1] = this->num_output_ / this->group_; // set channel_axis_ instead of 1
+      cudnn::setTensorNdDesc<Dtype>(&bias_desc_,bias_shape);
   }
 }
 
diff --git a/src/caffe/layers/cudnn_conv_layer.cu b/src/caffe/layers/cudnn_conv_layer.cu
index 8bc5346..981b136 100644
--- a/src/caffe/layers/cudnn_conv_layer.cu
+++ b/src/caffe/layers/cudnn_conv_layer.cu
@@ -1,6 +1,5 @@
 #ifdef USE_CUDNN
 #include <vector>
-
 #include "caffe/layers/cudnn_conv_layer.hpp"
 
 namespace caffe {
diff --git a/src/caffe/layers/cudnn_deconv_layer.cpp b/src/caffe/layers/cudnn_deconv_layer.cpp
new file mode 100644
index 0000000..2c379db
--- /dev/null
+++ b/src/caffe/layers/cudnn_deconv_layer.cpp
@@ -0,0 +1,274 @@
+#ifdef USE_CUDNN
+#include <algorithm>
+#include <vector>
+
+#include "caffe/layers/cudnn_deconv_layer.hpp"
+
+namespace caffe {
+
+// Set to three for the benefit of the backward pass, which
+// can use separate streams for calculating the gradient w.r.t.
+// bias, filter weights, and bottom data for each group independently
+#define CUDNN_STREAMS_PER_GROUP 3
+
+/**
+ * TODO(dox) explain cuDNN interface
+ */
+template <typename Dtype>
+void CuDNNDeconvolutionLayer<Dtype>::LayerSetUp(
+    const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
+  DeconvolutionLayer<Dtype>::LayerSetUp(bottom, top);
+  // Initialize CUDA streams and cuDNN.
+  stream_         = new cudaStream_t[this->group_ * CUDNN_STREAMS_PER_GROUP];
+  handle_         = new cudnnHandle_t[this->group_ * CUDNN_STREAMS_PER_GROUP];
+
+  // Initialize algorithm arrays
+  fwd_algo_       = new cudnnConvolutionFwdAlgo_t[bottom.size()];
+  bwd_filter_algo_= new cudnnConvolutionBwdFilterAlgo_t[bottom.size()];
+  bwd_data_algo_  = new cudnnConvolutionBwdDataAlgo_t[bottom.size()];
+
+  // initialize size arrays
+  workspace_fwd_sizes_ = new size_t[bottom.size()];
+  workspace_bwd_filter_sizes_ = new size_t[bottom.size()];
+  workspace_bwd_data_sizes_ = new size_t[bottom.size()];
+
+  // workspace data
+  workspaceSizeInBytes = 0;
+  workspaceData = NULL;
+  workspace = new void*[this->group_ * CUDNN_STREAMS_PER_GROUP];
+
+  for (size_t i = 0; i < bottom.size(); ++i) {
+    // initialize all to default algorithms
+    fwd_algo_[i] = (cudnnConvolutionFwdAlgo_t)0;
+    bwd_filter_algo_[i] = (cudnnConvolutionBwdFilterAlgo_t)0;
+    bwd_data_algo_[i] = (cudnnConvolutionBwdDataAlgo_t)0;
+    // default algorithms don't require workspace
+    workspace_fwd_sizes_[i] = 0;
+    workspace_bwd_data_sizes_[i] = 0;
+    workspace_bwd_filter_sizes_[i] = 0;
+  }
+
+  for (int g = 0; g < this->group_ * CUDNN_STREAMS_PER_GROUP; g++) {
+    CUDA_CHECK(cudaStreamCreate(&stream_[g]));
+    CUDNN_CHECK(cudnnCreate(&handle_[g]));
+    CUDNN_CHECK(cudnnSetStream(handle_[g], stream_[g]));
+    workspace[g] = NULL;
+  }
+
+  // Set the indexing parameters.
+  bias_offset_ = (this->num_output_ / this->group_);
+
+  // Create filter descriptor.
+  vector<int> kernel_shape(this->kernel_shape_.shape(0) + 2);
+  int* kernel_shape_data = this->kernel_shape_.mutable_cpu_data();
+  for (int d = 0; d < kernel_shape.size() - 2; d++) {
+      kernel_shape[d + 2] = kernel_shape_data[d];
+  }
+  kernel_shape[1] = this->num_output_ / this->group_;
+  kernel_shape[0] = this->channels_ / this->group_;
+  cudnn::createNdFilterDesc<Dtype>(&filter_desc_,kernel_shape);
+
+  // Create tensor descriptor(s) for data and corresponding convolution(s).
+  for (int i = 0; i < bottom.size(); i++) {
+    cudnnTensorDescriptor_t bottom_desc;
+    cudnn::createTensorDesc<Dtype>(&bottom_desc);
+    bottom_descs_.push_back(bottom_desc);
+    cudnnTensorDescriptor_t top_desc;
+    cudnn::createTensorDesc<Dtype>(&top_desc);
+    top_descs_.push_back(top_desc);
+    cudnnConvolutionDescriptor_t conv_desc;
+    cudnn::createConvolutionDesc<Dtype>(&conv_desc);
+    conv_descs_.push_back(conv_desc);
+  }
+
+  // Tensor descriptor for bias.
+  if (this->bias_term_) {
+    cudnn::createTensorDesc<Dtype>(&bias_desc_);
+  }
+
+  handles_setup_ = true;
+}
+
+template <typename Dtype>
+void CuDNNDeconvolutionLayer<Dtype>::Reshape(
+    const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
+  DeconvolutionLayer<Dtype>::Reshape(bottom, top);
+  bottom_offset_ = this->bottom_dim_ / this->group_;
+  top_offset_ = this->top_dim_ / this->group_;
+
+  // Specify workspace limit for kernels directly until we have a
+  // planning strategy and a rewrite of Caffe's GPU memory mangagement
+  size_t workspace_limit_bytes = 8*1024*1024;
+
+  for (int i = 0; i < bottom.size(); i++) {
+    vector<int> bottom_shape(bottom[i]->shape());
+    bottom_shape[0] = 1;
+    bottom_shape[1] /= this->group_; // set channel_axis_ instead of 1
+    vector<int> bottom_tensor_stride(bottom[i]->shape().size(), 1);
+    for (int j = bottom[i]->shape().size()-2; j >= 0; --j) {
+        bottom_tensor_stride[j] = bottom[i]->shape()[j+1] * bottom_tensor_stride[j
+            +1];
+    }
+    cudnn::setTensorNdDesc<Dtype>(&bottom_descs_[i],bottom_shape,bottom_tensor_stride);
+    vector<int> top_shape(top[i]->shape());
+    top_shape[0] = 1;
+    top_shape[1] /= this->group_; // set channel_axis_ instead of 1
+    vector<int> top_tensor_stride(top[i]->shape().size(), 1);
+    for (int j = top[i]->shape().size()-2; j >= 0; --j) {
+        top_tensor_stride[j] = top[i]->shape()[j+1] * top_tensor_stride[j
+            +1];
+    }
+    cudnn::setTensorNdDesc<Dtype>(&top_descs_[i],top_shape,top_tensor_stride);
+    vector<int> pad_shape(this->pad_.count());
+    int* pad_shape_data = this->pad_.mutable_cpu_data();
+    for (int d = 0; d < pad_shape.size(); d++) {
+        pad_shape[d] = pad_shape_data[d];
+    }
+    vector<int> stride_shape(this->stride_.count());
+    int* stride_shape_data = this->stride_.mutable_cpu_data();
+    for (int d = 0; d < stride_shape.size(); d++) {
+        stride_shape[d] = stride_shape_data[d];
+    }
+    cudnn::setNdConvolutionDesc<Dtype>(&conv_descs_[i], top_descs_[i],
+                                      filter_desc_, pad_shape, stride_shape);
+
+    // choose forward and backward algorithms + workspace(s)
+    CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(handle_[0],
+      top_descs_[i],
+      filter_desc_,
+      conv_descs_[i],
+      bottom_descs_[i],
+      CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT,
+      workspace_limit_bytes,
+      &fwd_algo_[i]));
+
+    CUDNN_CHECK(cudnnGetConvolutionForwardWorkspaceSize(handle_[0],
+      top_descs_[i],
+      filter_desc_,
+      conv_descs_[i],
+      bottom_descs_[i],
+      fwd_algo_[i],
+      &(workspace_fwd_sizes_[i])));
+
+    // choose backward algorithm for filter
+    CUDNN_CHECK(cudnnGetConvolutionBackwardFilterAlgorithm(handle_[0],
+          top_descs_[i], bottom_descs_[i], conv_descs_[i], filter_desc_,
+          CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT,
+          workspace_limit_bytes, &bwd_filter_algo_[i]) );
+
+    // get workspace for backwards filter algorithm
+    CUDNN_CHECK(cudnnGetConvolutionBackwardFilterWorkspaceSize(handle_[0],
+          top_descs_[i], bottom_descs_[i], conv_descs_[i], filter_desc_,
+          bwd_filter_algo_[i], &workspace_bwd_filter_sizes_[i]));
+
+    // choose backward algo for data
+    CUDNN_CHECK(cudnnGetConvolutionBackwardDataAlgorithm(handle_[0],
+          filter_desc_, bottom_descs_[i], conv_descs_[i], top_descs_[i],
+          CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT,
+        workspace_limit_bytes, &bwd_data_algo_[i]));
+
+    // get workspace size
+    CUDNN_CHECK(cudnnGetConvolutionBackwardDataWorkspaceSize(handle_[0],
+          filter_desc_, bottom_descs_[i], conv_descs_[i], top_descs_[i],
+          bwd_data_algo_[i], &workspace_bwd_data_sizes_[i]) );
+  }
+
+  // reduce over all workspace sizes to get a maximum to allocate / reallocate
+  size_t total_workspace_fwd = 0;
+  size_t total_workspace_bwd_data = 0;
+  size_t total_workspace_bwd_filter = 0;
+
+  for (size_t i = 0; i < bottom.size(); i++) {
+    total_workspace_fwd        = std::max(total_workspace_fwd,
+                                     workspace_fwd_sizes_[i]);
+    total_workspace_bwd_data   = std::max(total_workspace_bwd_data,
+                                     workspace_bwd_data_sizes_[i]);
+    total_workspace_bwd_filter = std::max(total_workspace_bwd_filter,
+                                     workspace_bwd_filter_sizes_[i]);
+  }
+  // get max over all operations
+  size_t max_workspace = std::max(total_workspace_fwd,
+                             total_workspace_bwd_data);
+  max_workspace = std::max(max_workspace, total_workspace_bwd_filter);
+  // ensure all groups have enough workspace
+  size_t total_max_workspace = max_workspace *
+                               (this->group_ * CUDNN_STREAMS_PER_GROUP);
+
+  // this is the total amount of storage needed over all groups + streams
+  if (total_max_workspace > workspaceSizeInBytes) {
+    DLOG(INFO) << "Reallocating workspace storage: " << total_max_workspace;
+    workspaceSizeInBytes = total_max_workspace;
+
+    // free the existing workspace and allocate a new (larger) one
+    cudaFree(this->workspaceData);
+
+    cudaError_t err = cudaMalloc(&(this->workspaceData), workspaceSizeInBytes);
+    if (err != cudaSuccess) {
+      // force zero memory path
+      for (int i = 0; i < bottom.size(); i++) {
+        workspace_fwd_sizes_[i] = 0;
+        workspace_bwd_filter_sizes_[i] = 0;
+        workspace_bwd_data_sizes_[i] = 0;
+        fwd_algo_[i] = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;
+        bwd_filter_algo_[i] = CUDNN_CONVOLUTION_BWD_FILTER_ALGO_0;
+        bwd_data_algo_[i] = CUDNN_CONVOLUTION_BWD_DATA_ALGO_0;
+      }
+
+      // NULL out all workspace pointers
+      for (int g = 0; g < (this->group_ * CUDNN_STREAMS_PER_GROUP); g++) {
+        workspace[g] = NULL;
+      }
+      // NULL out underlying data
+      workspaceData = NULL;
+      workspaceSizeInBytes = 0;
+    }
+
+    // if we succeed in the allocation, set pointer aliases for workspaces
+    for (int g = 0; g < (this->group_ * CUDNN_STREAMS_PER_GROUP); g++) {
+      workspace[g] = reinterpret_cast<char *>(workspaceData) + g*max_workspace;
+    }
+  }
+
+  // Tensor descriptor for bias.
+  if (this->bias_term_) {
+      vector<int> bias_shape(top[0]->shape().size(),1);
+      bias_shape[1] = this->num_output_ / this->group_; // set channel_axis_ instead of 1
+      cudnn::setTensorNdDesc<Dtype>(&bias_desc_,bias_shape);
+  }
+}
+
+template <typename Dtype>
+CuDNNDeconvolutionLayer<Dtype>::~CuDNNDeconvolutionLayer() {
+  // Check that handles have been setup before destroying.
+  if (!handles_setup_) { return; }
+
+  for (int i = 0; i < bottom_descs_.size(); i++) {
+    cudnnDestroyTensorDescriptor(bottom_descs_[i]);
+    cudnnDestroyTensorDescriptor(top_descs_[i]);
+    cudnnDestroyConvolutionDescriptor(conv_descs_[i]);
+  }
+  if (this->bias_term_) {
+    cudnnDestroyTensorDescriptor(bias_desc_);
+  }
+  cudnnDestroyFilterDescriptor(filter_desc_);
+
+  for (int g = 0; g < this->group_ * CUDNN_STREAMS_PER_GROUP; g++) {
+    cudaStreamDestroy(stream_[g]);
+    cudnnDestroy(handle_[g]);
+  }
+
+  cudaFree(workspaceData);
+  delete [] stream_;
+  delete [] handle_;
+  delete [] fwd_algo_;
+  delete [] bwd_filter_algo_;
+  delete [] bwd_data_algo_;
+  delete [] workspace_fwd_sizes_;
+  delete [] workspace_bwd_data_sizes_;
+  delete [] workspace_bwd_filter_sizes_;
+}
+
+INSTANTIATE_CLASS(CuDNNDeconvolutionLayer);
+
+}   // namespace caffe
+#endif
diff --git a/src/caffe/layers/cudnn_deconv_layer.cu b/src/caffe/layers/cudnn_deconv_layer.cu
new file mode 100644
index 0000000..1dbbe99
--- /dev/null
+++ b/src/caffe/layers/cudnn_deconv_layer.cu
@@ -0,0 +1,120 @@
+#ifdef USE_CUDNN
+#include <vector>
+#include "caffe/layers/cudnn_deconv_layer.hpp"
+
+namespace caffe {
+
+__global__ void sync_deconv_groups() { }
+
+template <typename Dtype>
+void CuDNNDeconvolutionLayer<Dtype>::Forward_gpu(
+    const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
+  const Dtype* weight = this->blobs_[0]->gpu_data();
+  for (int i = 0; i < bottom.size(); ++i) {
+    for (int n = 0; n < this->num_; ++n) {
+      const Dtype* bottom_data = bottom[i]->gpu_data();
+      Dtype* top_data = top[i]->mutable_gpu_data();
+      // Forward through cuDNN in parallel over groups.
+      for (int g = 0; g < this->group_; g++) {
+        // Filters.
+        CUDNN_CHECK(cudnnConvolutionBackwardData(
+              handle_[g],
+              cudnn::dataType<Dtype>::one,
+              filter_desc_, weight + this->weight_offset_ * g,
+              bottom_descs_[i], bottom_data + bottom_offset_ * g + n * this->bottom_dim_,
+              conv_descs_[i],
+              bwd_data_algo_[i], workspace[g],
+              workspace_bwd_data_sizes_[i],
+              cudnn::dataType<Dtype>::zero,
+              top_descs_[i], top_data + top_offset_ * g + n * this->top_dim_));
+        // Bias.
+        if (this->bias_term_) {
+            const Dtype* bias_data = this->blobs_[1]->gpu_data();
+            CUDNN_CHECK(cudnnAddTensor(handle_[g],
+              cudnn::dataType<Dtype>::one,
+              bias_desc_, bias_data + bias_offset_ * g,
+              cudnn::dataType<Dtype>::one,
+              top_descs_[i], top_data + top_offset_ * g + n * this->top_dim_));
+        }
+      }
+      // Synchronize the work across groups, each of which went into its own
+      // stream, by launching an empty kernel into the default (null) stream.
+      // NOLINT_NEXT_LINE(whitespace/operators)
+      sync_deconv_groups<<<1, 1>>>();
+    }
+  }
+}
+
+template <typename Dtype>
+void CuDNNDeconvolutionLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
+    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+  const Dtype* weight = NULL;
+  Dtype* weight_diff = NULL;
+  for (int i = 0; i < top.size(); ++i) {
+    if (this->param_propagate_down_[0]) {
+      weight = this->blobs_[0]->gpu_data();
+      weight_diff = this->blobs_[0]->mutable_gpu_diff();
+    }
+    Dtype* bias_diff = NULL;
+    if (this->bias_term_ && this->param_propagate_down_[1]) {
+      bias_diff = this->blobs_[1]->mutable_gpu_diff();
+    }
+    const Dtype* top_diff = top[i]->gpu_diff();
+    const Dtype* bottom_data = bottom[i]->gpu_data();
+    Dtype* bottom_diff = bottom[i]->mutable_gpu_diff();
+    // Backward through cuDNN in parallel over groups and gradients.
+    for (int g = 0; g < this->group_; g++) {
+      // Gradient w.r.t. bias.
+      if (this->bias_term_ && this->param_propagate_down_[1]) {
+      for (int n = 0; n < this->num_; ++n) {
+          CUDNN_CHECK(cudnnConvolutionBackwardBias(handle_[0*this->group_ + g],
+            cudnn::dataType<Dtype>::one,
+            top_descs_[i],  top_diff + top_offset_ * g + n * this->top_dim_,
+            cudnn::dataType<Dtype>::one,
+            bias_desc_, bias_diff + bias_offset_ * g));
+          }
+      }
+
+      // Gradient w.r.t. weights. Note that we will accumulate diffs.
+      if (this->param_propagate_down_[0] || propagate_down[i]) {
+        for (int n = 0; n < this->num_; ++n) {
+          if (this->param_propagate_down_[0]) {
+           CUDNN_CHECK(cudnnConvolutionBackwardFilter(
+              handle_[1*this->group_ + g],
+              cudnn::dataType<Dtype>::one,
+              top_descs_[i],    top_diff + top_offset_ * g + n * this->top_dim_,
+              bottom_descs_[i], bottom_data + bottom_offset_ * g + n * this->bottom_dim_,
+              conv_descs_[i],
+              bwd_filter_algo_[i], workspace[1*this->group_ + g],
+              workspace_bwd_filter_sizes_[i],
+              cudnn::dataType<Dtype>::one,
+              filter_desc_, weight_diff + this->weight_offset_ * g));
+          }
+          // Gradient w.r.t. bottom data.
+          if (propagate_down[i]) {
+            if (weight == NULL) {
+              weight = this->blobs_[0]->gpu_data();
+            }
+           CUDNN_CHECK(cudnnConvolutionForward(handle_[2*this->group_ + g],
+              cudnn::dataType<Dtype>::one,
+              top_descs_[i], top_diff + top_offset_ * g + n * this->top_dim_,
+              filter_desc_, weight + this->weight_offset_ * g,
+              conv_descs_[i],
+              fwd_algo_[i], workspace[2*this->group_ + g], workspace_fwd_sizes_[i],
+              cudnn::dataType<Dtype>::zero,
+              bottom_descs_[i], bottom_diff + bottom_offset_ * g + n * this->bottom_dim_));
+          }
+        }
+      }
+    }
+    // Synchronize the work across groups, each of which went into its own
+    // stream, by launching an empty kernel into the default (null) stream.
+    // NOLINT_NEXT_LINE(whitespace/operators)
+    sync_deconv_groups<<<1, 1>>>();
+  }
+}
+
+INSTANTIATE_LAYER_GPU_FUNCS(CuDNNDeconvolutionLayer);
+
+}  // namespace caffe
+#endif
diff --git a/src/caffe/layers/cudnn_pooling_layer.cpp b/src/caffe/layers/cudnn_pooling_layer.cpp
index 24f1478..51967ab 100644
--- a/src/caffe/layers/cudnn_pooling_layer.cpp
+++ b/src/caffe/layers/cudnn_pooling_layer.cpp
@@ -10,12 +10,26 @@ void CuDNNPoolingLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
     const vector<Blob<Dtype>*>& top) {
   PoolingLayer<Dtype>::LayerSetUp(bottom, top);
   CUDNN_CHECK(cudnnCreate(&handle_));
-  cudnn::createTensor4dDesc<Dtype>(&bottom_desc_);
-  cudnn::createTensor4dDesc<Dtype>(&top_desc_);
-  cudnn::createPoolingDesc<Dtype>(&pooling_desc_,
+  cudnn::createTensorDesc<Dtype>(&bottom_desc_);
+  cudnn::createTensorDesc<Dtype>(&top_desc_);
+  vector<int> kernel_shape(this->kernel_shape_.count());
+  int* kernel_shape_data = this->kernel_shape_.mutable_cpu_data();
+  for (int d = 0; d < kernel_shape.size(); d++) {
+      kernel_shape[d] = kernel_shape_data[d];
+  }
+  vector<int> pad_shape(this->pad_.count());
+  int* pad_shape_data = this->pad_.mutable_cpu_data();
+  for (int d = 0; d < pad_shape.size(); d++) {
+    pad_shape[d] = pad_shape_data[d];
+  }
+  vector<int> stride_shape(this->stride_.count());
+  int* stride_shape_data = this->stride_.mutable_cpu_data();
+  for (int d = 0; d < stride_shape.size(); d++) {
+    stride_shape[d] = stride_shape_data[d];
+  }
+  cudnn::createNdPoolingDesc<Dtype>(&pooling_desc_,
       this->layer_param_.pooling_param().pool(), &mode_,
-      this->kernel_h_, this->kernel_w_, this->pad_h_, this->pad_w_,
-      this->stride_h_, this->stride_w_);
+      kernel_shape,pad_shape,stride_shape);
   handles_setup_ = true;
 }
 
@@ -23,10 +37,8 @@ template <typename Dtype>
 void CuDNNPoolingLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
     const vector<Blob<Dtype>*>& top) {
   PoolingLayer<Dtype>::Reshape(bottom, top);
-  cudnn::setTensor4dDesc<Dtype>(&bottom_desc_, bottom[0]->num(),
-      this->channels_, this->height_, this->width_);
-  cudnn::setTensor4dDesc<Dtype>(&top_desc_, bottom[0]->num(),
-      this->channels_, this->pooled_height_, this->pooled_width_);
+  cudnn::setTensorNdDesc<Dtype>(&bottom_desc_, bottom[0]->shape());
+  cudnn::setTensorNdDesc<Dtype>(&top_desc_, top[0]->shape());
 }
 
 template <typename Dtype>
diff --git a/src/caffe/layers/cudnn_relu_layer.cpp b/src/caffe/layers/cudnn_relu_layer.cpp
index 795e0a9..b444a5f 100644
--- a/src/caffe/layers/cudnn_relu_layer.cpp
+++ b/src/caffe/layers/cudnn_relu_layer.cpp
@@ -11,8 +11,8 @@ void CuDNNReLULayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
   ReLULayer<Dtype>::LayerSetUp(bottom, top);
   // initialize cuDNN
   CUDNN_CHECK(cudnnCreate(&handle_));
-  cudnn::createTensor4dDesc<Dtype>(&bottom_desc_);
-  cudnn::createTensor4dDesc<Dtype>(&top_desc_);
+  cudnn::createTensorDesc<Dtype>(&bottom_desc_);
+  cudnn::createTensorDesc<Dtype>(&top_desc_);
   cudnn::createActivationDescriptor<Dtype>(&activ_desc_, CUDNN_ACTIVATION_RELU);
   handles_setup_ = true;
 }
@@ -21,12 +21,9 @@ template <typename Dtype>
 void CuDNNReLULayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   ReLULayer<Dtype>::Reshape(bottom, top);
-  const int N = bottom[0]->num();
-  const int K = bottom[0]->channels();
-  const int H = bottom[0]->height();
-  const int W = bottom[0]->width();
-  cudnn::setTensor4dDesc<Dtype>(&bottom_desc_, N, K, H, W);
-  cudnn::setTensor4dDesc<Dtype>(&top_desc_, N, K, H, W);
+  vector<int> bottom_shape(bottom[0]->shape());
+  cudnn::setTensorNdDesc<Dtype>(&bottom_desc_,bottom_shape);
+  cudnn::setTensorNdDesc<Dtype>(&top_desc_,bottom_shape);
 }
 
 template <typename Dtype>
diff --git a/src/caffe/layers/deconv_layer.cpp b/src/caffe/layers/deconv_layer.cpp
index 20a460f..b86472b 100644
--- a/src/caffe/layers/deconv_layer.cpp
+++ b/src/caffe/layers/deconv_layer.cpp
@@ -79,6 +79,5 @@ STUB_GPU(DeconvolutionLayer);
 #endif
 
 INSTANTIATE_CLASS(DeconvolutionLayer);
-REGISTER_LAYER_CLASS(Deconvolution);
 
 }  // namespace caffe
diff --git a/src/caffe/layers/hdf5_data_layer.cpp b/src/caffe/layers/hdf5_data_layer.cpp
index 2f13dc6..c31e5c3 100644
--- a/src/caffe/layers/hdf5_data_layer.cpp
+++ b/src/caffe/layers/hdf5_data_layer.cpp
@@ -16,6 +16,7 @@ TODO:
 
 #include "caffe/layers/hdf5_data_layer.hpp"
 #include "caffe/util/hdf5.hpp"
+#include "caffe/util/vector_helper.hpp"
 
 namespace caffe {
 
@@ -94,6 +95,54 @@ void HDF5DataLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
   CHECK_GE(num_files_, 1) << "Must have at least 1 HDF5 filename listed in "
     << source;
 
+  // check the shapes of all datasets, if they are equal, and if the
+  // number of images per blob is divisible by the batch size
+  const int batch_size = this->layer_param_.hdf5_data_param().batch_size();
+  int num_datasets = top.size();
+  dataset_shapes_.resize( num_files_ * num_datasets);
+  files_have_consistent_shapes_ = true;
+  hdf_blobs_divisible_by_batch_size_ = true;
+  for (int fi = 0; fi < num_files_; ++fi) {
+    std::string msg;
+    std::string filename = hdf_filenames_[fi];
+    hid_t file_id = H5Fopen(filename.c_str(), H5F_ACC_RDONLY, H5P_DEFAULT);
+    msg += filename + ":";
+    for (int di = 0; di < num_datasets; ++di) {
+      std::vector<hsize_t> shape =
+          hdf5_get_dataset_shape( file_id, this->layer_param_.top(di).c_str());
+      dataset_shapes_[fi * num_datasets + di] = shape;
+      if( di > 0) {
+        if( shape.size() != dataset_shapes_[di].size()) {
+          LOG(FATAL) << filename << " dataset " << this->layer_param_.top(di).c_str() << toString( shape) << " has different number of axes.";
+        }
+        if( shape[0] % batch_size != 0) {
+          hdf_blobs_divisible_by_batch_size_ = false;
+        }
+        for (int j = 1; j < shape.size(); ++j) {
+          if( shape[j] != dataset_shapes_[di][j]) {
+            files_have_consistent_shapes_ = false;
+          }
+        }
+      }
+      msg += std::string("  ") + this->layer_param_.top(di).c_str() + " " + toString( shape);
+    }
+    LOG(INFO) << msg;
+    herr_t status = H5Fclose(file_id);
+    CHECK_GE(status, 0) << "Failed to close HDF5 file: " << filename;
+  }
+  LOG(INFO) << "files_have_consistent_shapes: "
+            << files_have_consistent_shapes_;
+  LOG(INFO) << "hdf_blobs_divisible_by_batch_size: "
+            << hdf_blobs_divisible_by_batch_size_;
+
+  if( files_have_consistent_shapes_ == false
+      && hdf_blobs_divisible_by_batch_size_ == false) {
+    LOG(FATAL) <<
+        "Cannot work with these files! The dataset must have either\n"
+        "the same spatial shapes, or the batch sizes in the HDF5 data\n"
+        "sets must be divisible by the requested training batch size!";
+  }
+
   file_permutation_.clear();
   file_permutation_.resize(num_files_);
   // Default to identity permutation.
@@ -106,19 +155,26 @@ void HDF5DataLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
     std::random_shuffle(file_permutation_.begin(), file_permutation_.end());
   }
 
-  // Load the first HDF5 file and initialize the line counter.
-  LoadHDF5FileData(hdf_filenames_[file_permutation_[current_file_]].c_str());
+  // initialize the line counter.
   current_row_ = 0;
+}
+
+template <typename Dtype>
+void HDF5DataLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
+                                   const vector<Blob<Dtype>*>& top) {
+  const int batch_size = this->layer_param_.hdf5_data_param().batch_size();
+
+  // index of current file
+  int fi = file_permutation_[current_file_];
 
   // Reshape blobs.
-  const int batch_size = this->layer_param_.hdf5_data_param().batch_size();
   const int top_size = this->layer_param_.top_size();
   vector<int> top_shape;
   for (int i = 0; i < top_size; ++i) {
-    top_shape.resize(hdf_blobs_[i]->num_axes());
+    top_shape.resize( dataset_shapes_[fi * top_size + i].size());
     top_shape[0] = batch_size;
     for (int j = 1; j < top_shape.size(); ++j) {
-      top_shape[j] = hdf_blobs_[i]->shape(j);
+      top_shape[j] = dataset_shapes_[fi * top_size + i][j];
     }
     top[i]->Reshape(top_shape);
   }
@@ -128,7 +184,23 @@ template <typename Dtype>
 void HDF5DataLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   const int batch_size = this->layer_param_.hdf5_data_param().batch_size();
-  for (int i = 0; i < batch_size; ++i, ++current_row_) {
+  for (int i = 0; i < batch_size; ++i) {
+    // if at the begin of a new file, load the data
+    if( current_row_ == 0) {
+      LoadHDF5FileData(
+          hdf_filenames_[file_permutation_[current_file_]].c_str());
+    }
+
+    // copy data to top blobs
+    for (int j = 0; j < this->layer_param_.top_size(); ++j) {
+      int data_dim = top[j]->count() / top[j]->shape(0);
+      caffe_copy(data_dim,
+          &hdf_blobs_[j]->cpu_data()[data_permutation_[current_row_]
+            * data_dim], &top[j]->mutable_cpu_data()[i * data_dim]);
+    }
+
+    // advance index to next "row", possibly go to next file
+    ++current_row_;
     if (current_row_ == hdf_blobs_[0]->shape(0)) {
       if (num_files_ > 1) {
         ++current_file_;
@@ -137,22 +209,14 @@ void HDF5DataLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
           if (this->layer_param_.hdf5_data_param().shuffle()) {
             std::random_shuffle(file_permutation_.begin(),
                                 file_permutation_.end());
-          }
           DLOG(INFO) << "Looping around to first file.";
+          }
         }
-        LoadHDF5FileData(
-            hdf_filenames_[file_permutation_[current_file_]].c_str());
       }
       current_row_ = 0;
       if (this->layer_param_.hdf5_data_param().shuffle())
         std::random_shuffle(data_permutation_.begin(), data_permutation_.end());
     }
-    for (int j = 0; j < this->layer_param_.top_size(); ++j) {
-      int data_dim = top[j]->count() / top[j]->shape(0);
-      caffe_copy(data_dim,
-          &hdf_blobs_[j]->cpu_data()[data_permutation_[current_row_]
-            * data_dim], &top[j]->mutable_cpu_data()[i * data_dim]);
-    }
   }
 }
 
diff --git a/src/caffe/layers/hdf5_data_layer.cu b/src/caffe/layers/hdf5_data_layer.cu
index 595d223..bc4f63e 100644
--- a/src/caffe/layers/hdf5_data_layer.cu
+++ b/src/caffe/layers/hdf5_data_layer.cu
@@ -17,31 +17,39 @@ template <typename Dtype>
 void HDF5DataLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   const int batch_size = this->layer_param_.hdf5_data_param().batch_size();
-  for (int i = 0; i < batch_size; ++i, ++current_row_) {
+  for (int i = 0; i < batch_size; ++i) {
+    // if at the begin of a new file, load the data
+    if( current_row_ == 0) {
+      LoadHDF5FileData(
+          hdf_filenames_[file_permutation_[current_file_]].c_str());
+    }
+
+    // copy data to top blobs
+    for (int j = 0; j < this->layer_param_.top_size(); ++j) {
+      int data_dim = top[j]->count() / top[j]->shape(0);
+      caffe_copy(data_dim,
+          &hdf_blobs_[j]->cpu_data()[data_permutation_[current_row_]
+            * data_dim], &top[j]->mutable_gpu_data()[i * data_dim]);
+    }
+
+    // advance index to next "row", possibly go to next file
+    ++current_row_;
     if (current_row_ == hdf_blobs_[0]->shape(0)) {
       if (num_files_ > 1) {
-        current_file_ += 1;
+        ++current_file_;
         if (current_file_ == num_files_) {
           current_file_ = 0;
           if (this->layer_param_.hdf5_data_param().shuffle()) {
             std::random_shuffle(file_permutation_.begin(),
                                 file_permutation_.end());
-          }
           DLOG(INFO) << "Looping around to first file.";
+          }
         }
-        LoadHDF5FileData(
-            hdf_filenames_[file_permutation_[current_file_]].c_str());
       }
       current_row_ = 0;
       if (this->layer_param_.hdf5_data_param().shuffle())
         std::random_shuffle(data_permutation_.begin(), data_permutation_.end());
     }
-    for (int j = 0; j < this->layer_param_.top_size(); ++j) {
-      int data_dim = top[j]->count() / top[j]->shape(0);
-      caffe_copy(data_dim,
-          &hdf_blobs_[j]->cpu_data()[data_permutation_[current_row_]
-            * data_dim], &top[j]->mutable_gpu_data()[i * data_dim]);
-    }
   }
 }
 
diff --git a/src/caffe/layers/hdf5_output_layer.cpp b/src/caffe/layers/hdf5_output_layer.cpp
index f8f1edc..ca365a2 100644
--- a/src/caffe/layers/hdf5_output_layer.cpp
+++ b/src/caffe/layers/hdf5_output_layer.cpp
@@ -5,6 +5,7 @@
 
 #include "caffe/layers/hdf5_output_layer.hpp"
 #include "caffe/util/hdf5.hpp"
+#include "caffe/util/vector_helper.hpp"
 
 namespace caffe {
 
@@ -12,50 +13,76 @@ template <typename Dtype>
 void HDF5OutputLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
     const vector<Blob<Dtype>*>& top) {
   file_name_ = this->layer_param_.hdf5_output_param().file_name();
-  file_id_ = H5Fcreate(file_name_.c_str(), H5F_ACC_TRUNC, H5P_DEFAULT,
-                       H5P_DEFAULT);
-  CHECK_GE(file_id_, 0) << "Failed to open HDF5 file" << file_name_;
-  file_opened_ = true;
+  file_iter_ = 0;
+
+  if( this->layer_param_.hdf5_output_param().dset_name().size() == 0) {
+    // if no data set names are given, be compatible to old implementation
+    dset_names_.push_back( HDF5_DATA_DATASET_NAME);
+    dset_names_.push_back( HDF5_DATA_LABEL_NAME);
+  }  else {
+    for (int i = 0; i < this->layer_param_.hdf5_output_param().dset_name().size(); ++i) {
+      dset_names_.push_back(this->layer_param_.hdf5_output_param().dset_name(i));
+    }
+  }
+  // check if the number of dset_names matches the number of
+  // bottom blobs
+  CHECK_EQ( bottom.size(), dset_names_.size());
 }
 
 template <typename Dtype>
 HDF5OutputLayer<Dtype>::~HDF5OutputLayer<Dtype>() {
-  if (file_opened_) {
-    herr_t status = H5Fclose(file_id_);
-    CHECK_GE(status, 0) << "Failed to close HDF5 file " << file_name_;
-  }
 }
 
 template <typename Dtype>
-void HDF5OutputLayer<Dtype>::SaveBlobs() {
-  // TODO: no limit on the number of blobs
-  LOG(INFO) << "Saving HDF5 file " << file_name_;
-  CHECK_EQ(data_blob_.num(), label_blob_.num()) <<
-      "data blob and label blob must have the same batch size";
-  hdf5_save_nd_dataset(file_id_, HDF5_DATA_DATASET_NAME, data_blob_);
-  hdf5_save_nd_dataset(file_id_, HDF5_DATA_LABEL_NAME, label_blob_);
-  LOG(INFO) << "Successfully saved " << data_blob_.num() << " rows";
+void HDF5OutputLayer<Dtype>::SaveBlobs(const vector<Blob<Dtype>*>& bottom, bool is_GPU_data) {
+  char formatted_file_name[2048];
+  sprintf( formatted_file_name, file_name_.c_str(), file_iter_);
+  LOG(INFO) << "Saving HDF5 file " << formatted_file_name;
+  hid_t file_id = 0;
+  if( file_iter_ == 0 ||
+      strcmp( formatted_file_name, file_name_.c_str()) != 0) {
+    // in first iteration or for differntly named files, create the files
+    file_id = H5Fcreate(formatted_file_name, H5F_ACC_TRUNC, H5P_DEFAULT,
+                       H5P_DEFAULT);
+  } else {
+    // otherwise open existing file for writing
+    file_id = H5Fopen(formatted_file_name, H5F_ACC_RDWR, H5P_DEFAULT);
+  }
+
+  CHECK_GE(file_id, 0) << "Failed to create or reopen HDF5 file" << formatted_file_name;
+  for (int i = 0; i < bottom.size(); ++i) {
+    char formatted_dset_name[2048];
+    sprintf( formatted_dset_name, dset_names_[i].c_str(), file_iter_);
+    std::vector<int> outshape;
+    for( int axis = 0; axis < bottom[i]->num_axes(); ++axis) {
+      if( this->layer_param_.hdf5_output_param().squeeze() &&
+          bottom[i]->shape(axis) == 1) {
+        // do not append axis with length 1 to output shape
+      } else {
+        outshape.push_back( bottom[i]->shape(axis));
+      }
+    }
+    LOG(INFO) << "outshape = " << toString(outshape);
+    Blob<Dtype> data( outshape);
+    if (is_GPU_data) {
+      caffe_copy( bottom[i]->count(), bottom[i]->gpu_data(),
+                  data.mutable_cpu_data());
+    } else {
+      caffe_copy( bottom[i]->count(), bottom[i]->cpu_data(),
+                  data.mutable_cpu_data());
+    }
+    hdf5_save_nd_dataset(file_id, formatted_dset_name, data);
+  }
+  herr_t status = H5Fclose(file_id);
+  CHECK_GE(status, 0) << "Failed to close HDF5 file " << file_name_;
+  LOG(INFO) << "Successfully saved " << bottom.size() << " blobs";
+  ++file_iter_;
 }
 
 template <typename Dtype>
 void HDF5OutputLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
-  CHECK_GE(bottom.size(), 2);
-  CHECK_EQ(bottom[0]->num(), bottom[1]->num());
-  data_blob_.Reshape(bottom[0]->num(), bottom[0]->channels(),
-                     bottom[0]->height(), bottom[0]->width());
-  label_blob_.Reshape(bottom[1]->num(), bottom[1]->channels(),
-                     bottom[1]->height(), bottom[1]->width());
-  const int data_datum_dim = bottom[0]->count() / bottom[0]->num();
-  const int label_datum_dim = bottom[1]->count() / bottom[1]->num();
-
-  for (int i = 0; i < bottom[0]->num(); ++i) {
-    caffe_copy(data_datum_dim, &bottom[0]->cpu_data()[i * data_datum_dim],
-        &data_blob_.mutable_cpu_data()[i * data_datum_dim]);
-    caffe_copy(label_datum_dim, &bottom[1]->cpu_data()[i * label_datum_dim],
-        &label_blob_.mutable_cpu_data()[i * label_datum_dim]);
-  }
-  SaveBlobs();
+  SaveBlobs(bottom, false);
 }
 
 template <typename Dtype>
diff --git a/src/caffe/layers/hdf5_output_layer.cu b/src/caffe/layers/hdf5_output_layer.cu
index c1685cd..6d7990a 100644
--- a/src/caffe/layers/hdf5_output_layer.cu
+++ b/src/caffe/layers/hdf5_output_layer.cu
@@ -10,22 +10,7 @@ namespace caffe {
 template <typename Dtype>
 void HDF5OutputLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
-  CHECK_GE(bottom.size(), 2);
-  CHECK_EQ(bottom[0]->num(), bottom[1]->num());
-  data_blob_.Reshape(bottom[0]->num(), bottom[0]->channels(),
-                     bottom[0]->height(), bottom[0]->width());
-  label_blob_.Reshape(bottom[1]->num(), bottom[1]->channels(),
-                     bottom[1]->height(), bottom[1]->width());
-  const int data_datum_dim = bottom[0]->count() / bottom[0]->num();
-  const int label_datum_dim = bottom[1]->count() / bottom[1]->num();
-
-  for (int i = 0; i < bottom[0]->num(); ++i) {
-    caffe_copy(data_datum_dim, &bottom[0]->gpu_data()[i * data_datum_dim],
-        &data_blob_.mutable_cpu_data()[i * data_datum_dim]);
-    caffe_copy(label_datum_dim, &bottom[1]->gpu_data()[i * label_datum_dim],
-        &label_blob_.mutable_cpu_data()[i * label_datum_dim]);
-  }
-  SaveBlobs();
+  SaveBlobs( bottom, true);
 }
 
 template <typename Dtype>
diff --git a/src/caffe/layers/loss_layer.cpp b/src/caffe/layers/loss_layer.cpp
index c0b7a86..a045b78 100644
--- a/src/caffe/layers/loss_layer.cpp
+++ b/src/caffe/layers/loss_layer.cpp
@@ -16,7 +16,7 @@ void LossLayer<Dtype>::LayerSetUp(
 template <typename Dtype>
 void LossLayer<Dtype>::Reshape(
     const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
-  CHECK_EQ(bottom[0]->num(), bottom[1]->num())
+  CHECK_EQ(bottom[0]->shape(0), bottom[1]->shape(0))
       << "The data and label should have the same number.";
   vector<int> loss_shape(0);  // Loss layers output a scalar; 0 axes.
   top[0]->Reshape(loss_shape);
diff --git a/src/caffe/layers/lrn_layer.cpp b/src/caffe/layers/lrn_layer.cpp
index 210525e..8fcfdf9 100644
--- a/src/caffe/layers/lrn_layer.cpp
+++ b/src/caffe/layers/lrn_layer.cpp
@@ -38,8 +38,8 @@ void LRNLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
     LayerParameter pool_param;
     pool_param.mutable_pooling_param()->set_pool(
         PoolingParameter_PoolMethod_AVE);
-    pool_param.mutable_pooling_param()->set_pad(pre_pad_);
-    pool_param.mutable_pooling_param()->set_kernel_size(size_);
+    pool_param.mutable_pooling_param()->add_pad(pre_pad_);
+    pool_param.mutable_pooling_param()->add_kernel_size(size_);
     pool_layer_.reset(new PoolingLayer<Dtype>(pool_param));
     pool_layer_->SetUp(square_top_vec_, pool_top_vec_);
     // Set up power_layer_ to compute (1 + alpha_/N^2 s)^-beta_, where s is
diff --git a/src/caffe/layers/pooling_layer.cpp b/src/caffe/layers/pooling_layer.cpp
index 90897db..8194419 100644
--- a/src/caffe/layers/pooling_layer.cpp
+++ b/src/caffe/layers/pooling_layer.cpp
@@ -2,8 +2,8 @@
 #include <cfloat>
 #include <vector>
 
-#include "caffe/layers/pooling_layer.hpp"
 #include "caffe/util/math_functions.hpp"
+#include "caffe/layers/pooling_layer.hpp"
 
 namespace caffe {
 
@@ -14,118 +14,207 @@ template <typename Dtype>
 void PoolingLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   PoolingParameter pool_param = this->layer_param_.pooling_param();
-  if (pool_param.global_pooling()) {
-    CHECK(!(pool_param.has_kernel_size() ||
-      pool_param.has_kernel_h() || pool_param.has_kernel_w()))
-      << "With Global_pooling: true Filter size cannot specified";
-  } else {
-    CHECK(!pool_param.has_kernel_size() !=
-      !(pool_param.has_kernel_h() && pool_param.has_kernel_w()))
-      << "Filter size is kernel_size OR kernel_h and kernel_w; not both";
-    CHECK(pool_param.has_kernel_size() ||
-      (pool_param.has_kernel_h() && pool_param.has_kernel_w()))
-      << "For non-square filters both kernel_h and kernel_w are required.";
-  }
-  CHECK((!pool_param.has_pad() && pool_param.has_pad_h()
-      && pool_param.has_pad_w())
-      || (!pool_param.has_pad_h() && !pool_param.has_pad_w()))
-      << "pad is pad OR pad_h and pad_w are required.";
-  CHECK((!pool_param.has_stride() && pool_param.has_stride_h()
-      && pool_param.has_stride_w())
-      || (!pool_param.has_stride_h() && !pool_param.has_stride_w()))
-      << "Stride is stride OR stride_h and stride_w are required.";
+  // find channel axis and compute spatial axes constants
+  channel_axis_ = bottom[0]->CanonicalAxisIndex(pool_param.axis());
+  channels_ = bottom[0]->shape(channel_axis_);
+  const int first_spatial_axis = channel_axis_ + 1;
+  const int num_axes = bottom[0]->num_axes();
+  num_spatial_axes_ = num_axes - first_spatial_axis;
+  CHECK_GE(num_spatial_axes_, 1);
+
+  vector<int> spatial_dim_blob_shape(1, num_spatial_axes_);
+
   global_pooling_ = pool_param.global_pooling();
+  // Setup filter kernel dimensions (kernel_shape_).
+  kernel_shape_.Reshape(spatial_dim_blob_shape);
+  int* kernel_shape_data = kernel_shape_.mutable_cpu_data();
   if (global_pooling_) {
-    kernel_h_ = bottom[0]->height();
-    kernel_w_ = bottom[0]->width();
-  } else {
-    if (pool_param.has_kernel_size()) {
-      kernel_h_ = kernel_w_ = pool_param.kernel_size();
-    } else {
-      kernel_h_ = pool_param.kernel_h();
-      kernel_w_ = pool_param.kernel_w();
+    // if global pooling height and width are set the entire blob,
+    // and the layer cannot have a kernel set
+    CHECK_GE(0, pool_param.kernel_size_size())
+        << "With Global_pooling: true Filter size cannot specified.";
+    CHECK(!pool_param.has_kernel_h() || !pool_param.has_kernel_w())
+        << "With Global_pooling: true Filter size cannot specified.";
+    for (int i = 0; i < num_spatial_axes_ + 1; ++i) {
+      kernel_shape_data[i] = bottom[0]->shape(channel_axis_ + i);
     }
-  }
-  CHECK_GT(kernel_h_, 0) << "Filter dimensions cannot be zero.";
-  CHECK_GT(kernel_w_, 0) << "Filter dimensions cannot be zero.";
-  if (!pool_param.has_pad_h()) {
-    pad_h_ = pad_w_ = pool_param.pad();
   } else {
-    pad_h_ = pool_param.pad_h();
-    pad_w_ = pool_param.pad_w();
+     // if kernel_h or kernel_w are set we cannot set the kernel another way
+     // And there must be 2 spatial dims
+    if (pool_param.has_kernel_h() || pool_param.has_kernel_w()) {
+        CHECK_EQ(num_spatial_axes_, 2)
+          << "kernel_h & kernel_w can only be used for 2D pooling.";
+        CHECK_EQ(0, pool_param.kernel_size_size())
+          << "Either kernel_size or kernel_h/w should be specified; not both.";
+        kernel_shape_data[0] = pool_param.kernel_h();
+        kernel_shape_data[1] = pool_param.kernel_w();
+      } else {
+        // using repeated kernel param
+        const int num_kernel_dims = pool_param.kernel_size_size();
+        CHECK(num_kernel_dims == 1 || num_kernel_dims == num_spatial_axes_)
+          << "kernel_size must be specified once, or once per spatial dimension"
+          << " (kernel_size specified " << num_kernel_dims << " times; "
+          << num_spatial_axes_ << " spatial dims);";
+        for (int i = 0; i < num_spatial_axes_; ++i) {
+            kernel_shape_data[i] =
+                pool_param.kernel_size((num_kernel_dims == 1) ? 0 : i);
+          }
+      }
   }
-  if (!pool_param.has_stride_h()) {
-    stride_h_ = stride_w_ = pool_param.stride();
-  } else {
-    stride_h_ = pool_param.stride_h();
-    stride_w_ = pool_param.stride_w();
+  for (int i = 0; i < num_spatial_axes_; ++i) {
+      CHECK_GT(kernel_shape_data[i], 0) << "Filter dimensions must be nonzero.";
   }
-  if (global_pooling_) {
-    CHECK(pad_h_ == 0 && pad_w_ == 0 && stride_h_ == 1 && stride_w_ == 1)
-      << "With Global_pooling: true; only pad = 0 and stride = 1";
+
+  // setup padding dimensions (pad_)
+  pad_.Reshape(spatial_dim_blob_shape);
+  int* pad_data = pad_.mutable_cpu_data();
+  int pad_sum = 0;
+  if (pool_param.has_pad_h() || pool_param.has_pad_w()) {
+      // if pad_h or pad_w are set we cannot set the pad another way
+      // And there must be 2 spatial dims
+      CHECK_EQ(num_spatial_axes_, 2)
+        << "pad_h & pad_w can only be used for 2D convolution.";
+      CHECK_EQ(0, pool_param.pad_size())
+        << "Either pad or pad_h/w should be specified; not both.";
+      pad_data[0] = pool_param.pad_h();
+      pad_data[1] = pool_param.pad_w();
+  } else {
+    // using repeated pad param
+    const int num_pad_dims = pool_param.pad_size();
+    CHECK(num_pad_dims == 0 || num_pad_dims == 1 ||
+          num_pad_dims == num_spatial_axes_)
+        << "pad must be specified once, or once per spatial dimension "
+        << "(pad specified " << num_pad_dims << " times; "
+        << num_spatial_axes_ << " spatial dims);";
+    const int kDefaultPad = 0;
+    for (int i = 0; i < num_spatial_axes_; ++i) {
+      pad_data[i] = (num_pad_dims == 0) ? kDefaultPad :
+          pool_param.pad((num_pad_dims == 1) ? 0 : i);
+      if (global_pooling_) {
+          CHECK_EQ(pad_data[i], 0)
+            << "With Global_pooling: true; pool = 0";
+        }
+      CHECK_LT(pad_data[i], kernel_shape_data[i]);
+      pad_sum += pad_data[i];
+    }
   }
-  if (pad_h_ != 0 || pad_w_ != 0) {
-    CHECK(this->layer_param_.pooling_param().pool()
-        == PoolingParameter_PoolMethod_AVE
-        || this->layer_param_.pooling_param().pool()
-        == PoolingParameter_PoolMethod_MAX)
+  if (pad_sum != 0) {
+     CHECK(this->layer_param_.pooling_param().pool() ==
+      PoolingParameter_PoolMethod_AVE
+      || this->layer_param_.pooling_param().pool() ==
+      PoolingParameter_PoolMethod_MAX)
         << "Padding implemented only for average and max pooling.";
-    CHECK_LT(pad_h_, kernel_h_);
-    CHECK_LT(pad_w_, kernel_w_);
+      }
+
+// Setup stride dimensions (stride_).
+  stride_.Reshape(spatial_dim_blob_shape);
+  int* stride_data = stride_.mutable_cpu_data();
+  if (pool_param.has_stride_h() || pool_param.has_stride_w()) {
+    CHECK_EQ(num_spatial_axes_, 2)
+        << "stride_h & stride_w can only be used for 2D convolution.";
+    CHECK_EQ(0, pool_param.stride_size())
+        << "Either stride or stride_h/w should be specified; not both.";
+    stride_data[0] = pool_param.stride_h();
+    stride_data[1] = pool_param.stride_w();
+  } else {
+    // using repeated stride param
+    const int num_stride_dims = pool_param.stride_size();
+    CHECK(num_stride_dims == 0 || num_stride_dims == 1 ||
+          num_stride_dims == num_spatial_axes_)
+        << "stride must be specified once, or once per spatial dimension "
+        << "(stride specified " << num_stride_dims << " times; "
+        << num_spatial_axes_ << " spatial dims);";
+    const int kDefaultStride = 1;
+    for (int i = 0; i < num_spatial_axes_; ++i) {
+      stride_data[i] = (num_stride_dims == 0) ? kDefaultStride :
+          pool_param.stride((num_stride_dims == 1) ? 0 : i);
+      CHECK_GT(stride_data[i], 0) << "Stride dimensions must be nonzero.";
+      if (global_pooling_) {
+        CHECK_EQ(stride_data[i], 1)
+          << "With Global_pooling: true; stride = 1";
+      }
+    }
   }
 }
 
 template <typename Dtype>
 void PoolingLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
-  CHECK_EQ(4, bottom[0]->num_axes()) << "Input must have 4 axes, "
-      << "corresponding to (num, channels, height, width)";
-  channels_ = bottom[0]->channels();
-  height_ = bottom[0]->height();
-  width_ = bottom[0]->width();
+  PoolingParameter pool_param = this->layer_param_.pooling_param();
+  channel_axis_ = bottom[0]->CanonicalAxisIndex(pool_param.axis());
+  num_ = bottom[0]->count(0, channel_axis_);
+  const int first_spatial_axis = channel_axis_ + 1;
+  const int num_axes = bottom[0]->num_axes();
+  num_spatial_axes_ = num_axes - first_spatial_axis;
+  CHECK_GE(num_spatial_axes_, 1);
+
+  // Setup input dimensions (input_shape_).
+  vector<int> bottom_dim_blob_shape(1, num_spatial_axes_ + 1);
+  input_shape_.Reshape(bottom_dim_blob_shape);
+  int* input_shape_data = input_shape_.mutable_cpu_data();
+  for (int i = 0; i < num_spatial_axes_ + 1; ++i) {
+    input_shape_data[i] = bottom[0]->shape(channel_axis_ + i);
+  }
+
+  int* kernel_shape_data = kernel_shape_.mutable_cpu_data();
   if (global_pooling_) {
-    kernel_h_ = bottom[0]->height();
-    kernel_w_ = bottom[0]->width();
-  }
-  pooled_height_ = static_cast<int>(ceil(static_cast<float>(
-      height_ + 2 * pad_h_ - kernel_h_) / stride_h_)) + 1;
-  pooled_width_ = static_cast<int>(ceil(static_cast<float>(
-      width_ + 2 * pad_w_ - kernel_w_) / stride_w_)) + 1;
-  if (pad_h_ || pad_w_) {
-    // If we have padding, ensure that the last pooling starts strictly
-    // inside the image (instead of at the padding); otherwise clip the last.
-    if ((pooled_height_ - 1) * stride_h_ >= height_ + pad_h_) {
-      --pooled_height_;
+    for (int i = 0; i < num_spatial_axes_; ++i) {
+      kernel_shape_data[i] = input_shape_data[i+1];
     }
-    if ((pooled_width_ - 1) * stride_w_ >= width_ + pad_w_) {
-      --pooled_width_;
+  }
+  // compute output shape
+  const int* pad_data = this->pad_.cpu_data();
+  const int* stride_data = this->stride_.cpu_data();
+  vector<int> spatial_dim_blob_shape(1, num_spatial_axes_);
+  output_shape_.Reshape(spatial_dim_blob_shape);
+  int* output_shape_data = output_shape_.mutable_cpu_data();
+  int pad_sum = 0;
+  for (int i = 0; i < num_spatial_axes_; ++i) {
+    int oc = static_cast<int>(ceil(static_cast<float>(
+          input_shape_data[i+1] + 2 * pad_data[i]
+          - kernel_shape_data[i]) / stride_data[i])) + 1;
+    pad_sum += pad_data[i];
+    output_shape_data[i] = oc;
+  }
+  if (pad_sum) {
+    for (int i = 0; i < num_spatial_axes_; ++i) {
+        if ( (output_shape_data[i] - 1) * stride_data[i] >=
+          input_shape_data[i+1] + pad_data[i] )
+            --output_shape_data[i];
+        CHECK_LT((output_shape_data[i] - 1) * stride_data[i],
+          input_shape_data[i+1] + pad_data[i]);
     }
-    CHECK_LT((pooled_height_ - 1) * stride_h_, height_ + pad_h_);
-    CHECK_LT((pooled_width_ - 1) * stride_w_, width_ + pad_w_);
   }
-  top[0]->Reshape(bottom[0]->num(), channels_, pooled_height_,
-      pooled_width_);
+
+  vector<int> top_shape = bottom[0]->shape();
+  top_shape.resize(first_spatial_axis);  // Discard input spatial axes.
+  for (int i = 0; i < num_spatial_axes_; ++i) {
+      top_shape.push_back(output_shape_data[i]);
+  }
+
+
+  top[0]->Reshape(top_shape);
   if (top.size() > 1) {
     top[1]->ReshapeLike(*top[0]);
   }
+
   // If max pooling, we will initialize the vector index part.
   if (this->layer_param_.pooling_param().pool() ==
       PoolingParameter_PoolMethod_MAX && top.size() == 1) {
-    max_idx_.Reshape(bottom[0]->num(), channels_, pooled_height_,
-        pooled_width_);
+    max_idx_.Reshape(top_shape);
   }
   // If stochastic pooling, we will initialize the random index part.
   if (this->layer_param_.pooling_param().pool() ==
       PoolingParameter_PoolMethod_STOCHASTIC) {
-    rand_idx_.Reshape(bottom[0]->num(), channels_, pooled_height_,
-      pooled_width_);
+    rand_idx_.Reshape(top_shape);
   }
 }
 
 // TODO(Yangqing): Is there a faster way to do pooling in the channel-first
 // case?
 template <typename Dtype>
-void PoolingLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
+void PoolingLayer<Dtype>::Forward_cpu(
+      const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   const Dtype* bottom_data = bottom[0]->cpu_data();
   Dtype* top_data = top[0]->mutable_cpu_data();
@@ -134,6 +223,15 @@ void PoolingLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
   const bool use_top_mask = top.size() > 1;
   int* mask = NULL;  // suppress warnings about uninitalized variables
   Dtype* top_mask = NULL;
+  vector<int> offset(2, 0);
+  offset[1] = 1;
+
+  const int* kernel_shape = kernel_shape_.cpu_data();
+  const int* pad_data = this->pad_.cpu_data();
+  const int* stride_data = this->stride_.cpu_data();
+  const int* input_shape_data = this->input_shape_.cpu_data();
+  const int* output_shape_data = this->output_shape_.cpu_data();
+
   // Different pooling methods. We explicitly do the switch outside the for
   // loop to save time, although this results in more code.
   switch (this->layer_param_.pooling_param().pool()) {
@@ -148,39 +246,80 @@ void PoolingLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
     }
     caffe_set(top_count, Dtype(-FLT_MAX), top_data);
     // The main loop
-    for (int n = 0; n < bottom[0]->num(); ++n) {
+
+    for (int n = 0; n < num_; ++n) {
       for (int c = 0; c < channels_; ++c) {
-        for (int ph = 0; ph < pooled_height_; ++ph) {
-          for (int pw = 0; pw < pooled_width_; ++pw) {
-            int hstart = ph * stride_h_ - pad_h_;
-            int wstart = pw * stride_w_ - pad_w_;
-            int hend = min(hstart + kernel_h_, height_);
-            int wend = min(wstart + kernel_w_, width_);
-            hstart = max(hstart, 0);
-            wstart = max(wstart, 0);
-            const int pool_index = ph * pooled_width_ + pw;
-            for (int h = hstart; h < hend; ++h) {
-              for (int w = wstart; w < wend; ++w) {
-                const int index = h * width_ + w;
-                if (bottom_data[index] > top_data[pool_index]) {
-                  top_data[pool_index] = bottom_data[index];
-                  if (use_top_mask) {
-                    top_mask[pool_index] = static_cast<Dtype>(index);
-                  } else {
-                    mask[pool_index] = index;
+        if (num_spatial_axes_ == 2) {
+          for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+            for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+              int hstart = ph * stride_data[0] - pad_data[0];
+              int wstart = pw * stride_data[1] - pad_data[1];
+              int hend = min(hstart + kernel_shape[0], input_shape_data[1]);
+              int wend = min(wstart + kernel_shape[1], input_shape_data[2]);
+              hstart = max(hstart, 0);
+              wstart = max(wstart, 0);
+              const int pool_index = ph * output_shape_data[1] + pw;
+              for (int h = hstart; h < hend; ++h) {
+                for (int w = wstart; w < wend; ++w) {
+                  const int index = h * input_shape_data[2] + w;
+                  if (bottom_data[index] > top_data[pool_index]) {
+                    top_data[pool_index] = bottom_data[index];
+                    if (use_top_mask) {
+                      top_mask[pool_index] = static_cast<Dtype>(index);
+                    } else {
+                      mask[pool_index] = index;
+                    }
                   }
                 }
               }
             }
           }
+        } else if (num_spatial_axes_ == 3) {
+          for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+            for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+              for (int pz = 0; pz< output_shape_data[2]; ++pz) {
+                int hstart = ph * stride_data[0] - pad_data[0];
+                int wstart = pw * stride_data[1] - pad_data[1];
+                int zstart = pz * stride_data[2] - pad_data[2];
+                int hend = min(hstart + kernel_shape[0], input_shape_data[1]);
+                int wend = min(wstart + kernel_shape[1], input_shape_data[2]);
+                int zend = min(zstart + kernel_shape[2], input_shape_data[3]);
+                hstart = max(hstart, 0);
+                wstart = max(wstart, 0);
+                zstart = max(zstart, 0);
+                const int pool_index = (ph * output_shape_data[1] + pw)*
+                                                  output_shape_data[2] +pz;
+                for (int h = hstart; h < hend; ++h) {
+                  for (int w = wstart; w < wend; ++w) {
+                    for (int z = zstart; z < zend; ++z) {
+                      const int index = (h * input_shape_data[2] + w)*
+                                                    input_shape_data[3]+z;
+                      if (bottom_data[index] > top_data[pool_index]) {
+                        top_data[pool_index] = bottom_data[index];
+                        if (use_top_mask) {
+                          top_mask[pool_index] = static_cast<Dtype>(index);
+                        } else {
+                          mask[pool_index] = index;
+                        }
+                      }
+                    }
+                  }
+                }
+              }
+            }
+          }
+        } else {
+          NOT_IMPLEMENTED;
         }
         // compute offset
-        bottom_data += bottom[0]->offset(0, 1);
-        top_data += top[0]->offset(0, 1);
-        if (use_top_mask) {
-          top_mask += top[0]->offset(0, 1);
-        } else {
-          mask += top[0]->offset(0, 1);
+        if (num_ > 1 || channels_ > 1) {
+          bottom_data += bottom[0]->offset(offset);
+          top_data += top[0]->offset(offset);
+          if (use_top_mask) {
+            top_mask += top[0]->offset(offset);
+          } else {
+            mask += top[0]->offset(offset);
+          }
         }
       }
     }
@@ -190,31 +329,79 @@ void PoolingLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
       top_data[i] = 0;
     }
     // The main loop
-    for (int n = 0; n < bottom[0]->num(); ++n) {
+    // printf ("Num axes: %d\n",num_spatial_axes_);
+    for (int n = 0; n < num_; ++n) {
       for (int c = 0; c < channels_; ++c) {
-        for (int ph = 0; ph < pooled_height_; ++ph) {
-          for (int pw = 0; pw < pooled_width_; ++pw) {
-            int hstart = ph * stride_h_ - pad_h_;
-            int wstart = pw * stride_w_ - pad_w_;
-            int hend = min(hstart + kernel_h_, height_ + pad_h_);
-            int wend = min(wstart + kernel_w_, width_ + pad_w_);
-            int pool_size = (hend - hstart) * (wend - wstart);
-            hstart = max(hstart, 0);
-            wstart = max(wstart, 0);
-            hend = min(hend, height_);
-            wend = min(wend, width_);
-            for (int h = hstart; h < hend; ++h) {
-              for (int w = wstart; w < wend; ++w) {
-                top_data[ph * pooled_width_ + pw] +=
-                    bottom_data[h * width_ + w];
+          if (num_spatial_axes_ == 2) {
+            for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+              for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+                int hstart = ph * stride_data[0] - pad_data[0];
+                int wstart = pw * stride_data[1] - pad_data[1];
+                int hend = min(hstart + kernel_shape[0],
+                         input_shape_data[1] + pad_data[0]);
+                int wend = min(wstart + kernel_shape[1],
+                         input_shape_data[2] + pad_data[1]);
+                int pool_size = (hend - hstart) * (wend - wstart);
+                hstart = max(hstart, 0);
+                wstart = max(wstart, 0);
+                hend = min(hend, input_shape_data[1]);
+                wend = min(wend, input_shape_data[2]);
+                const int pool_index = ph * output_shape_data[1] + pw;
+                for (int h = hstart; h < hend; ++h) {
+                  for (int w = wstart; w < wend; ++w) {
+                    const int index = h * input_shape_data[2] + w;
+                    top_data[pool_index] += bottom_data[index];
+                  }
+                }
+                top_data[pool_index] /= pool_size;
               }
             }
-            top_data[ph * pooled_width_ + pw] /= pool_size;
-          }
+        } else if (num_spatial_axes_ == 3) {
+            for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+              for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+                for (int pz = 0; pz< output_shape_data[2]; ++pz) {
+                  int hstart = ph * stride_data[0] - pad_data[0];
+                  int wstart = pw * stride_data[1] - pad_data[1];
+                  int zstart = pz * stride_data[2] - pad_data[2];
+                  int hend = min(hstart + kernel_shape[0],
+                            input_shape_data[1]+ pad_data[0]);
+                  int wend = min(wstart + kernel_shape[1],
+                          input_shape_data[2]+ pad_data[1]);
+                  int zend = min(zstart + kernel_shape[2],
+                           input_shape_data[3]+ pad_data[2]);
+                  int pool_size = (hend - hstart) *
+                                  (wend - wstart) *
+                                  (zend - zstart);
+                  hstart = max(hstart, 0);
+                  wstart = max(wstart, 0);
+                  zstart = max(zstart, 0);
+                  hend = min(hend, input_shape_data[1]);
+                  wend = min(wend, input_shape_data[2]);
+                  zend = min(zend, input_shape_data[3]);
+
+                  const int pool_index = (ph * output_shape_data[1] + pw)*
+                                                  output_shape_data[2] +pz;
+                  for (int h = hstart; h < hend; ++h) {
+                    for (int w = wstart; w < wend; ++w) {
+                      for (int z = zstart; z < zend; ++z) {
+                        const int index = (h * input_shape_data[2] + w)*
+                                                      input_shape_data[3]+z;
+                        top_data[pool_index] += bottom_data[index];
+                      }
+                    }
+                  }
+                  top_data[pool_index] /= pool_size;
+                }
+              }
+            }
+        } else {
+          NOT_IMPLEMENTED;
         }
         // compute offset
-        bottom_data += bottom[0]->offset(0, 1);
-        top_data += top[0]->offset(0, 1);
+        if (num_ > 1 || channels_ > 1) {
+          bottom_data += bottom[0]->offset(offset);
+          top_data += top[0]->offset(offset);
+        }
       }
     }
     break;
@@ -241,6 +428,15 @@ void PoolingLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
   const bool use_top_mask = top.size() > 1;
   const int* mask = NULL;  // suppress warnings about uninitialized variables
   const Dtype* top_mask = NULL;
+
+  const int* kernel_shape = this->kernel_shape_.cpu_data();
+  const int* pad_data = this->pad_.cpu_data();
+  const int* stride_data = this->stride_.cpu_data();
+  const int* input_shape_data = this->input_shape_.cpu_data();
+  const int* output_shape_data = this->output_shape_.cpu_data();
+  int top_num = top[0]->count(0, channel_axis_);
+  vector<int> offset(2, 0);
+  offset[1] = 1;
   switch (this->layer_param_.pooling_param().pool()) {
   case PoolingParameter_PoolMethod_MAX:
     // The main loop
@@ -249,52 +445,115 @@ void PoolingLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
     } else {
       mask = max_idx_.cpu_data();
     }
-    for (int n = 0; n < top[0]->num(); ++n) {
+    for (int n = 0; n < top_num; ++n) {
       for (int c = 0; c < channels_; ++c) {
-        for (int ph = 0; ph < pooled_height_; ++ph) {
-          for (int pw = 0; pw < pooled_width_; ++pw) {
-            const int index = ph * pooled_width_ + pw;
-            const int bottom_index =
-                use_top_mask ? top_mask[index] : mask[index];
-            bottom_diff[bottom_index] += top_diff[index];
+        if (num_spatial_axes_ == 2) {
+          for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+            for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+              const int index = ph * output_shape_data[1] + pw;
+              const int bottom_index =
+                  use_top_mask ? top_mask[index] : mask[index];
+              bottom_diff[bottom_index] += top_diff[index];
+            }
+          }
+        } else if (num_spatial_axes_ == 3) {
+            for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+              for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+                for (int pz = 0; pz < output_shape_data[2]; ++pz) {
+                const int index = (ph * output_shape_data[1] + pw)*
+                                            output_shape_data[2] +pz;
+                const int bottom_index =
+                    use_top_mask ? top_mask[index] : mask[index];
+                bottom_diff[bottom_index] += top_diff[index];
+              }
+            }
           }
-        }
-        bottom_diff += bottom[0]->offset(0, 1);
-        top_diff += top[0]->offset(0, 1);
-        if (use_top_mask) {
-          top_mask += top[0]->offset(0, 1);
         } else {
-          mask += top[0]->offset(0, 1);
+          NOT_IMPLEMENTED;
+        }
+        if (num_ > 1 || channels_ > 1) {
+          bottom_diff += bottom[0]->offset(offset);
+          top_diff += top[0]->offset(offset);
+          if (use_top_mask) {
+            top_mask += top[0]->offset(offset);
+          } else {
+            mask += top[0]->offset(offset);
+          }
         }
       }
     }
     break;
   case PoolingParameter_PoolMethod_AVE:
     // The main loop
-    for (int n = 0; n < top[0]->num(); ++n) {
+    for (int n = 0; n < top_num; ++n) {
       for (int c = 0; c < channels_; ++c) {
-        for (int ph = 0; ph < pooled_height_; ++ph) {
-          for (int pw = 0; pw < pooled_width_; ++pw) {
-            int hstart = ph * stride_h_ - pad_h_;
-            int wstart = pw * stride_w_ - pad_w_;
-            int hend = min(hstart + kernel_h_, height_ + pad_h_);
-            int wend = min(wstart + kernel_w_, width_ + pad_w_);
-            int pool_size = (hend - hstart) * (wend - wstart);
-            hstart = max(hstart, 0);
-            wstart = max(wstart, 0);
-            hend = min(hend, height_);
-            wend = min(wend, width_);
-            for (int h = hstart; h < hend; ++h) {
-              for (int w = wstart; w < wend; ++w) {
-                bottom_diff[h * width_ + w] +=
-                  top_diff[ph * pooled_width_ + pw] / pool_size;
+        if (num_spatial_axes_ == 2) {
+          for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+            for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+              int hstart = ph * stride_data[0] - pad_data[0];
+              int wstart = pw * stride_data[1] - pad_data[1];
+              int hend = min(hstart + kernel_shape[0],
+                            input_shape_data[1]+pad_data[0]);
+              int wend = min(wstart + kernel_shape[1],
+                            input_shape_data[2]+pad_data[1]);
+
+              int pool_size = (hend - hstart) * (wend - wstart);
+              hstart = max(hstart, 0);
+              wstart = max(wstart, 0);
+              hend = min(hend, input_shape_data[1]);
+              wend = min(wend, input_shape_data[2]);
+
+
+              const int pool_index = ph * output_shape_data[1] + pw;
+              for (int h = hstart; h < hend; ++h) {
+                for (int w = wstart; w < wend; ++w) {
+                  const int index = h * input_shape_data[2] + w;
+                  bottom_diff[index] +=
+                    top_diff[pool_index] / pool_size;
+                }
               }
             }
           }
+        } else if (num_spatial_axes_ == 3) {
+            for (int ph = 0; ph < output_shape_data[0]; ++ph) {
+              for (int pw = 0; pw < output_shape_data[1]; ++pw) {
+                for (int pz = 0; pz< output_shape_data[2]; ++pz) {
+                  int hstart = ph * stride_data[0] - pad_data[0];
+                  int wstart = pw * stride_data[1] - pad_data[1];
+                  int zstart = pz * stride_data[2] - pad_data[2];
+                  int hend = min(hstart + kernel_shape[0], input_shape_data[1]);
+                  int wend = min(wstart + kernel_shape[1], input_shape_data[2]);
+                  int zend = min(zstart + kernel_shape[2], input_shape_data[3]);
+                  hstart = max(hstart, 0);
+                  wstart = max(wstart, 0);
+                  zstart = max(zstart, 0);
+                  const int pool_index = (ph * output_shape_data[1] + pw)*
+                                                    output_shape_data[2] +pz;
+                  int pool_size = (hend - hstart) *
+                                  (wend - wstart) *
+                                  (zend - zstart);
+                  for (int h = hstart; h < hend; ++h) {
+                    for (int w = wstart; w < wend; ++w) {
+                      for (int z = zstart; z < zend; ++z) {
+                        const int index = (h * input_shape_data[2] + w)*
+                                                      input_shape_data[3]+z;
+                        bottom_diff[index] +=
+                                      top_diff[pool_index] / pool_size;
+                      }
+                    }
+                  }
+                }
+              }
+            }
+        } else {
+          NOT_IMPLEMENTED;
         }
+
         // offset
-        bottom_diff += bottom[0]->offset(0, 1);
-        top_diff += top[0]->offset(0, 1);
+        if (num_ > 1 || channels_ > 1) {
+          bottom_diff += bottom[0]->offset(offset);
+          top_diff += top[0]->offset(offset);
+        }
       }
     }
     break;
diff --git a/src/caffe/layers/pooling_layer.cu b/src/caffe/layers/pooling_layer.cu
index 1ea46cc..a3ab96f 100644
--- a/src/caffe/layers/pooling_layer.cu
+++ b/src/caffe/layers/pooling_layer.cu
@@ -2,38 +2,93 @@
 #include <cfloat>
 #include <vector>
 
-#include "caffe/layers/pooling_layer.hpp"
 #include "caffe/util/math_functions.hpp"
-
+#include "caffe/layers/pooling_layer.hpp"
+#define MAX_SPATIAL_AXES 10
 namespace caffe {
 
 template <typename Dtype>
 __global__ void MaxPoolForward(const int nthreads,
-    const Dtype* const bottom_data, const int num, const int channels,
-    const int height, const int width, const int pooled_height,
-    const int pooled_width, const int kernel_h, const int kernel_w,
-    const int stride_h, const int stride_w, const int pad_h, const int pad_w,
-    Dtype* const top_data, int* mask, Dtype* top_mask) {
+    const Dtype* bottom_data,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride,
+    const int* pad, Dtype* top_data,
+    int* mask, Dtype* top_mask) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    const int pw = index % pooled_width;
-    const int ph = (index / pooled_width) % pooled_height;
-    const int c = (index / pooled_width / pooled_height) % channels;
-    const int n = index / pooled_width / pooled_height / channels;
-    int hstart = ph * stride_h - pad_h;
-    int wstart = pw * stride_w - pad_w;
-    const int hend = min(hstart + kernel_h, height);
-    const int wend = min(wstart + kernel_w, width);
-    hstart = max(hstart, 0);
-    wstart = max(wstart, 0);
+    // ind2sub
+    int k = index;
+    for (int i = num_axes-1; i >= 0; --i) {
+      pool_loc[i] = k % pooled_shape[i];
+      k /= pooled_shape[i];
+    }
+    int c = k % channels;
+    int n = k / channels;
+    // Get starts and calc size (sub2ind)
+    int start, end;
+    int im_size = 1;
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] = pool_loc[i]*stride[i] - pad[i];
+      ends[i] = min(starts[i]+kernel_shape[i], im_shape[i+1]);
+      starts[i] = max(starts[i], 0);
+      ends[i] = min(ends[i], im_shape[i+1]);
+      if (i > 0) {
+        start = start*im_shape[i+1]+starts[i];
+        end = end*im_shape[i+1]+ends[i];
+      } else {
+        start = starts[0];
+        end = ends[0];
+      }
+      im_size *= im_shape[i+1];
+    }
+    // get input kernel and compute pool
     Dtype maxval = -FLT_MAX;
     int maxidx = -1;
-    const Dtype* const bottom_slice =
-        bottom_data + (n * channels + c) * height * width;
-    for (int h = hstart; h < hend; ++h) {
-      for (int w = wstart; w < wend; ++w) {
-        if (bottom_slice[h * width + w] > maxval) {
-          maxidx = h * width + w;
-          maxval = bottom_slice[maxidx];
+    bottom_data += (n * channels + c) * im_size;
+    if ( num_axes ==2 ) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          const int bottom_index = h * im_shape[2] + w;
+          if ( bottom_data[bottom_index] > maxval ) {
+              maxidx = bottom_index;
+              maxval = bottom_data[maxidx];
+          }
+        }
+      }
+    } else if (num_axes == 3) {
+        for (int h = starts[0]; h < ends[0]; ++h) {
+          for (int w = starts[1]; w < ends[1]; ++w) {
+            for (int z = starts[2]; z < ends[2]; ++z) {
+              const int bottom_index = (h * im_shape[2] + w)*im_shape[3]+z;
+              if ( bottom_data[bottom_index] > maxval ) {
+                  maxidx = bottom_index;
+                  maxval = bottom_data[maxidx];
+              }
+            }
+          }
+        }
+    } else {
+      for (int bottom_index = start; bottom_index < end; ++bottom_index) {
+        bool in_range = true;
+        // ind2sub
+        int m = bottom_index;
+        for (int j = num_axes-1; j >= 0; --j) {
+          im_loc[j] = m % im_shape[j+1];
+          m /= im_shape[j+1];
+          in_range &= (m < im_shape[j+1])&&
+                      (im_loc[j] >= starts[j])&&
+                      (im_loc[j] < ends[j]);
+          if (!in_range) { break; }
+        }
+        if ( in_range ) {
+          if (bottom_data[bottom_index] > maxval) {
+            maxval = bottom_data[bottom_index];
+            maxidx = bottom_index;
+          }
         }
       }
     }
@@ -48,31 +103,83 @@ __global__ void MaxPoolForward(const int nthreads,
 
 template <typename Dtype>
 __global__ void AvePoolForward(const int nthreads,
-    const Dtype* const bottom_data, const int num, const int channels,
-    const int height, const int width, const int pooled_height,
-    const int pooled_width, const int kernel_h, const int kernel_w,
-    const int stride_h, const int stride_w, const int pad_h, const int pad_w,
-    Dtype* const top_data) {
+    const Dtype* bottom_data,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride, const int* pad,
+    Dtype* top_data) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    const int pw = index % pooled_width;
-    const int ph = (index / pooled_width) % pooled_height;
-    const int c = (index / pooled_width / pooled_height) % channels;
-    const int n = index / pooled_width / pooled_height / channels;
-    int hstart = ph * stride_h - pad_h;
-    int wstart = pw * stride_w - pad_w;
-    int hend = min(hstart + kernel_h, height + pad_h);
-    int wend = min(wstart + kernel_w, width + pad_w);
-    const int pool_size = (hend - hstart) * (wend - wstart);
-    hstart = max(hstart, 0);
-    wstart = max(wstart, 0);
-    hend = min(hend, height);
-    wend = min(wend, width);
+    // ind2sub
+    int k = index;
+    for (int i = num_axes-1; i >=0; --i) {
+      pool_loc[i] = k % pooled_shape[i];
+      k /= pooled_shape[i];
+    }
+    int c = k % channels;
+    int n = k / channels;
+
+    // Get starts and calc size (sub2ind)
+    int pool_size = 1;
+    int start, end;
+    int im_size = 1;
+
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] = pool_loc[i]*stride[i] - pad[i];
+      ends[i] = min(starts[i]+kernel_shape[i], im_shape[i+1] + pad[i]);
+      int s1 = ends[i];
+      int s2 = starts[i];
+      pool_size *= (s1 - s2);
+      starts[i] = max(starts[i], 0);
+      if (i > 0) {
+        start = start*im_shape[i+1]+starts[i];
+        end = end*im_shape[i+1]+ends[i];
+      } else {
+        start = starts[0];
+        end = ends[0];
+      }
+      ends[i] = min(ends[i], im_shape[i+1]);
+      im_size *= im_shape[i+1];
+    }
+
     Dtype aveval = 0;
-    const Dtype* const bottom_slice =
-        bottom_data + (n * channels + c) * height * width;
-    for (int h = hstart; h < hend; ++h) {
-      for (int w = wstart; w < wend; ++w) {
-        aveval += bottom_slice[h * width + w];
+    bottom_data += (n * channels + c) * im_size;
+
+    if (num_axes == 2) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          const int bottom_index = h * im_shape[2] + w;
+          aveval += bottom_data[bottom_index];
+        }
+      }
+    } else if (num_axes == 3) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          for (int z = starts[2]; z < ends[2]; ++z) {
+            const int bottom_index = (h * im_shape[2] + w)*im_shape[3]+z;
+            aveval += bottom_data[bottom_index];
+          }
+        }
+      }
+    } else {
+      for (int bottom_index = start; bottom_index < end; ++bottom_index) {
+        bool in_range = true;
+        // ind2sub
+        int m = bottom_index;
+        for (int j = num_axes-1; j >= 0; --j) {
+          im_loc[j] = m % im_shape[j+1];
+          m /= im_shape[j+1];
+          in_range &= (m < im_shape[j+1])&&
+                      (im_loc[j] >= starts[j])&&
+                      (im_loc[j] < ends[j]);
+          if ( !in_range ) { break; }
+        }
+        if ( in_range ) {
+          aveval += bottom_data[bottom_index];
+        }
       }
     }
     top_data[index] = aveval / pool_size;
@@ -81,39 +188,128 @@ __global__ void AvePoolForward(const int nthreads,
 
 template <typename Dtype>
 __global__ void StoPoolForwardTrain(const int nthreads,
-    const Dtype* const bottom_data,
-    const int num, const int channels, const int height,
-    const int width, const int pooled_height, const int pooled_width,
-    const int kernel_h, const int kernel_w, const int stride_h,
-    const int stride_w, Dtype* const rand_idx, Dtype* const top_data) {
+  const Dtype* bottom_data,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride,
+    Dtype* rand_idx, Dtype* top_data) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    const int pw = index % pooled_width;
-    const int ph = (index / pooled_width) % pooled_height;
-    const int c = (index / pooled_width / pooled_height) % channels;
-    const int n = index / pooled_width / pooled_height / channels;
-    const int hstart = ph * stride_h;
-    const int hend = min(hstart + kernel_h, height);
-    const int wstart = pw * stride_w;
-    const int wend = min(wstart + kernel_w, width);
+    // ind2sub
+    int k = index;
+    for (int i = num_axes-1; i >=0; --i) {
+      pool_loc[i] = k % pooled_shape[i];
+      k /= pooled_shape[i];
+    }
+    int c = k % channels;
+    int n = k / channels;
+
+    // Get starts and calc size (sub2ind)
+    int pool_size = 1;
+    int start, end;
+    int im_size = 1;
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] = pool_loc[i]*stride[i];
+      ends[i] = min(starts[i]+kernel_shape[i], im_shape[i+1]);
+      int s1 = ends[i];
+      int s2 = starts[i];
+      pool_size *= (s1 - s2);
+      im_size *= im_shape[i+1];
+      if (i > 0) {
+        start = start*im_shape[i+1]+starts[i];
+        end = end*im_shape[i+1]+ends[i];
+      } else {
+        start = starts[0];
+        end = ends[0];
+      }
+    }
     Dtype cumsum = 0.;
-    const Dtype* const bottom_slice =
-        bottom_data + (n * channels + c) * height * width;
+    bottom_data += (n * channels + c) * im_size;
     // First pass: get sum
-    for (int h = hstart; h < hend; ++h) {
-      for (int w = wstart; w < wend; ++w) {
-        cumsum += bottom_slice[h * width + w];
+    if ( num_axes == 2 ) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          const int bottom_index = h * im_shape[2] + w;
+          cumsum += bottom_data[bottom_index];
+        }
+      }
+    } else if ( num_axes == 3 ) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          for (int z = starts[2]; z < ends[2]; ++z) {
+            const int bottom_index = (h * im_shape[2] + w)*im_shape[3]+z;
+            cumsum += bottom_data[bottom_index];
+          }
+        }
+      }
+    } else {
+      for (int bottom_index = start; bottom_index < end; ++bottom_index) {
+        bool in_range = true;
+        // ind2sub
+        int m = bottom_index;
+        for (int j = num_axes-1; j >= 0; --j) {
+          im_loc[j] = m % im_shape[j+1];
+          m /= im_shape[j+1];
+          in_range &= (m < im_shape[j+1])&&
+                      (im_loc[j] >= starts[j])&&
+                      (im_loc[j] < ends[j]);
+          if (!in_range) { break;}
+        }
+        if ( in_range ) {
+          cumsum += bottom_data[bottom_index];
+        }
       }
     }
-    const float thres = rand_idx[index] * cumsum;
+
+    float thres = rand_idx[index] * cumsum;
     // Second pass: get value, and set index.
     cumsum = 0;
-    for (int h = hstart; h < hend; ++h) {
-      for (int w = wstart; w < wend; ++w) {
-        cumsum += bottom_slice[h * width + w];
-        if (cumsum >= thres) {
-          rand_idx[index] = ((n * channels + c) * height + h) * width + w;
-          top_data[index] = bottom_slice[h * width + w];
-          return;
+    if ( num_axes == 2 ) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          const int bottom_index = h * im_shape[2] + w;
+          cumsum += bottom_data[bottom_index];
+          if (cumsum >= thres) {
+            rand_idx[index] = ((n * channels + c) * im_size) + bottom_index;
+            top_data[index] = bottom_data[bottom_index];
+          }
+        }
+      }
+    } else if (num_axes == 3) {
+      for (int h = starts[0]; h < ends[0]; ++h) {
+        for (int w = starts[1]; w < ends[1]; ++w) {
+          for (int z = starts[2]; z < ends[2]; ++z) {
+            const int bottom_index = (h * im_shape[2] + w)*im_shape[3]+z;
+            cumsum += bottom_data[bottom_index];
+            if (cumsum >= thres) {
+              rand_idx[index] = ((n * channels + c) * im_size) + bottom_index;
+              top_data[index] = bottom_data[bottom_index];
+            }
+          }
+        }
+      }
+    } else {
+      for (int bottom_index = start; bottom_index < end; ++bottom_index) {
+        bool in_range = true;
+        // ind2sub
+        int m = bottom_index;
+        for (int j = num_axes-1; j >= 0; --j) {
+          im_loc[j] = m % im_shape[j+1];
+          m /= im_shape[j+1];
+          in_range &= (m < im_shape[j+1])&&
+                      (im_loc[j] >= starts[j])&&
+                      (im_loc[j] < ends[j]);
+          if ( !in_range ) { break; }
+        }
+        if ( in_range ) {
+          if (cumsum >= thres) {
+            rand_idx[index] = ((n * channels + c) * im_size) + bottom_index;
+            top_data[index] = bottom_data[bottom_index];
+            return;
+          }
         }
       }
     }
@@ -123,30 +319,64 @@ __global__ void StoPoolForwardTrain(const int nthreads,
 
 template <typename Dtype>
 __global__ void StoPoolForwardTest(const int nthreads,
-    const Dtype* const bottom_data,
-    const int num, const int channels, const int height,
-    const int width, const int pooled_height, const int pooled_width,
-    const int kernel_h, const int kernel_w, const int stride_h,
-    const int stride_w, Dtype* const top_data) {
+    const Dtype* bottom_data,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride,
+    Dtype* top_data) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    const int pw = index % pooled_width;
-    const int ph = (index / pooled_width) % pooled_height;
-    const int c = (index / pooled_width / pooled_height) % channels;
-    const int n = index / pooled_width / pooled_height / channels;
-    const int hstart = ph * stride_h;
-    const int hend = min(hstart + kernel_h, height);
-    const int wstart = pw * stride_w;
-    const int wend = min(wstart + kernel_w, width);
-    // We set cumsum to be 0 to avoid divide-by-zero problems
+    // ind2sub
+    int k = index;
+    for (int i = num_axes-1; i >= 0; --i) {
+      pool_loc[i] = k % pooled_shape[i];
+      k /= pooled_shape[i];
+    }
+    int c = k % channels;
+    int n = k / channels;
+
+    // Get starts and calc size (sub2ind)
+    int pool_size = 1;
+    int start, end;
+    int im_size = 1;
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] = pool_loc[i]*stride[i];
+      ends[i] = min(starts[i]+kernel_shape[i], im_shape[i+1]);
+      int s1 = ends[i];
+      int s2 = starts[i];
+      pool_size *= (s1 - s2);
+      starts[i] = max(starts[i], 0);
+      im_size *= im_shape[i+1];
+      if (i > 0) {
+        start = start*im_shape[i+1]+starts[i];
+        end = end*im_shape[i+1]+ends[i];
+      } else {
+        start = starts[0];
+        end = ends[0];
+      }
+    }
     Dtype cumsum = FLT_MIN;
     Dtype cumvalues = 0.;
-    const Dtype* const bottom_slice =
-        bottom_data + (n * channels + c) * height * width;
+    bottom_data += (n * channels + c) * im_size;
     // First pass: get sum
-    for (int h = hstart; h < hend; ++h) {
-      for (int w = wstart; w < wend; ++w) {
-        cumsum += bottom_slice[h * width + w];
-        cumvalues += bottom_slice[h * width + w] * bottom_slice[h * width + w];
+    for (int bottom_index = start; bottom_index < end; ++bottom_index) {
+      bool in_range = true;
+      // ind2sub
+      int m = bottom_index;
+      for (int j = num_axes-1; j >= 0; --j) {
+        im_loc[j] = m % im_shape[j+1];
+        m /= im_shape[j+1];
+        in_range &= (m < im_shape[j+1])&&
+                    (im_loc[j] >= starts[j])&&
+                    (im_loc[j] < ends[j]);
+        if (!in_range) { break;}
+      }
+      if (in_range) {
+        cumsum += bottom_data[bottom_index];
+        cumvalues += bottom_data[bottom_index] * bottom_data[bottom_index];
       }
     }
     top_data[index] = cumvalues / cumsum;
@@ -155,7 +385,8 @@ __global__ void StoPoolForwardTest(const int nthreads,
 
 
 template <typename Dtype>
-void PoolingLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
+void PoolingLayer<Dtype>::Forward_gpu(
+      const vector<Blob<Dtype>*>& bottom,
       const vector<Blob<Dtype>*>& top) {
   const Dtype* bottom_data = bottom[0]->gpu_data();
   Dtype* top_data = top[0]->mutable_gpu_data();
@@ -166,6 +397,7 @@ void PoolingLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
   Dtype* top_mask = NULL;
   switch (this->layer_param_.pooling_param().pool()) {
   case PoolingParameter_PoolMethod_MAX:
+  // printf("Forward_gpuMAX\n");
     if (use_top_mask) {
       top_mask = top[1]->mutable_gpu_data();
     } else {
@@ -173,17 +405,19 @@ void PoolingLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
     }
     // NOLINT_NEXT_LINE(whitespace/operators)
     MaxPoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, bottom_data, bottom[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_, kernel_h_,
-        kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, top_data,
+        count, bottom_data, num_, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(), pad_.gpu_data(), top_data,
         mask, top_mask);
     break;
   case PoolingParameter_PoolMethod_AVE:
     // NOLINT_NEXT_LINE(whitespace/operators)
     AvePoolForward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, bottom_data, bottom[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_, kernel_h_,
-        kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, top_data);
+        count, bottom_data,  num_, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(), pad_.gpu_data(), top_data);
     break;
   case PoolingParameter_PoolMethod_STOCHASTIC:
     if (this->phase_ == TRAIN) {
@@ -193,17 +427,19 @@ void PoolingLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
       // NOLINT_NEXT_LINE(whitespace/operators)
       StoPoolForwardTrain<Dtype><<<CAFFE_GET_BLOCKS(count),
                                    CAFFE_CUDA_NUM_THREADS>>>(
-          count, bottom_data, bottom[0]->num(), channels_,
-          height_, width_, pooled_height_, pooled_width_, kernel_h_,
-          kernel_w_, stride_h_, stride_w_,
+        count, bottom_data,  num_, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(),
           rand_idx_.mutable_gpu_data(), top_data);
     } else {
       // NOLINT_NEXT_LINE(whitespace/operators)
       StoPoolForwardTest<Dtype><<<CAFFE_GET_BLOCKS(count),
                                   CAFFE_CUDA_NUM_THREADS>>>(
-          count, bottom_data, bottom[0]->num(), channels_,
-          height_, width_, pooled_height_, pooled_width_, kernel_h_,
-          kernel_w_, stride_h_, stride_w_, top_data);
+          count, bottom_data,  num_, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(), top_data);
     }
     break;
   default:
@@ -214,116 +450,280 @@ void PoolingLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom,
 
 
 template <typename Dtype>
-__global__ void MaxPoolBackward(const int nthreads, const Dtype* const top_diff,
-    const int* const mask, const Dtype* const top_mask, const int num,
-    const int channels, const int height, const int width,
-    const int pooled_height, const int pooled_width, const int kernel_h,
-    const int kernel_w, const int stride_h, const int stride_w, const int pad_h,
-    const int pad_w, Dtype* const bottom_diff) {
+__global__ void MaxPoolBackward(const int nthreads,
+    const Dtype* top_diff,
+    const int* mask, const Dtype* top_mask,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride, const int* pad,
+    Dtype* bottom_diff) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    // find out the local index
-    // find out the local offset
-    const int w = index % width;
-    const int h = (index / width) % height;
-    const int c = (index / width / height) % channels;
-    const int n = index / width / height / channels;
-    const int phstart =
-         (h + pad_h < kernel_h) ? 0 : (h + pad_h - kernel_h) / stride_h + 1;
-    const int phend = min((h + pad_h) / stride_h + 1, pooled_height);
-    const int pwstart =
-         (w + pad_w < kernel_w) ? 0 : (w + pad_w - kernel_w) / stride_w + 1;
-    const int pwend = min((w + pad_w) / stride_w + 1, pooled_width);
+    int k = index;
+    for (int i = num_axes-1; i >= 0; --i) {
+      im_loc[i] = k % im_shape[i+1];
+      k /= im_shape[i+1];
+    }
+    int c = k % channels;
+    int n = k / channels;
+    int shift_size = 1;
+    int start, end;
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] =
+       (im_loc[i]+pad[i] < kernel_shape[i]) ? 0 :
+       (im_loc[i] + pad[i] - kernel_shape[i]) / stride[i] + 1;
+      ends[i] = min((im_loc[i]+pad[i]) / stride[i] + 1, pooled_shape[i]);
+      shift_size *= pooled_shape[i];
+      if (num_axes > 0) {
+        if (i > 0) {
+          start = start*pooled_shape[i]+starts[i];
+          end = end*pooled_shape[i]+ends[i];
+        } else {
+          start = starts[0];
+          end = ends[0];
+      }
+      }
+    }
     Dtype gradient = 0;
-    const int offset = (n * channels + c) * pooled_height * pooled_width;
-    const Dtype* const top_diff_slice = top_diff + offset;
-    if (mask) {
-      const int* const mask_slice = mask + offset;
-      for (int ph = phstart; ph < phend; ++ph) {
-        for (int pw = pwstart; pw < pwend; ++pw) {
-          if (mask_slice[ph * pooled_width + pw] == h * width + w) {
-            gradient += top_diff_slice[ph * pooled_width + pw];
-          }
+    bool use_top_mask = !(mask);
+    int offset = (n * channels + c) * shift_size;
+    top_diff += offset;
+    mask += offset;
+    top_mask += offset;
+    if (num_axes == 2) {
+      for (int ph = starts[0]; ph < ends[0]; ++ph) {
+        for (int pw = starts[1]; pw < ends[1]; ++pw) {
+          const int top_index = ph * pooled_shape[1] + pw;
+          const int im_index = im_loc[0] * im_shape[2] + im_loc[1];
+          const int index_match =
+                use_top_mask ? top_mask[top_index] : mask[top_index];
+          if (index_match == im_index)
+              gradient += top_diff[top_index];
         }
       }
+    } else if (num_axes == 3) {
+          for (int ph = starts[0]; ph < ends[0]; ++ph) {
+            for (int pw = starts[1]; pw < ends[1]; ++pw) {
+              for (int pz = starts[2]; pz < ends[2]; ++pz) {
+                const int top_index = (ph * pooled_shape[1] + pw)*
+                                                  pooled_shape[2] + pz;
+                const int im_index = (im_loc[0] * im_shape[2] + im_loc[1])*
+                                                  im_shape[3] + im_loc[2];
+                const int index_match =
+                      use_top_mask ? top_mask[top_index] : mask[top_index];
+                if (index_match == im_index)
+                    gradient += top_diff[top_index];
+              }
+            }
+          }
     } else {
-      const Dtype* const top_mask_slice = top_mask + offset;
-      for (int ph = phstart; ph < phend; ++ph) {
-        for (int pw = pwstart; pw < pwend; ++pw) {
-          if (top_mask_slice[ph * pooled_width + pw] == h * width + w) {
-            gradient += top_diff_slice[ph * pooled_width + pw];
+        // ND is slower...
+        for (int top_index = start; top_index < end; ++top_index) {
+          bool in_range = true;
+          // ind2sub
+          int m = top_index;
+          for (int j = num_axes-1; j >= 0; --j) {
+            pool_loc[j] = m % pooled_shape[j];
+            m /= pooled_shape[j];
+            in_range &= (m < pooled_shape[j])&&
+                        (pool_loc[j] >= starts[j])&&
+                        (pool_loc[j] < ends[j]);
+            if (!in_range) { break;}
+          }
+          if (in_range) {
+            int im_index = im_loc[0];
+            for (int i = 1; i < num_axes; ++i) {
+              im_index = im_index*im_shape[i+1]+im_loc[i];
+            }
+            const int index_match =
+                        use_top_mask ? top_mask[top_index] : mask[top_index];
+            if (index_match == im_index)
+                gradient += top_diff[top_index];
           }
         }
-      }
     }
     bottom_diff[index] = gradient;
   }
 }
 
 template <typename Dtype>
-__global__ void AvePoolBackward(const int nthreads, const Dtype* const top_diff,
-    const int num, const int channels, const int height,
-    const int width, const int pooled_height, const int pooled_width,
-    const int kernel_h, const int kernel_w, const int stride_h,
-    const int stride_w, const int pad_h, const int pad_w,
-    Dtype* const bottom_diff) {
+__global__ void AvePoolBackward(const int nthreads, const Dtype* top_diff,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride, const int* pad,
+    Dtype* bottom_diff) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    // find out the local index
-    // find out the local offset
-    const int w = index % width + pad_w;
-    const int h = (index / width) % height + pad_h;
-    const int c = (index / width / height) % channels;
-    const int n = index / width / height / channels;
-    const int phstart = (h < kernel_h) ? 0 : (h - kernel_h) / stride_h + 1;
-    const int phend = min(h / stride_h + 1, pooled_height);
-    const int pwstart = (w < kernel_w) ? 0 : (w - kernel_w) / stride_w + 1;
-    const int pwend = min(w / stride_w + 1, pooled_width);
+    // ind2sub
+    int k = index;
+    for (int i = num_axes-1; i >= 0; --i) {
+      im_loc[i] = (k % im_shape[i+1])+pad[i];
+      k /= im_shape[i+1];
+    }
+    int c = k % channels;
+    int n = k / channels;
+    int shift_size = 1;
+    int start, end;
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] =
+      (im_loc[i] < kernel_shape[i]) ? 0 :
+      (im_loc[i] - kernel_shape[i]) / stride[i] + 1;
+      ends[i] = min(im_loc[i] / stride[i] + 1, pooled_shape[i]);
+      shift_size *= pooled_shape[i];
+      if (num_axes > 3) {
+        // obtain the stop index for ND calculation.
+        if (i > 0) {
+          start = start*pooled_shape[i]+starts[i];
+          end = end*pooled_shape[i]+ends[i];
+        } else {
+          start = starts[0];
+          end = ends[0];
+        }
+      }
+    }
+    int pool_size;
     Dtype gradient = 0;
-    const Dtype* const top_diff_slice =
-        top_diff + (n * channels + c) * pooled_height * pooled_width;
-    for (int ph = phstart; ph < phend; ++ph) {
-      for (int pw = pwstart; pw < pwend; ++pw) {
-        // figure out the pooling size
-        int hstart = ph * stride_h - pad_h;
-        int wstart = pw * stride_w - pad_w;
-        int hend = min(hstart + kernel_h, height + pad_h);
-        int wend = min(wstart + kernel_w, width + pad_w);
-        int pool_size = (hend - hstart) * (wend - wstart);
-        gradient += top_diff_slice[ph * pooled_width + pw] / pool_size;
+    top_diff += (n * channels + c) * shift_size;
+    if (num_axes == 2) {
+      for (int ph = starts[0]; ph < ends[0]; ++ph) {
+        for (int pw = starts[1]; pw < ends[1]; ++pw) {
+          int hstart = ph * stride[0] - pad[0];
+          int wstart = pw * stride[1] - pad[1];
+          int hend = min(hstart + kernel_shape[0], im_shape[1] + pad[0]);
+          int wend = min(wstart + kernel_shape[1], im_shape[2] + pad[1]);
+          pool_size = (hend - hstart) * (wend - wstart);
+          gradient += top_diff[ph * pooled_shape[1] + pw] / pool_size;
+        }
       }
+    } else if (num_axes == 3) {
+      for (int ph = starts[0]; ph < ends[0]; ++ph) {
+        for (int pw = starts[1]; pw < ends[1]; ++pw) {
+          for (int pz = starts[2]; pz < ends[2]; ++pz) {
+            int hstart = ph * stride[0] - pad[0];
+            int wstart = pw * stride[1] - pad[1];
+            int zstart = pz * stride[2] - pad[2];
+            int hend = min(hstart + kernel_shape[0], im_shape[1] + pad[0]);
+            int wend = min(wstart + kernel_shape[1], im_shape[2] + pad[1]);
+            int zend = min(wstart + kernel_shape[2], im_shape[3] + pad[2]);
+            pool_size = (hend - hstart)*
+                        (wend - wstart)*
+                        (zend - zstart);
+            gradient += top_diff[(ph * pooled_shape[1] + pw)*
+                                  pooled_shape[2]+pz] / pool_size;
+          }
+        }
+      }
+    } else {
+      // ND loop (much slower)
+        for (int top_index = start; top_index < end; ++top_index) {
+          bool in_range = true;
+          // ind2sub
+          int m = top_index;
+          for (int j = num_axes-1; j >= 0; --j) {
+            pool_loc[j] = m % pooled_shape[j];
+            m /= pooled_shape[j];
+            in_range &= (m < pooled_shape[j])&&
+                        (pool_loc[j] >= starts[j])&&
+                        (pool_loc[j] < ends[j]);
+            if (!in_range) { break;}
+          }
+          if (in_range) {
+            pool_size = 1;
+            for (int i = 0; i< num_axes; ++i) {
+              int pstart = pool_loc[i]*stride[i]-pad[i];
+              int pend = min(pstart + kernel_shape[i], im_shape[i+1] + pad[i]);
+              pool_size *= (pend - pstart);
+            }
+            gradient += top_diff[top_index] / pool_size;
+          }
+        }
     }
     bottom_diff[index] = gradient;
   }
 }
 
-
 template <typename Dtype>
 __global__ void StoPoolBackward(const int nthreads,
-    const Dtype* const rand_idx, const Dtype* const top_diff,
-    const int num, const int channels, const int height,
-    const int width, const int pooled_height, const int pooled_width,
-    const int kernel_h, const int kernel_w, const int stride_h,
-    const int stride_w, Dtype* const bottom_diff) {
+    const Dtype* rand_idx, const Dtype* top_diff,
+    int num, int channels, int num_axes,
+    const int* im_shape, const int* pooled_shape,
+    const int* kernel_shape, const int* stride, Dtype* bottom_diff) {
+    int pool_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int im_loc[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int starts[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
+    int ends[MAX_SPATIAL_AXES];  // NOLINT(runtime/arrays)
   CUDA_KERNEL_LOOP(index, nthreads) {
-    // find out the local index
-    // find out the local offset
-    const int w = index % width;
-    const int h = (index / width) % height;
-    const int c = (index / width / height) % channels;
-    const int n = index / width / height / channels;
-    const int phstart = (h < kernel_h) ? 0 : (h - kernel_h) / stride_h + 1;
-    const int phend = min(h / stride_h + 1, pooled_height);
-    const int pwstart = (w < kernel_w) ? 0 : (w - kernel_w) / stride_w + 1;
-    const int pwend = min(w / stride_w + 1, pooled_width);
+    // ind2sub
+    int k = index;
+    for (int i = num_axes-1; i >= 0; --i) {
+      im_loc[i] = (k % im_shape[i+1]);
+      k /= im_shape[i+1];
+    }
+    int c = k % channels;
+    int n = k / channels;
+    int shift_size = 1;
+    int start, end;
+    for (int i = 0; i < num_axes; ++i) {
+      starts[i] =
+       (im_loc[i] < kernel_shape[i]) ? 0 :
+       (im_loc[i] - kernel_shape[i]) / stride[i] + 1;
+      ends[i] = min((im_loc[i]) / stride[i] + 1, pooled_shape[i]);
+      shift_size *= pooled_shape[i];
+      if (num_axes > 3) {
+        if (i > 0) {
+          start = start*pooled_shape[i]+starts[i];
+          end = end*pooled_shape[i]+ends[i];
+        } else {
+          start = starts[0];
+          end = ends[0];
+        }
+      }
+    }
     Dtype gradient = 0;
-    const Dtype* const rand_idx_slice =
-        rand_idx + (n * channels + c) * pooled_height * pooled_width;
-    const Dtype* const top_diff_slice =
-        top_diff + (n * channels + c) * pooled_height * pooled_width;
-    for (int ph = phstart; ph < phend; ++ph) {
-      for (int pw = pwstart; pw < pwend; ++pw) {
-        gradient += top_diff_slice[ph * pooled_width + pw] *
-            (index == static_cast<int>(rand_idx_slice[ph * pooled_width + pw]));
+    rand_idx += (n * channels + c) * shift_size;
+    top_diff += (n * channels + c) * shift_size;
+    if (num_axes == 2) {
+      for (int ph = starts[0]; ph < ends[0]; ++ph) {
+        for (int pw = starts[1]; pw < ends[1]; ++pw) {
+          gradient += top_diff[ph * pooled_shape[1] + pw] *
+            (index == static_cast<int>(rand_idx[ph * pooled_shape[1] + pw]));
+        }
       }
+    } else if (num_axes == 3) {
+      for (int ph = starts[0]; ph < ends[0]; ++ph) {
+        for (int pw = starts[1]; pw < ends[1]; ++pw) {
+          for (int pz = starts[2]; pz < ends[2]; ++pz) {
+            gradient += top_diff[(ph * pooled_shape[1] + pw)*
+                                         pooled_shape[2]+pz]*
+              (index == static_cast<int>(rand_idx[(ph * pooled_shape[1] + pw)*
+                                         pooled_shape[2]+pz]));
+          }
+        }
+      }
+    } else {
+        for (int top_index = start; top_index < end; ++top_index) {
+          bool in_range = true;
+          // ind2sub
+          int m = top_index;
+          for (int j = num_axes-1; j >= 0; --j) {
+            pool_loc[j] = m % pooled_shape[j];
+            m /= pooled_shape[j];
+            in_range &= (m < pooled_shape[j])&&
+                        (pool_loc[j] >= starts[j])&&
+                        (pool_loc[j] < ends[j]);
+            if (!in_range) { break;}
+          }
+          if (in_range) {
+             gradient += top_diff[top_index] *
+              (index == static_cast<int>(rand_idx[top_index]));
+          }
+        }
     }
     bottom_diff[index] = gradient;
   }
@@ -331,8 +731,10 @@ __global__ void StoPoolBackward(const int nthreads,
 
 
 template <typename Dtype>
-void PoolingLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
-      const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+void PoolingLayer<Dtype>::Backward_gpu(
+      const vector<Blob<Dtype>*>& top,
+      const vector<bool>& propagate_down,
+      const vector<Blob<Dtype>*>& bottom) {
   if (!propagate_down[0]) {
     return;
   }
@@ -344,6 +746,7 @@ void PoolingLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
   const bool use_top_mask = top.size() > 1;
   const int* mask = NULL;
   const Dtype* top_mask = NULL;
+  int top_num = top[0]->count(0, channel_axis_);
   switch (this->layer_param_.pooling_param().pool()) {
   case PoolingParameter_PoolMethod_MAX:
     if (use_top_mask) {
@@ -353,24 +756,28 @@ void PoolingLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
     }
     // NOLINT_NEXT_LINE(whitespace/operators)
     MaxPoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, top_diff, mask, top_mask, top[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_,
-        kernel_h_, kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_,
+        count, top_diff, mask, top_mask, top_num, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(), pad_.gpu_data(),
         bottom_diff);
     break;
   case PoolingParameter_PoolMethod_AVE:
     // NOLINT_NEXT_LINE(whitespace/operators)
     AvePoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
-        count, top_diff, top[0]->num(), channels_,
-        height_, width_, pooled_height_, pooled_width_, kernel_h_,
-        kernel_w_, stride_h_, stride_w_, pad_h_, pad_w_, bottom_diff);
+        count, top_diff, top_num, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(), pad_.gpu_data(), bottom_diff);
     break;
   case PoolingParameter_PoolMethod_STOCHASTIC:
     // NOLINT_NEXT_LINE(whitespace/operators)
     StoPoolBackward<Dtype><<<CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS>>>(
         count, rand_idx_.gpu_data(), top_diff,
-        top[0]->num(), channels_, height_, width_, pooled_height_,
-        pooled_width_, kernel_h_, kernel_w_, stride_h_, stride_w_,
+        top_num, channels_, num_spatial_axes_,
+        input_shape_.gpu_data(), output_shape_.gpu_data(),
+        kernel_shape_.gpu_data(),
+        stride_.gpu_data(),
         bottom_diff);
     break;
   default:
diff --git a/src/caffe/layers/softmax_loss_layer.cpp b/src/caffe/layers/softmax_loss_layer.cpp
index dddb760..863bab3 100644
--- a/src/caffe/layers/softmax_loss_layer.cpp
+++ b/src/caffe/layers/softmax_loss_layer.cpp
@@ -49,6 +49,13 @@ void SoftmaxWithLossLayer<Dtype>::Reshape(
       << "e.g., if softmax axis == 1 and prediction shape is (N, C, H, W), "
       << "label count (number of labels) must be N*H*W, "
       << "with integer values in {0, 1, ..., C-1}.";
+  if( bottom.size() == 3) {
+    CHECK_EQ(outer_num_ * inner_num_, bottom[2]->count())
+        << "Number of weights must match number of predictions; "
+        << "e.g., if softmax axis == 1 and prediction shape is (N, C, H, W), "
+        << "weight count (number of weights) must be N*H*W, "
+        << "with positive float values";
+  }
   if (top.size() >= 2) {
     // softmax output
     top[1]->ReshapeLike(*bottom[0]);
@@ -93,24 +100,51 @@ void SoftmaxWithLossLayer<Dtype>::Forward_cpu(
   const Dtype* prob_data = prob_.cpu_data();
   const Dtype* label = bottom[1]->cpu_data();
   int dim = prob_.count() / outer_num_;
-  int count = 0;
-  Dtype loss = 0;
-  for (int i = 0; i < outer_num_; ++i) {
-    for (int j = 0; j < inner_num_; j++) {
-      const int label_value = static_cast<int>(label[i * inner_num_ + j]);
-      if (has_ignore_label_ && label_value == ignore_label_) {
-        continue;
+
+  if(bottom.size() == 2 ) {
+    // original version with equally weighted pixels
+    int count = 0;
+    Dtype loss = 0;
+    for (int i = 0; i < outer_num_; ++i) {
+      for (int j = 0; j < inner_num_; j++) {
+	const int label_value = static_cast<int>(label[i * inner_num_ + j]);
+	if (has_ignore_label_ && label_value == ignore_label_) {
+	  continue;
+	}
+	DCHECK_GE(label_value, 0);
+	DCHECK_LT(label_value, prob_.shape(softmax_axis_));
+	loss -= log(std::max(prob_data[i * dim + label_value * inner_num_ + j],
+			     Dtype(FLT_MIN)));
+	++count;
       }
-      DCHECK_GE(label_value, 0);
-      DCHECK_LT(label_value, prob_.shape(softmax_axis_));
-      loss -= log(std::max(prob_data[i * dim + label_value * inner_num_ + j],
-                           Dtype(FLT_MIN)));
-      ++count;
     }
-  }
-  top[0]->mutable_cpu_data()[0] = loss / get_normalizer(normalization_, count);
-  if (top.size() == 2) {
-    top[1]->ShareData(prob_);
+    top[0]->mutable_cpu_data()[0] = loss / get_normalizer(normalization_, count);
+  } else {
+    // version with pixel-wise loss weights using a third input blob
+    const Dtype* weight_data = bottom[2]->cpu_data();
+    Dtype weightsum = 0;
+    Dtype loss = 0;
+    for (int i = 0; i < outer_num_; ++i) {
+      for (int j = 0; j < inner_num_; j++) {
+        const int label_value = static_cast<int>(label[i * inner_num_ + j]);
+        if (has_ignore_label_ && label_value == ignore_label_) {
+          continue;
+        }
+        DCHECK_GE(label_value, 0);
+        DCHECK_LT(label_value, prob_.shape(softmax_axis_));
+        loss -= weight_data[i * inner_num_ + j] *
+            log(std::max(prob_data[i * dim + label_value * inner_num_ + j],
+                             Dtype(FLT_MIN)));
+        weightsum += weight_data[i * inner_num_ + j];
+      }
+    }
+    if( weightsum == 0) {
+      LOG(INFO) << this->type()
+		<< " warning: sum of pixel wise loss weights is zero!";
+      top[0]->mutable_cpu_data()[0] = 0;
+    } else {
+      top[0]->mutable_cpu_data()[0] = loss / get_normalizer(normalization_, weightsum);
+    }
   }
 }
 
@@ -127,24 +161,57 @@ void SoftmaxWithLossLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
     caffe_copy(prob_.count(), prob_data, bottom_diff);
     const Dtype* label = bottom[1]->cpu_data();
     int dim = prob_.count() / outer_num_;
-    int count = 0;
-    for (int i = 0; i < outer_num_; ++i) {
-      for (int j = 0; j < inner_num_; ++j) {
-        const int label_value = static_cast<int>(label[i * inner_num_ + j]);
-        if (has_ignore_label_ && label_value == ignore_label_) {
-          for (int c = 0; c < bottom[0]->shape(softmax_axis_); ++c) {
-            bottom_diff[i * dim + c * inner_num_ + j] = 0;
+    if( bottom.size() == 2) {
+      // original version with equally weighted pixels
+      int count = 0;
+      for (int i = 0; i < outer_num_; ++i) {
+	for (int j = 0; j < inner_num_; ++j) {
+	  const int label_value = static_cast<int>(label[i * inner_num_ + j]);
+	  if (has_ignore_label_ && label_value == ignore_label_) {
+	    for (int c = 0; c < bottom[0]->shape(softmax_axis_); ++c) {
+	      bottom_diff[i * dim + c * inner_num_ + j] = 0;
+	    }
+	  } else {
+	    bottom_diff[i * dim + label_value * inner_num_ + j] -= 1;
+	    ++count;
+	  }
+	}
+      }
+      // Scale gradient
+      Dtype loss_weight = top[0]->cpu_diff()[0] /
+	get_normalizer(normalization_, count);
+      caffe_scal(prob_.count(), loss_weight, bottom_diff);
+    } else {
+      // version with pixel-wise loss weights using a third input blob
+      const Dtype* weight_data = bottom[2]->cpu_data();
+      Dtype weightsum = 0;
+      for (int i = 0; i < outer_num_; ++i) {
+        for (int j = 0; j < inner_num_; ++j) {
+          const int label_value = static_cast<int>(label[i * inner_num_ + j]);
+          if (has_ignore_label_ && label_value == ignore_label_) {
+            for (int c = 0; c < bottom[0]->shape(softmax_axis_); ++c) {
+              bottom_diff[i * dim + c * inner_num_ + j] = 0;
+            }
+          } else {
+            bottom_diff[i * dim + label_value * inner_num_ + j] -= 1;
+            Dtype weight = weight_data[i * inner_num_ + j];
+            for (int c = 0; c < bottom[0]->shape(softmax_axis_); ++c) {
+              bottom_diff[i * dim + c * inner_num_ + j] *= weight;
+            }
+            weightsum += weight;
           }
-        } else {
-          bottom_diff[i * dim + label_value * inner_num_ + j] -= 1;
-          ++count;
         }
       }
+      // Scale gradient
+      const Dtype loss_weight = top[0]->cpu_diff()[0];
+      if( weightsum == 0) {
+	LOG(INFO) << this->type()
+		  << " warning: sum of pixel wise loss weights is zero!";
+	//top[0]->mutable_cpu_data()[0] = 0;
+      } else {
+          caffe_scal(prob_.count(), loss_weight/weightsum, bottom_diff);
+      }
     }
-    // Scale gradient
-    Dtype loss_weight = top[0]->cpu_diff()[0] /
-                        get_normalizer(normalization_, count);
-    caffe_scal(prob_.count(), loss_weight, bottom_diff);
   }
 }
 
diff --git a/src/caffe/layers/softmax_loss_layer.cu b/src/caffe/layers/softmax_loss_layer.cu
index 660e1b3..60f5027 100644
--- a/src/caffe/layers/softmax_loss_layer.cu
+++ b/src/caffe/layers/softmax_loss_layer.cu
@@ -29,6 +29,30 @@ __global__ void SoftmaxLossForwardGPU(const int nthreads,
 }
 
 template <typename Dtype>
+__global__ void WeightedSoftmaxLossForwardGPU(const int nthreads,
+          const Dtype* prob_data, const Dtype* label, const Dtype* weights,
+          Dtype* loss,
+          const int num, const int dim, const int spatial_dim,
+          const bool has_ignore_label_, const int ignore_label_,
+          Dtype* counts) {
+  CUDA_KERNEL_LOOP(index, nthreads) {
+    const int n = index / spatial_dim;
+    const int s = index % spatial_dim;
+    const int label_value = static_cast<int>(label[n * spatial_dim + s]);
+    if (has_ignore_label_ && label_value == ignore_label_) {
+      loss[index] = 0;
+      counts[index] = 0;
+    } else {
+      Dtype weight = weights[n * spatial_dim + s];
+      loss[index] = weight *
+          -log(max(prob_data[n * dim + label_value * spatial_dim + s],
+                   Dtype(FLT_MIN)));
+      counts[index] = weight;
+    }
+  }
+}
+
+template <typename Dtype>
 void SoftmaxWithLossLayer<Dtype>::Forward_gpu(
     const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) {
   softmax_layer_->Forward(softmax_bottom_vec_, softmax_top_vec_);
@@ -43,21 +67,40 @@ void SoftmaxWithLossLayer<Dtype>::Forward_gpu(
   // Similarly, this memory is never used elsewhere, and thus we can use it
   // to avoid having to allocate additional GPU memory.
   Dtype* counts = prob_.mutable_gpu_diff();
-  // NOLINT_NEXT_LINE(whitespace/operators)
-  SoftmaxLossForwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
-      CAFFE_CUDA_NUM_THREADS>>>(nthreads, prob_data, label, loss_data,
-      outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, counts);
+  if( bottom.size() == 2) {
+    // original version with equally weighted pixels
+    // NOLINT_NEXT_LINE(whitespace/operators)
+    SoftmaxLossForwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
+        CAFFE_CUDA_NUM_THREADS>>>(nthreads, prob_data, label, loss_data,
+        outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, counts);
+  } else {
+    // version with pixel-wise loss weights using a third input blob
+    WeightedSoftmaxLossForwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
+        CAFFE_CUDA_NUM_THREADS>>>(nthreads, prob_data, label,
+        bottom[2]->gpu_data(), loss_data,
+        outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, counts);
+  }
   Dtype loss;
   caffe_gpu_asum(nthreads, loss_data, &loss);
   Dtype valid_count = -1;
   // Only launch another CUDA kernel if we actually need the count of valid
   // outputs.
-  if (normalization_ == LossParameter_NormalizationMode_VALID &&
-      has_ignore_label_) {
+
+  if ( (normalization_ == LossParameter_NormalizationMode_VALID &&
+        has_ignore_label_) || bottom.size() == 3) {
     caffe_gpu_asum(nthreads, counts, &valid_count);
+    if( valid_count == 0 ) {
+      LOG(INFO) << this->type()
+		<< " warning: sum of pixel wise loss weights is zero!";
+    }
   }
-  top[0]->mutable_cpu_data()[0] = loss / get_normalizer(normalization_,
-                                                        valid_count);
+  if ( valid_count == 0) {
+      top[0]->mutable_cpu_data()[0] = 0.;
+  } else {
+      top[0]->mutable_cpu_data()[0] = loss / get_normalizer(normalization_,
+                                                          valid_count);
+  }
+
   if (top.size() == 2) {
     top[1]->ShareData(prob_);
   }
@@ -88,6 +131,35 @@ __global__ void SoftmaxLossBackwardGPU(const int nthreads, const Dtype* top,
 }
 
 template <typename Dtype>
+__global__ void WeightedSoftmaxLossBackwardGPU(const int nthreads,
+          const Dtype* top, const Dtype* label, const Dtype* weights,
+          Dtype* bottom_diff, const int num, const int dim,
+          const int spatial_dim, const bool has_ignore_label_,
+          const int ignore_label_, Dtype* counts) {
+  const int channels = dim / spatial_dim;
+
+  CUDA_KERNEL_LOOP(index, nthreads) {
+    const int n = index / spatial_dim;
+    const int s = index % spatial_dim;
+    const int label_value = static_cast<int>(label[n * spatial_dim + s]);
+
+    if (has_ignore_label_ && label_value == ignore_label_) {
+      for (int c = 0; c < channels; ++c) {
+        bottom_diff[n * dim + c * spatial_dim + s] = 0;
+      }
+      counts[index] = 0;
+    } else {
+      bottom_diff[n * dim + label_value * spatial_dim + s] -= 1;
+      Dtype weight = weights[n * spatial_dim + s];
+      for (int c = 0; c < channels; ++c) {
+        bottom_diff[n * dim + c * spatial_dim + s] *= weight;
+      }
+      counts[index] = weight;
+    }
+  }
+}
+
+template <typename Dtype>
 void SoftmaxWithLossLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
     const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
   if (propagate_down[1]) {
@@ -105,20 +177,36 @@ void SoftmaxWithLossLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top,
     // Since this memory is never used for anything else,
     // we use to to avoid allocating new GPU memory.
     Dtype* counts = prob_.mutable_gpu_diff();
-    // NOLINT_NEXT_LINE(whitespace/operators)
-    SoftmaxLossBackwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
-        CAFFE_CUDA_NUM_THREADS>>>(nthreads, top_data, label, bottom_diff,
-        outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_, counts);
 
+   if( bottom.size() == 2) {
+      // original version with equally weighted pixels
+      // NOLINT_NEXT_LINE(whitespace/operators)
+      SoftmaxLossBackwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
+          CAFFE_CUDA_NUM_THREADS>>>(nthreads, top_data, label, bottom_diff,
+          outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_,
+          counts);
+    } else {
+       WeightedSoftmaxLossBackwardGPU<Dtype><<<CAFFE_GET_BLOCKS(nthreads),
+          CAFFE_CUDA_NUM_THREADS>>>(nthreads, top_data, label,
+          bottom[2]->gpu_data(), bottom_diff,
+          outer_num_, dim, inner_num_, has_ignore_label_, ignore_label_,
+          counts);
+    }
     Dtype valid_count = -1;
     // Only launch another CUDA kernel if we actually need the count of valid
     // outputs.
-    if (normalization_ == LossParameter_NormalizationMode_VALID &&
-        has_ignore_label_) {
+    if ( (normalization_ == LossParameter_NormalizationMode_VALID &&
+          has_ignore_label_) || (bottom.size() == 3) ) {
       caffe_gpu_asum(nthreads, counts, &valid_count);
     }
-    const Dtype loss_weight = top[0]->cpu_diff()[0] /
-                              get_normalizer(normalization_, valid_count);
+    Dtype loss_weight = 0;
+    if( valid_count == 0) {
+        LOG(INFO) << this->type()
+                  << " warning: sum of pixel wise loss weights is zero!";
+    } else {
+        loss_weight = top[0]->cpu_diff()[0] /
+            get_normalizer(normalization_, valid_count);
+    }
     caffe_gpu_scal(prob_.count(), loss_weight , bottom_diff);
   }
 }
diff --git a/src/caffe/layers/value_augmentation_layer.cpp b/src/caffe/layers/value_augmentation_layer.cpp
new file mode 100644
index 0000000..e7e16d7
--- /dev/null
+++ b/src/caffe/layers/value_augmentation_layer.cpp
@@ -0,0 +1,297 @@
+#include <algorithm>
+#include <vector>
+
+#include "caffe/layer.hpp"
+#include "caffe/util/math_functions.hpp"
+#include "caffe/layers/value_augmentation_layer.hpp"
+
+#include <stdexcept>
+
+namespace caffe {
+
+template<typename Dtype>
+Dtype random_factor( Dtype max_factor) {
+  CHECK_GE(max_factor, 1);
+  if (max_factor == 1) return 1;
+  Dtype sigma = log(max_factor)/3;
+  Dtype v = 0;
+  while( v < 1/max_factor || v > max_factor) {
+    caffe_rng_gaussian<Dtype>( 1, 0, sigma, &v);
+    v = exp(v);
+  }
+  return v;
+}
+
+template<typename Dtype>
+Dtype uniform_random_value( Dtype minvalue, Dtype maxvalue) {
+  Dtype v = 0;
+  caffe_rng_uniform<Dtype>( 1, minvalue, maxvalue, &v);
+  return v;
+}
+
+
+template <typename Dtype>
+void ValueAugmentationLayer<Dtype>::CreateLinearInterpExtrapMatrix(
+    int n_in,  Dtype dx_in,
+    int n_out, Dtype dx_out,
+    int n_extrapol,
+    Dtype* lin_mat) {
+  const int ncols = n_in;
+  const int nrows = n_out + 2 * n_extrapol;
+
+  // left side linear extrapolation
+  // f(x) = y0 + x * (y1 - y0) / dx_in
+  //      = (1 - x / dx_in) * y0   +   (x / dx_in) * y1
+  //
+  for (int row = 0; row < n_extrapol; ++row) {
+    Dtype x_out = (row - n_extrapol) * dx_out;
+    lin_mat[ row * ncols + 0] = 1 - x_out / dx_in;
+    lin_mat[ row * ncols + 1] = x_out / dx_in;
+    for (int col = 2; col < ncols; ++col) {
+      lin_mat[ row * ncols + col] = 0;
+    }
+  }
+
+  // interpolation
+  // simple triangular kernel
+  //
+  for (int row = n_extrapol; row < n_out + n_extrapol; ++row) {
+    Dtype x_out = (row - n_extrapol) * dx_out;
+    for (int col = 0; col < ncols; ++col) {
+      Dtype x_in = col * dx_in;
+      lin_mat[ row * ncols + col] =
+          std::max( Dtype(0), 1 - std::abs( x_out - x_in) / dx_in);
+    }
+  }
+
+  // right side linear extrapolation
+  // e.g. for 3 data points
+  // f(x) = y2 + (x - x2) * (y2 - y1) / dx_in
+  //      = (- (x - x2) / dx_in) * y1   +   (1 + (x - x2) / dx_in) * y2
+  //
+  for (int row = n_extrapol + n_out; row < nrows; ++row) {
+    Dtype x_out = (row - (n_extrapol + n_out - 1)) * dx_out;
+    for (int col = 0; col < ncols-2; ++col) {
+      lin_mat[ row * ncols + col] = 0;
+    }
+    lin_mat[ row * ncols + ncols - 2] = - x_out / dx_in;
+    lin_mat[ row * ncols + ncols - 1] = 1 + x_out / dx_in;
+  }
+}
+
+
+
+template <typename Dtype>
+void ValueAugmentationLayer<Dtype>::LayerSetUp(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  NeuronLayer<Dtype>::LayerSetUp(bottom, top);
+  const ValueAugmentationParameter& param =
+      this->layer_param_.value_augmentation_param();
+
+  // check that arguments are valid
+  CHECK_GE(param.lut_size(), 2)
+      << "Lookup table must have at least two elements.";
+  CHECK_GE(param.slope_max(), param.slope_min())
+      << "Minimum slope must be smaller or equal than the maximum slope.";
+  CHECK_GE(param.n_control_point_insertions(),0) << "Parameter must be positive";
+  CHECK_LE(param.black_from(), param.black_to());
+  CHECK_LE(param.white_from(), param.white_to());
+  CHECK_LE(param.black_to(), param.white_from());
+
+  // set parameters
+  slope_min_        = param.slope_min();
+  slope_max_        = param.slope_max();
+  black_from_       = param.black_from();
+  black_to_         = param.black_to();
+  white_from_       = param.white_from();
+  white_to_         = param.white_to();
+
+  // setup interpolation matrix
+  n_control_point_insertions_ = param.n_control_point_insertions();
+  n_control_points_ = pow(2, n_control_point_insertions_) + 1;
+  lut_size_         = param.lut_size();
+
+  // Matrix for linear interpolation and linear extrapolation
+  //
+  const int n_extrapol    = lut_size_/2;
+  const Dtype dx_lowres   = 1.0 / (n_control_points_ - 1);
+  const Dtype dx_highres  = 1.0 / (lut_size_ - 1);
+  const int lin_mat_ncols = n_control_points_;
+  const int lin_mat_nrows = lut_size_ + 2 * n_extrapol;
+  Dtype* lin_mat = new Dtype[lin_mat_nrows * lin_mat_ncols];
+
+  CreateLinearInterpExtrapMatrix(n_control_points_, dx_lowres,
+                                 lut_size_, dx_highres,
+                                 n_extrapol, lin_mat);
+
+  // Matrix for Gaussian smoothing
+  //
+    Dtype sigma = dx_lowres / 4;
+  const int gauss_mat_ncols = lin_mat_nrows;
+  const int gauss_mat_nrows = lut_size_;
+  Dtype* gauss_mat = new Dtype[gauss_mat_nrows * gauss_mat_ncols];
+
+  for (int row = 0; row < gauss_mat_nrows; ++row) {
+    Dtype xout = row * dx_highres;
+    Dtype rowsum = 0;
+    for (int col = 0; col < gauss_mat_ncols; ++col) {
+      Dtype xin = (col - n_extrapol) * dx_highres;
+      Dtype v = exp( -0.5 * (xout - xin) * (xout - xin) / (sigma * sigma));
+      gauss_mat[ row * gauss_mat_ncols + col] = v;
+      rowsum += v;
+    }
+    for (int col = 0; col < gauss_mat_ncols; ++col) {
+      gauss_mat[ row * gauss_mat_ncols + col] /= rowsum;
+    }
+  }
+
+  // create interpolation matrix
+  vector<int> interpol_mat_shape;
+  interpol_mat_shape.push_back(lut_size_ * n_control_points_);
+  interpol_mat_.Reshape(interpol_mat_shape);
+
+  caffe_cpu_gemm<Dtype>( CblasNoTrans, CblasNoTrans,
+                         lut_size_, n_control_points_, lin_mat_nrows,
+                         Dtype(1), gauss_mat, lin_mat,
+                         Dtype(0), interpol_mat_.mutable_cpu_data());
+  delete[] lin_mat;
+  delete[] gauss_mat;
+
+  // control points of lookup table are sampled with a strategy
+  // involving several user-set ranges and in some cases an incompatible
+  // set of parameters is sampled.
+  // Maximum 50% of failures are allowed.
+  int n_fails = 0;
+  for (int i=0; i < 100000; ++i) {
+     try {
+     std::vector<Dtype> lut = dense_lut( random_lut_controlpoints(
+          black_from_, black_to_,
+          white_from_, white_to_,
+          slope_min_,  slope_max_,
+         n_control_point_insertions_));
+     } catch (const std::runtime_error& e) {
+          n_fails++;
+     }
+  }
+
+  LOG(INFO) << "Generating 100000 random lookup tables with given " <<
+      "parameters for ValueAugmentationLayer.";
+  LOG(INFO) << "Failure rate: " << (n_fails*100.)/100000 << "%";
+
+  CHECK_LE(n_fails, 50000) << "Provided value augmentation parameters " <<
+      "produced in more than 50% of cases incompatible control points." <<
+      " Parameters of ValueAugmentationLayer need to be changed.";
+}
+
+
+template <typename Dtype>
+std::vector<Dtype> ValueAugmentationLayer<Dtype>::random_lut_controlpoints(
+    Dtype black_from, Dtype black_to,
+    Dtype white_from, Dtype white_to,
+    Dtype slope_min,  Dtype slope_max,
+    int n_control_point_insertions) {
+  // initial lut has only start and end point
+  //
+  std::vector<Dtype> lut(2);
+  lut[0] = uniform_random_value( black_from, black_to);
+  lut[1] = uniform_random_value( white_from, white_to);
+  Dtype dx = 1;
+
+  for (int iter = 0; iter < n_control_point_insertions; ++iter) {
+    // insert intermediate points
+    std::vector<Dtype> newlut;
+    newlut.push_back(lut[0]);
+    dx /= 2;
+    for (int i = 0; i < lut.size() - 1; ++i) {
+      Dtype left_constraint_from  = lut[i] + slope_min * dx;
+      Dtype left_constraint_to    = lut[i] + slope_max * dx;
+      Dtype right_constraint_from = lut[i+1] - slope_max * dx;
+      Dtype right_constraint_to   = lut[i+1] - slope_min * dx;
+      Dtype ymin = std::max( left_constraint_from, right_constraint_from);
+      Dtype ymax = std::min( left_constraint_to, right_constraint_to);
+      if (ymin > ymax) {
+          throw std::runtime_error("Invalid arguments for subsequent call of "
+                                   "uniform_random_value encountered.");
+      }
+      newlut.push_back( uniform_random_value( ymin, ymax));
+      newlut.push_back( lut[i+1]);
+    }
+    lut = newlut;
+  }
+
+  return lut;
+}
+
+template <typename Dtype>
+std::vector<Dtype> ValueAugmentationLayer<Dtype>::dense_lut(
+    const std::vector<Dtype>& lut_control_points) {
+  std::vector<Dtype> lut(lut_size_);
+  caffe_cpu_gemv<Dtype>( CblasNoTrans,
+                         lut_size_, n_control_points_,
+                         Dtype(1), interpol_mat_.cpu_data(),
+                         lut_control_points.data(), Dtype(0), lut.data());
+  return lut;
+}
+
+
+template <typename Dtype>
+void ValueAugmentationLayer<Dtype>::apply_lut(
+    const std::vector<Dtype>& lut,
+    const Dtype* in_data, Dtype* out_data, size_t count) {
+  for (size_t i = 0; i < count; ++i) {
+    float lut_i = in_data[i] * (lut.size()-1);
+    if (lut_i <= 0) {
+      out_data[i]  = lut[0];
+    } else if (lut_i >= lut.size()-1) {
+      out_data[i] = lut[lut.size()-1];
+    } else {
+      int i1  = floor( lut_i);
+      float f = lut_i - i1;
+      out_data[i] = (1-f) * lut[i1] + f * lut[i1+1];
+    }
+  }
+}
+
+
+template <typename Dtype>
+void ValueAugmentationLayer<Dtype>::Forward_cpu(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  const Dtype* bottom_data = bottom[0]->cpu_data();
+  Dtype* top_data = top[0]->mutable_cpu_data();
+  const int nsamples  = bottom[0]->shape(0);
+  const int nchannels = bottom[0]->shape(1);
+  const int count     = bottom[0]->count() / (nsamples * nchannels);
+
+  for (int num = 0; num < nsamples; ++num) {
+    for (int ch = 0; ch < nchannels; ++ch) {
+      while (true) {
+        try {
+          std::vector<Dtype> lut = dense_lut( random_lut_controlpoints(
+            black_from_, black_to_,
+            white_from_, white_to_,
+            slope_min_,  slope_max_,
+            n_control_point_insertions_));
+          apply_lut( lut, bottom_data + (num * nchannels + ch) * count,
+                 top_data + (num * nchannels + ch) * count,
+                 count);
+          break;
+        } catch (const std::runtime_error& e) {}
+      }
+    }
+  }
+}
+
+
+template <typename Dtype>
+void ValueAugmentationLayer<Dtype>::Backward_cpu(
+    const vector<Blob<Dtype>*>& top,
+    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+}
+
+
+INSTANTIATE_CLASS(ValueAugmentationLayer);
+REGISTER_LAYER_CLASS(ValueAugmentation);
+
+}  // namespace caffe
diff --git a/src/caffe/layers/value_transformation_layer.cpp b/src/caffe/layers/value_transformation_layer.cpp
new file mode 100644
index 0000000..ee3a56f
--- /dev/null
+++ b/src/caffe/layers/value_transformation_layer.cpp
@@ -0,0 +1,100 @@
+#include <algorithm>
+#include <vector>
+
+#include "caffe/layer.hpp"
+#include "caffe/util/math_functions.hpp"
+#include "caffe/layers/value_transformation_layer.hpp"
+
+namespace caffe {
+
+template <typename Dtype>
+void ValueTransformationLayer<Dtype>::LayerSetUp(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  NeuronLayer<Dtype>::LayerSetUp(bottom, top);
+  const ValueTransformationParameter& param =
+      this->layer_param_.value_transformation_param();
+  const int nchannels = bottom[0]->shape(1);
+  CHECK(param.offset().v_size() <= 1 || param.offset().v_size() == nchannels)
+      << "Specify either one offset or as many as channels: " << nchannels;
+  CHECK(param.scale().v_size() <= 1 || param.scale().v_size() == nchannels)
+      << "Specify either one scale or as many as channels: " << nchannels;
+  _offset.resize(nchannels);
+  _scale.resize(nchannels);
+  if (param.offset().v_size() == 1) {
+    for (int ch = 0; ch < nchannels; ++ch) _offset[ch] = param.offset().v(0);
+  }
+  else if (param.offset().v_size() == nchannels) {
+    for (int ch = 0; ch < nchannels; ++ch) _offset[ch] = param.offset().v(ch);
+  }
+  else {
+    for (int ch = 0; ch < nchannels; ++ch) _offset[ch] = 0.0f;
+  }
+
+  if (param.scale().v_size() == 1) {
+    for (int ch = 0; ch < nchannels; ++ch) _scale[ch] = param.scale().v(0);
+  }
+  else if (param.scale().v_size() == nchannels) {
+    for (int ch = 0; ch < nchannels; ++ch) _scale[ch] = param.scale().v(ch);
+  }
+  else {
+    for (int ch = 0; ch < nchannels; ++ch) _scale[ch] = 1.0f;
+  }
+}
+
+template <typename Dtype>
+void ValueTransformationLayer<Dtype>::Forward_cpu(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  const Dtype* bottom_data = bottom[0]->cpu_data();
+  Dtype* top_data = top[0]->mutable_cpu_data();
+  const int nsamples  = bottom[0]->shape(0);
+  const int nchannels = bottom[0]->shape(1);
+  const int count     = bottom[0]->count() / (nsamples * nchannels);
+
+  caffe_copy(bottom[0]->count(), bottom_data, top_data);
+
+  for (int num = 0; num < nsamples; ++num) {
+    for (int ch = 0; ch < nchannels; ++ch) {
+      if (_offset[ch] != Dtype(0)) {
+        caffe_add_scalar(
+            count, _offset[ch], top_data + (num * nchannels + ch) * count);
+      }
+      if (_scale[ch] != Dtype(1)) {
+        caffe_scal(
+            count, _scale[ch], top_data + (num * nchannels + ch) * count);
+      }
+    }
+  }
+}
+
+template <typename Dtype>
+void ValueTransformationLayer<Dtype>::Backward_cpu(
+    const vector<Blob<Dtype>*>& top,
+    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+  if (propagate_down[0]) {
+    const Dtype* top_diff = top[0]->cpu_diff();
+    Dtype* bottom_diff = bottom[0]->mutable_cpu_diff();
+    const int nsamples  = bottom[0]->shape(0);
+    const int nchannels = bottom[0]->shape(1);
+    const int count     = bottom[0]->count() / (nsamples * nchannels);
+
+    for (int num = 0; num < nsamples; ++num) {
+      for (int ch = 0; ch < nchannels; ++ch) {
+        // d/dx alpha_c * (x + beta_c) = alpha_c
+        caffe_set(count, _scale[ch],
+                  bottom_diff + (num * nchannels + ch) * count);
+      }
+    }
+    caffe_mul(bottom[0]->count(), top_diff, bottom_diff, bottom_diff);
+  }
+}
+
+#ifdef CPU_ONLY
+STUB_GPU(ValueTransformationLayer);
+#endif
+
+INSTANTIATE_CLASS(ValueTransformationLayer);
+REGISTER_LAYER_CLASS(ValueTransformation);
+
+}  // namespace caffe
diff --git a/src/caffe/layers/value_transformation_layer.cu b/src/caffe/layers/value_transformation_layer.cu
new file mode 100644
index 0000000..7c6aba9
--- /dev/null
+++ b/src/caffe/layers/value_transformation_layer.cu
@@ -0,0 +1,58 @@
+#include <vector>
+
+#include "caffe/layers/value_transformation_layer.hpp"
+#include "caffe/util/math_functions.hpp"
+
+namespace caffe {
+
+template <typename Dtype>
+void ValueTransformationLayer<Dtype>::Forward_gpu(
+    const vector<Blob<Dtype>*>& bottom,
+    const vector<Blob<Dtype>*>& top) {
+  const Dtype* bottom_data = bottom[0]->gpu_data();
+  Dtype* top_data = top[0]->mutable_gpu_data();
+  const int nsamples  = bottom[0]->shape(0);
+  const int nchannels = bottom[0]->shape(1);
+  const int count     = bottom[0]->count() / (nsamples * nchannels);
+
+  caffe_copy(bottom[0]->count(), bottom_data, top_data);
+
+  for (int num = 0; num < nsamples; ++num) {
+    for (int ch = 0; ch < nchannels; ++ch) {
+      if (_offset[ch] != Dtype(0)) {
+        caffe_gpu_add_scalar(
+            count, _offset[ch], top_data + (num * nchannels + ch) * count);
+      }
+      if (_scale[ch] != Dtype(1)) {
+        caffe_gpu_scal(
+            count, _scale[ch], top_data + (num * nchannels + ch) * count);
+      }
+    }
+  }
+}
+
+template <typename Dtype>
+void ValueTransformationLayer<Dtype>::Backward_gpu(
+    const vector<Blob<Dtype>*>& top,
+    const vector<bool>& propagate_down, const vector<Blob<Dtype>*>& bottom) {
+  if (propagate_down[0]) {
+    const Dtype* top_diff = top[0]->gpu_diff();
+    Dtype* bottom_diff = bottom[0]->mutable_gpu_diff();
+    const int nsamples  = bottom[0]->shape(0);
+    const int nchannels = bottom[0]->shape(1);
+    const int count     = bottom[0]->count() / (nsamples * nchannels);
+
+    for (int num = 0; num < nsamples; ++num) {
+      for (int ch = 0; ch < nchannels; ++ch) {
+        // d/dx alpha_c * (x + beta_c) = alpha_c
+        caffe_gpu_set(count, _scale[ch],
+                      bottom_diff + (num * nchannels + ch) * count);
+      }
+    }
+    caffe_gpu_mul(bottom[0]->count(), top_diff, bottom_diff, bottom_diff);
+  }
+}
+
+INSTANTIATE_LAYER_GPU_FUNCS(ValueTransformationLayer);
+
+}
diff --git a/src/caffe/net.cpp b/src/caffe/net.cpp
index f0bf594..dcc640d 100644
--- a/src/caffe/net.cpp
+++ b/src/caffe/net.cpp
@@ -86,6 +86,7 @@ void Net<Dtype>::Init(const NetParameter& in_param) {
       layers_[layer_id]->SetShared(true);
     } else {
       layers_.push_back(LayerRegistry<Dtype>::CreateLayer(layer_param));
+      layers_[layer_id]->set_parent_net( this);
     }
     layer_names_.push_back(layer_param.name());
     LOG_IF(INFO, Caffe::root_solver())
diff --git a/src/caffe/proto/caffe.proto b/src/caffe/proto/caffe.proto
index 650c87a..d3ebeda 100644
--- a/src/caffe/proto/caffe.proto
+++ b/src/caffe/proto/caffe.proto
@@ -27,6 +27,15 @@ message BlobProtoVector {
   repeated BlobProto blobs = 1;
 }
 
+// some Vectors
+message VectorFloat {
+  repeated float v = 1 [packed = true];
+}
+
+message VectorInt32 {
+  repeated int32 v = 1 [packed = true];
+}
+
 message Datum {
   optional int32 channels = 1;
   optional int32 height = 2;
@@ -359,12 +368,14 @@ message LayerParameter {
   // engine parameter for selecting the implementation.
   // The default for the engine is set by the ENGINE switch at compile-time.
   optional AccuracyParameter accuracy_param = 102;
+  optional ApplyDeformationParameter apply_deformation_param = 146;
   optional ArgMaxParameter argmax_param = 103;
   optional BatchNormParameter batch_norm_param = 139;
   optional BiasParameter bias_param = 141;
   optional ConcatParameter concat_param = 104;
   optional ContrastiveLossParameter contrastive_loss_param = 105;
   optional ConvolutionParameter convolution_param = 106;
+  optional CreateDeformationParameter create_deformation_param = 145;
   optional CropParameter crop_param = 144;
   optional DataParameter data_param = 107;
   optional DropoutParameter dropout_param = 108;
@@ -400,6 +411,8 @@ message LayerParameter {
   optional TanHParameter tanh_param = 127;
   optional ThresholdParameter threshold_param = 128;
   optional TileParameter tile_param = 138;
+  optional ValueAugmentationParameter value_augmentation_param = 147;
+  optional ValueTransformationParameter value_transformation_param = 148;
   optional WindowDataParameter window_data_param = 129;
 }
 
@@ -473,6 +486,16 @@ message AccuracyParameter {
   optional int32 ignore_label = 3;
 }
 
+// Message that stores parameters used by ApplyDeformationLayer
+message ApplyDeformationParameter {
+  // interpolation type ("linear" or "nearest")
+  optional string interpolation = 1 [default = "linear"];
+  // extrapolation type ("mirror" or "zero")
+  optional string extrapolation = 2 [default = "mirror"];
+  // get output shape from other blob
+  optional string output_shape_from = 3 [default = ""];
+}
+
 message ArgMaxParameter {
   // If true produce pairs (argmax, maxval)
   optional bool out_max_val = 1 [default = false];
@@ -604,6 +627,52 @@ message ConvolutionParameter {
   optional bool force_nd_im2col = 17 [default = false];
 }
 
+// Message that stores parameters used by CreateDeformationLayer
+message CreateDeformationParameter {
+  // Specify relative voxel element_size in z-direction.
+  // Needed for rotation
+  optional float voxel_relsize_z = 1 [default = 1];
+  // wanted output shape:
+  optional uint32 batch_size = 2 [default = 1];
+  optional uint32 nz = 3 [default = 0];
+  optional uint32 ny = 4 [default = 0];
+  optional uint32 nx = 5 [default = 0];
+  optional uint32 ncomponents = 6 [default = 2];
+  // control point grid for random elastic transformation
+  // spacing in pixels
+  optional VectorInt32 random_elastic_grid_spacing = 7;
+  // magnitude for random elastic transformation (normal distribution)
+  // sigma in pixels
+  optional VectorFloat random_elastic_deform_magnitude = 8;
+  // random rotation (uniform distribution)
+  // rotation axis is center of the output blob
+  // for 2D: rot_z  (rotation around the z-axis)
+  // for 3D: rot_z, rot_y, rot_x (rotation around the z, y and x-axis)
+  optional VectorFloat random_rotate_from = 9;
+  optional VectorFloat random_rotate_to = 10;
+  // random offset (uniform distribution) in pixels
+  // (zero offset means, that the output image is centered on the input image)
+  // for 2D: y, x
+  // for 3D: z, y, x
+  optional VectorFloat random_offset_from = 11;
+  optional VectorFloat random_offset_to = 12;
+  // compute the offset range from the input blob, such that the
+  // central pixel of the output is within the input blob, i.e.
+  // offset_from = -(input_shape-1)/2 and offset_to = (input_shape-1)/2
+  optional bool random_offset_range_from_in_blob_shape = 13 [default = false];
+  // draw the random offset (location of central pixel of the
+  // output) using a given probability map. I.e. pixels with
+  // probability 0 will never be chosen
+  optional bool random_offset_range_from_pdf = 14 [default = false];
+  // draw random offset according to the ignore label in the label
+  // map. I.e. pixels with ignore label will never be chosen
+  optional uint32 random_offset_range_from_ignore_label = 15;
+  // random mirror flag (1: this axis should be randomly mirrored)
+  // for 2D: y, x
+  // for 3D: z, y, x
+  optional VectorInt32 random_mirror_flag = 16;
+}
+
 message CropParameter {
   // To crop, elements of the first bottom are selected to fit the dimensions
   // of the second, reference bottom. The crop is configured by
@@ -754,6 +823,8 @@ message HDF5DataParameter {
 
 message HDF5OutputParameter {
   optional string file_name = 1;
+  repeated string dset_name = 2;
+  optional bool squeeze = 3 [default = false];
 }
 
 message HingeLossParameter {
@@ -881,16 +952,20 @@ message PoolingParameter {
   }
   optional PoolMethod pool = 1 [default = MAX]; // The pooling method
   // Pad, kernel size, and stride are all given as a single value for equal
-  // dimensions in height and width or as Y, X pairs.
-  optional uint32 pad = 4 [default = 0]; // The padding size (equal in Y, X)
-  optional uint32 pad_h = 9 [default = 0]; // The padding height
-  optional uint32 pad_w = 10 [default = 0]; // The padding width
-  optional uint32 kernel_size = 2; // The kernel size (square)
-  optional uint32 kernel_h = 5; // The kernel height
-  optional uint32 kernel_w = 6; // The kernel width
-  optional uint32 stride = 3 [default = 1]; // The stride (equal in Y, X)
-  optional uint32 stride_h = 7; // The stride height
-  optional uint32 stride_w = 8; // The stride width
+  // dimensions in all spatial dimensions, or once per spatial dimension.
+  repeated uint32 pad = 2; // The padding size defaults to 0
+  repeated uint32 kernel_size = 3; // The kernel size (square)
+  repeated uint32 stride = 4; // defaults to 1
+
+  // For 2D pooling only, the *_h and *_w versions may also be used to
+  // specify both spatial dimensions.
+  optional uint32 pad_h = 5 [default = 0]; // The padding height (2D only)
+  optional uint32 pad_w = 6 [default = 0]; // The padding width (2D only)
+  optional uint32 kernel_h = 7; // The kernel height (2D only)
+  optional uint32 kernel_w = 8; // The kernel width (2D only)
+  optional uint32 stride_h = 9; // The stride height (2D only)
+  optional uint32 stride_w = 10; // The stride width (2D only)
+
   enum Engine {
     DEFAULT = 0;
     CAFFE = 1;
@@ -900,6 +975,10 @@ message PoolingParameter {
   // If global_pooling then it will pool over the size of the bottom by doing
   // kernel_h = bottom->height and kernel_w = bottom->width
   optional bool global_pooling = 12 [default = false];
+  // The axis to interpret as "channels" when performing pooling.
+  // Preceding dimensions are treated as independent inputs;
+  // succeeding dimensions are treated as "spatial".
+  optional int32 axis = 13 [default = 1];
 }
 
 message PowerParameter {
@@ -1127,6 +1206,50 @@ message ThresholdParameter {
   optional float threshold = 1 [default = 0]; // Strictly positive values
 }
 
+// Message that stores parameters used by ValueAugmentationLayer
+message ValueAugmentationParameter {
+
+  // new black level:
+  // i.e. input 0 is mapped to this value
+  // range for uniform random number
+  optional float black_from = 1 [default = 0];
+  optional float black_to   = 2 [default = 0];
+
+  // new white level:
+  // i.e. input 1 is mapped to this value
+
+  // range for uniform random number
+  optional float white_from = 3 [default = 1];
+  optional float white_to   = 4 [default = 1];
+
+  // minimal and maximal slope of lookup curve
+  optional float slope_min = 5 [default = 0.666];
+  optional float slope_max = 6 [default = 1.5];
+
+  // number of control point insertions, i.e.
+  // 0 --> two control points (for black and white)
+  // 1 --> 3 control points
+  // 2 --> 5 control points
+  // 3 --> 9 control points
+  // ...
+  optional int32 n_control_point_insertions = 7 [default = 2];
+
+  // size of lookup table
+  optional int32 lut_size = 8 [default = 256];
+}
+
+// Message that stores parameters used by ValueTransformationLayer
+message ValueTransformationParameter {
+  // Per channel offset which is added to the original channels
+  // Pass one float to add the same value to all channels, pass nChannels
+  // floats to add individual offsets for each channel
+  optional VectorFloat offset = 1;
+  // Per channel scale that is applied after adding the offset
+  // One value: apply same scale to all channels, nChannels values: apply
+  // individual scale per layer
+  optional VectorFloat scale = 2;
+}
+
 message WindowDataParameter {
   // Specify the data source.
   optional string source = 1;
diff --git a/src/caffe/test/test_apply_deformation_layer.cpp b/src/caffe/test/test_apply_deformation_layer.cpp
new file mode 100644
index 0000000..de748aa
--- /dev/null
+++ b/src/caffe/test/test_apply_deformation_layer.cpp
@@ -0,0 +1,413 @@
+#include <string>
+#include <vector>
+
+#include "google/protobuf/text_format.h"
+
+#include "gtest/gtest.h"
+
+#include "caffe/blob.hpp"
+#include "caffe/common.hpp"
+#include "caffe/proto/caffe.pb.h"
+#include "caffe/net.hpp"
+#include "caffe/layers/apply_deformation_layer.hpp"
+#include "caffe/util/vector_helper.hpp"
+
+#include "caffe/test/test_caffe_main.hpp"
+
+namespace caffe {
+
+template <typename Dtype>
+class ApplyDeformationLayerTest : public ::testing::Test {
+ protected:
+  ApplyDeformationLayerTest() {
+  }
+
+  virtual void SetUp() {
+  }
+
+  virtual ~ApplyDeformationLayerTest() {
+  }
+
+};
+
+TYPED_TEST_CASE(ApplyDeformationLayerTest, TestDtypes);
+
+TYPED_TEST(ApplyDeformationLayerTest, TestOutShape) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  ApplyDeformationParameter* apply_deformation_param = param.mutable_apply_deformation_param();
+  apply_deformation_param->set_interpolation("linear");
+  apply_deformation_param->set_extrapolation("mirror");
+
+  // Test reshaping for 2 input blobs
+  // 2D, 2 components
+  ApplyDeformationLayer<TypeParam> layer(param);
+  Blob<TypeParam> data;
+  Blob<TypeParam> deform;
+  data.Reshape(2, 4, 5, 7);  // num, c, y, x
+  deform.Reshape(2, 5, 7, 2); // num, y, x, ncomp
+  vector<Blob<TypeParam>*> blob_bottom_vec;
+  blob_bottom_vec.push_back( &data);
+  blob_bottom_vec.push_back( &deform);
+  Blob<TypeParam> top;
+  vector<Blob<TypeParam>*> blob_top_vec;
+  blob_top_vec.push_back( &top);
+  layer.SetUp(blob_bottom_vec, blob_top_vec);
+
+  EXPECT_EQ("2 4 5 7 (280)", top.shape_string());
+
+  // 3D, 2 components
+  data.Reshape(make_vec<int>(2, 4, 5, 7, 9));  // num, c, z, y, x
+  deform.Reshape(make_vec<int>(2, 5, 7, 9, 2)); // num, z, y, x, ncomp
+  layer.SetUp(blob_bottom_vec, blob_top_vec);
+  EXPECT_EQ("2 4 5 7 9 (2520)", top.shape_string());
+
+  // 3D, 3 components
+  data.Reshape(make_vec<int>(2, 4, 5, 7, 9));  // num, c, z, y, x
+  deform.Reshape(make_vec<int>(2, 5, 7, 9, 3)); // num, z, y, x, ncomp
+  layer.SetUp(blob_bottom_vec, blob_top_vec);
+  EXPECT_EQ("2 4 5 7 9 (2520)", top.shape_string());
+
+#if 0
+  // 3D, 2 components
+  data.Reshape(make_vec<int>(2, 4, 5, 7, 9));  // num, c, z, y, x
+  deform.Reshape(make_vec<int>(2, 5, 7, 9, 2)); // num, z, y, x, ncomp
+  ref.Reshape(make_vec<int>(2, 1, 3, 4, 6)); // num, c, z, y, x  (only shape of z, y and x is used)
+  layer.SetUp(blob_bottom_vec, blob_top_vec);
+  EXPECT_EQ("2 4 3 4 6 (576)", top.shape_string());
+
+  // 3D, 3 components
+  deform.Reshape(make_vec<int>(2, 5, 7, 9, 3)); // num, z, y, x, ncomp
+  layer.SetUp(blob_bottom_vec, blob_top_vec);
+  EXPECT_EQ("2 4 3 4 6 (576)", top.shape_string());
+#endif
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestOutShapeFromRef_2D_2comp) {
+  // Test reshaping to shape of a reference blob
+  // 2D, 2 components
+  string proto =
+      "name: 'TestNetwork' "
+      "layer { "
+      "  name: 'data' "
+      "  type: 'DummyData' "
+      "  dummy_data_param { "
+      "    shape { dim: 2 dim: 4 dim: 5 dim: 7 } " // num, c, y, x
+      "    shape { dim: 2 dim: 5 dim: 7 dim: 2 } " // num, y, x, ncomp
+      "    shape { dim: 2 dim: 1 dim: 3 dim: 4 } " // num, c, y, x (only
+      "  } "                                       //  shape of y and x is used)
+      "  top: 'data' "
+      "  top: 'deform' "
+      "  top: 'ref' "
+      "} "
+      "layer { "
+      "  name: 'apply_deformation' "
+      "  type: 'ApplyDeformation' "
+      "  bottom: 'data' "
+      "  bottom: 'deform' "
+      "  top: 'deformed_data' "
+      "  apply_deformation_param { "
+      "    interpolation: 'nearest' "
+      "    extrapolation: 'mirror' "
+      "    output_shape_from: 'ref' "
+      "  } "
+      "}";
+  NetParameter param;
+  CHECK(google::protobuf::TextFormat::ParseFromString(proto, &param));
+  Net<TypeParam> net( param);
+  EXPECT_EQ("2 4 3 4 (96)", net.blob_by_name("deformed_data")->shape_string());
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestOutShapeFromRef_3D_2comp) {
+  // Test reshaping to shape of a reference blob
+  // 2D, 2 components
+  string proto =
+      "name: 'TestNetwork' "
+      "layer { "
+      "  name: 'data' "
+      "  type: 'DummyData' "
+      "  dummy_data_param { "
+      "    shape { dim: 2 dim: 4 dim: 5 dim: 7 dim: 9} " // num, c, z, y, x
+      "    shape { dim: 2 dim: 5 dim: 7 dim: 9 dim: 2 } " // num, z, y, x, ncomp
+      "    shape { dim: 2 dim: 1 dim: 3 dim: 4 dim: 6 } " // num, c, z, y, x (only shape of z, y and x is used)
+      "  } "
+      "  top: 'data' "
+      "  top: 'deform' "
+      "  top: 'ref' "
+      "} "
+      "layer { "
+      "  name: 'apply_deformation' "
+      "  type: 'ApplyDeformation' "
+      "  bottom: 'data' "
+      "  bottom: 'deform' "
+      "  top: 'deformed_data' "
+      "  apply_deformation_param { "
+      "    interpolation: 'nearest' "
+      "    extrapolation: 'mirror' "
+      "    output_shape_from: 'ref' "
+      "  } "
+      "}";
+  NetParameter param;
+  CHECK(google::protobuf::TextFormat::ParseFromString(proto, &param));
+  Net<TypeParam> net( param);
+  EXPECT_EQ("2 4 3 4 6 (576)", net.blob_by_name("deformed_data")->shape_string());
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestOutShapeFromRef_3D_3comp) {
+  // Test reshaping to shape of a reference blob
+  // 2D, 2 components
+  string proto =
+      "name: 'TestNetwork' "
+      "layer { "
+      "  name: 'data' "
+      "  type: 'DummyData' "
+      "  dummy_data_param { "
+      "    shape { dim: 2 dim: 4 dim: 5 dim: 7 dim: 9} " // num, c, z, y, x
+      "    shape { dim: 2 dim: 5 dim: 7 dim: 9 dim: 3 } " // num, z, y, x, ncomp
+      "    shape { dim: 2 dim: 1 dim: 3 dim: 4 dim: 6 } " // num, c, z, y, x (only shape of z, y and x is used)
+      "  } "
+      "  top: 'data' "
+      "  top: 'deform' "
+      "  top: 'ref' "
+      "} "
+      "layer { "
+      "  name: 'apply_deformation' "
+      "  type: 'ApplyDeformation' "
+      "  bottom: 'data' "
+      "  bottom: 'deform' "
+      "  top: 'deformed_data' "
+      "  apply_deformation_param { "
+      "    interpolation: 'nearest' "
+      "    extrapolation: 'mirror' "
+      "    output_shape_from: 'ref' "
+      "  } "
+      "}";
+  NetParameter param;
+  CHECK(google::protobuf::TextFormat::ParseFromString(proto, &param));
+  Net<TypeParam> net( param);
+  EXPECT_EQ("2 4 3 4 6 (576)", net.blob_by_name("deformed_data")->shape_string());
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestExtrapolationMirror) {
+  Caffe::set_mode(Caffe::CPU);
+  TypeParam data[] = {0,1,2,3,4};
+  TypeParam def[] = {0,-10,
+                     0,-9,
+                     0,-8,
+                     0,-7,
+                     0,-6,
+                     0,-5,
+                     0,-4,
+                     0,-3,
+                     0,-2,
+                     0,-1,
+                     0,0,
+                     0,1,
+                     0,2,
+                     0,3,
+                     0,4,
+                     0,5,
+                     0,6,
+                     0,7,
+                     0,8,
+                     0,9,
+                     0,10};
+  std::vector<TypeParam> out(21);
+  transform2D( data, 1, 1, 1, 1,  5,
+               def,  1,    1, 1, 21,
+               out.data(),  1, 1, 1, 1, 21, linear2D_mirror<TypeParam>);
+  EXPECT_EQ( "(2,1,0,1,2,3,4,3,2,1,0,1,2,3,4,3,2,1,0,1,2)", toString(out));
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestExtrapolationZero) {
+  Caffe::set_mode(Caffe::CPU);
+  TypeParam data[] = {10,11,12,13,14};
+  TypeParam def[] = {0,-10,
+                     0,-9,
+                     0,-8,
+                     0,-7,
+                     0,-6,
+                     0,-5,
+                     0,-4,
+                     0,-3,
+                     0,-2,
+                     0,-1,
+                     0,0,
+                     0,1,
+                     0,2,
+                     0,3,
+                     0,4,
+                     0,5,
+                     0,6,
+                     0,7,
+                     0,8,
+                     0,9,
+                     0,10};
+  std::vector<TypeParam> out(21);
+  transform2D( data, 1, 1, 1, 1,  5,
+               def,  1,    1, 1, 21,
+               out.data(),  1, 1, 1, 1, 21, linear2D_zeropad<TypeParam>);
+  EXPECT_EQ( "(0,0,0,0,0,0,0,0,0,0,10,11,12,13,14,0,0,0,0,0,0)", toString(out));
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestLinearInterpolation2D) {
+  Caffe::set_mode(Caffe::CPU);
+  TypeParam data[] = {0, 1,
+                      0, 2};
+  TypeParam def[] = {0,  0.5,
+                     0,  1,
+                     0.5, 0.5,
+                     0.5, 1};
+  std::vector<TypeParam> out(4);
+  transform2D( data, 1, 1, 1, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, linear2D_zeropad<TypeParam>);
+  EXPECT_EQ( "(0.5,1,0.75,1.5)", toString(out));
+  transform2D( data, 1, 1, 1, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, linear2D_mirror<TypeParam>);
+  EXPECT_EQ( "(0.5,1,0.75,1.5)", toString(out));
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestLinearInterpolation3D) {
+  Caffe::set_mode(Caffe::CPU);
+  TypeParam data[] = {0, 1,
+                      0, 2,
+                      0, 0,
+                      0, 3};
+  TypeParam def[] = {0,   0, 0.5,
+                     0,   1,   1,
+                     0.5, 0.5, 0.5,
+                     1,   1,   0.25};
+  std::vector<TypeParam> out(4);
+  transform3D( data, 1, 1, 2, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, linear3D_zeropad<TypeParam>);
+  EXPECT_EQ( "(0.5,2,0.75,0.75)", toString(out));
+  transform3D( data, 1, 1, 2, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, linear3D_mirror<TypeParam>);
+  EXPECT_EQ( "(0.5,2,0.75,0.75)", toString(out));
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestNearestInterpolation2D) {
+  Caffe::set_mode(Caffe::CPU);
+  TypeParam data[] = {0, 1,
+                      0, 2};
+  TypeParam def[] = {0,  0.5,
+                     0,  1,
+                     0.5, 0.5,
+                     0.5, 1};
+  std::vector<TypeParam> out(4);
+  transform2D( data, 1, 1, 1, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, nearest2D_zeropad<TypeParam>);
+  EXPECT_EQ( "(1,1,2,2)", toString(out));
+  transform2D( data, 1, 1, 1, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, nearest2D_mirror<TypeParam>);
+  EXPECT_EQ( "(1,1,2,2)", toString(out));
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestnearestInterpolation3D) {
+  Caffe::set_mode(Caffe::CPU);
+  TypeParam data[] = {0, 1,
+                      0, 2,
+                      0, 0,
+                      0, 3};
+  TypeParam def[] = {0,   0, 0.5,
+                     0,   1,   1,
+                     0.5, 0.5, 0.5,
+                     1,   1,   0.25};
+  std::vector<TypeParam> out(4);
+  transform3D( data, 1, 1, 2, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, nearest3D_zeropad<TypeParam>);
+  EXPECT_EQ( "(1,2,3,0)", toString(out));
+  transform3D( data, 1, 1, 2, 2, 2,
+               def,  1,    1, 2, 2,
+               out.data(),  1, 1, 1, 2, 2, nearest3D_mirror<TypeParam>);
+  EXPECT_EQ( "(1,2,3,0)", toString(out));
+}
+
+TYPED_TEST(ApplyDeformationLayerTest, TestRotate90) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  ApplyDeformationParameter* apply_deformation_param = param.mutable_apply_deformation_param();
+  apply_deformation_param->set_interpolation("linear");
+  apply_deformation_param->set_extrapolation("zero");
+
+  // Test 90 degree rotation
+  // 2D, 2 components
+  ApplyDeformationLayer<TypeParam> layer(param);
+  Blob<TypeParam> data;
+  Blob<TypeParam> deform;
+  data.Reshape(2, 4, 5, 9);  // num, c, y, x
+  deform.Reshape(2, 5, 9, 2); // num, y, x, ncomp
+  vector<Blob<TypeParam>*> blob_bottom_vec;
+  blob_bottom_vec.push_back( &data);
+  blob_bottom_vec.push_back( &deform);
+  Blob<TypeParam> top;
+  vector<Blob<TypeParam>*> blob_top_vec;
+  blob_top_vec.push_back( &top);
+  layer.SetUp(blob_bottom_vec, blob_top_vec);
+
+  // fill data blob with unique values
+  for( int i = 0; i < data.count(); ++i) {
+    data.mutable_cpu_data()[i] = 10 + i;
+  }
+//  std::cout << "input field: \n"
+//            << Array2DtoString( data.cpu_data(), data.shape(-2), data.shape(-1))
+//            << std::endl;
+
+  // setup 90 degree rotation
+  for( int n = 0; n < deform.shape(0); ++n) {
+    for( int y = 0; y < deform.shape(1); ++y) {
+      for( int x = 0; x < deform.shape(2); ++x) {
+        int offs = deform.offset(make_vec<int>(n, y, x, 0));
+        deform.mutable_cpu_data()[offs] = x - 2;
+        deform.mutable_cpu_data()[offs + 1] = 6 - y;
+      }
+    }
+  }
+//  std::cout << "Deformation field: \n"
+//            << Array2DtoString( deform.cpu_data(), deform.shape(1), deform.shape(2)*2)
+//            << std::endl;
+  // apply layer
+  layer.Forward(blob_bottom_vec, blob_top_vec);
+
+  // check result
+//  std::cout << "output field: \n"
+//            << Array2DtoString( top.cpu_data(), top.shape(-2), top.shape(-1))
+//            << std::endl;
+
+  EXPECT_EQ(
+      "0,0,16,25,34,43,52,0,0,\n"
+      "0,0,15,24,33,42,51,0,0,\n"
+      "0,0,14,23,32,41,50,0,0,\n"
+      "0,0,13,22,31,40,49,0,0,\n"
+      "0,0,12,21,30,39,48,0,0,\n", Array2DtoString( top.cpu_data(), top.shape(-2), top.shape(-1)));
+
+  EXPECT_EQ(
+      "0,0,331,340,349,358,367,0,0,\n"
+      "0,0,330,339,348,357,366,0,0,\n"
+      "0,0,329,338,347,356,365,0,0,\n"
+      "0,0,328,337,346,355,364,0,0,\n"
+      "0,0,327,336,345,354,363,0,0,\n", Array2DtoString( top.cpu_data() + top.offset(1,3,0,0), top.shape(-2), top.shape(-1)));
+
+  // test mirroring
+  //
+  apply_deformation_param->set_extrapolation("mirror");
+  ApplyDeformationLayer<TypeParam> layer2(param);
+  layer2.SetUp(blob_bottom_vec, blob_top_vec);
+  layer2.Forward(blob_bottom_vec, blob_top_vec);
+  EXPECT_EQ(
+      "34,25,16,25,34,43,52,43,34,\n"
+      "33,24,15,24,33,42,51,42,33,\n"
+      "32,23,14,23,32,41,50,41,32,\n"
+      "31,22,13,22,31,40,49,40,31,\n"
+      "30,21,12,21,30,39,48,39,30,\n", Array2DtoString( top.cpu_data(), top.shape(-2), top.shape(-1)));
+
+}
+
+}  // namespace caffe
diff --git a/src/caffe/test/test_concat_layer.cpp b/src/caffe/test/test_concat_layer.cpp
index 23c1e8c..64e5d44 100644
--- a/src/caffe/test/test_concat_layer.cpp
+++ b/src/caffe/test/test_concat_layer.cpp
@@ -40,18 +40,47 @@ class ConcatLayerTest : public MultiDeviceTest<TypeParam> {
     blob_bottom_vec_1_.push_back(blob_bottom_0_);
     blob_bottom_vec_1_.push_back(blob_bottom_2_);
     blob_top_vec_.push_back(blob_top_);
+
+    // testing 3D blobs and cropping
+    vector<int> shape1(5);
+    shape1[0] = 2;
+    shape1[1] = 5;
+    shape1[2] = 3;
+    shape1[3] = 6;
+    shape1[4] = 4;
+    blob_bottom_3d1_ = new Blob<Dtype>( shape1);
+    filler_param.set_value(1.);
+    GaussianFiller<Dtype> gfiller(filler_param);
+    gfiller.Fill(this->blob_bottom_3d1_);
+
+    vector<int> shape2(5);
+    shape2[0] = 2;
+    shape2[1] = 4;
+    shape2[2] = 5;
+    shape2[3] = 8;
+    shape2[4] = 10;
+    blob_bottom_3d2_ = new Blob<Dtype>( shape2);
+    gfiller.Fill(this->blob_bottom_3d2_);
+
+    blob_bottom_vec_3d1_.push_back( blob_bottom_3d1_);
+    blob_bottom_vec_3d1_.push_back( blob_bottom_3d2_);
   }
 
   virtual ~ConcatLayerTest() {
     delete blob_bottom_0_; delete blob_bottom_1_;
     delete blob_bottom_2_; delete blob_top_;
+    delete blob_bottom_3d1_;
+    delete blob_bottom_3d2_;
   }
 
   Blob<Dtype>* const blob_bottom_0_;
   Blob<Dtype>* const blob_bottom_1_;
   Blob<Dtype>* const blob_bottom_2_;
   Blob<Dtype>* const blob_top_;
+  Blob<Dtype>* blob_bottom_3d1_;
+  Blob<Dtype>* blob_bottom_3d2_;
   vector<Blob<Dtype>*> blob_bottom_vec_0_, blob_bottom_vec_1_;
+  vector<Blob<Dtype>*> blob_bottom_vec_3d1_;
   vector<Blob<Dtype>*> blob_top_vec_;
 };
 
@@ -204,4 +233,73 @@ TYPED_TEST(ConcatLayerTest, TestGradientChannelsBottomOneOnly) {
     this->blob_top_vec_, 1);
 }
 
+TYPED_TEST(ConcatLayerTest, TestSetupChannels3DAndCrop) {
+  typedef typename TypeParam::Dtype Dtype;
+  LayerParameter layer_param;
+  ConcatLayer<Dtype> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_3d1_, this->blob_top_vec_);
+  for( int j = 0; j < this->blob_bottom_3d1_->num_axes(); ++j)
+  {
+    if( j == layer_param.concat_param().axis()) {
+      EXPECT_EQ(this->blob_top_->shape(j),
+                this->blob_bottom_3d1_->shape(j) + this->blob_bottom_3d2_->shape(j));
+    } else {
+      EXPECT_EQ(this->blob_top_->shape(j),
+                this->blob_bottom_3d1_->shape(j));
+    }
+  }
+}
+
+TYPED_TEST(ConcatLayerTest, TestForwardChannels3DAndCrop) {
+  typedef typename TypeParam::Dtype Dtype;
+  LayerParameter layer_param;
+  ConcatLayer<Dtype> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_3d1_, this->blob_top_vec_);
+  layer.Forward(this->blob_bottom_vec_3d1_, this->blob_top_vec_);
+  vector<int> i(5);
+  vector<int> in;
+  vector<int> out;
+
+  for (i[0] = 0; i[0] < this->blob_top_->shape(0); ++i[0]) {
+    for (i[1] = 0; i[1] < this->blob_bottom_3d1_->shape(1); ++i[1]) {
+      for (i[2] = 0; i[2] < this->blob_top_->shape(2); ++i[2]) {
+        for (i[3] = 0; i[3] < this->blob_top_->shape(3); ++i[3]) {
+          for (i[4] = 0; i[4] < this->blob_top_->shape(4); ++i[4]) {
+            EXPECT_EQ(this->blob_top_->data_at(i),
+                      this->blob_bottom_vec_3d1_[0]->data_at(i));
+          }
+        }
+      }
+    }
+    for (i[1] = 0; i[1] < this->blob_bottom_3d2_->shape(1); ++i[1]) {
+      for (i[2] = 0; i[2] < this->blob_top_->shape(2); ++i[2]) {
+        for (i[3] = 0; i[3] < this->blob_top_->shape(3); ++i[3]) {
+          for (i[4] = 0; i[4] < this->blob_top_->shape(4); ++i[4]) {
+            in = i;
+            out = i;
+            in[2] += 1;
+            in[3] += 1;
+            in[4] += 3;
+            out[1] += 5;
+
+            EXPECT_EQ(this->blob_top_->data_at(out),
+                      this->blob_bottom_vec_3d1_[1]->data_at(in)) <<
+                "in = (" << in[0] << "," << in[1] << "," << in[2] << "," << in[3] << "," << in[4] << "), "
+                "out = (" << out[0] << "," << out[1] << "," << out[2] << "," << out[3] << "," << out[4] << ")";
+          }
+        }
+      }
+    }
+  }
+}
+
+TYPED_TEST(ConcatLayerTest, TestGradientChannels3DAndCrop) {
+  typedef typename TypeParam::Dtype Dtype;
+  LayerParameter layer_param;
+  ConcatLayer<Dtype> layer(layer_param);
+  GradientChecker<Dtype> checker(1e-2, 1e-2);
+  checker.CheckGradient(&layer, this->blob_bottom_vec_3d1_,
+    this->blob_top_vec_);
+}
+
 }  // namespace caffe
diff --git a/src/caffe/test/test_convolution_layer.cpp b/src/caffe/test/test_convolution_layer.cpp
index 9bb19d1..ee528f6 100644
--- a/src/caffe/test/test_convolution_layer.cpp
+++ b/src/caffe/test/test_convolution_layer.cpp
@@ -856,6 +856,59 @@ class CuDNNConvolutionLayerTest : public GPUDeviceTest<Dtype> {
 
 TYPED_TEST_CASE(CuDNNConvolutionLayerTest, TestDtypes);
 
+template <typename Dtype>
+class CuDNNConvolutionLayerTest3D : public GPUDeviceTest<Dtype> {
+ protected:
+  CuDNNConvolutionLayerTest3D()
+      : blob_bottom_(new Blob<Dtype>(2,3,6,4)),
+        blob_bottom_2_(new Blob<Dtype>(2,3,6,4)),
+        blob_top_(new Blob<Dtype>()),
+        blob_top_2_(new Blob<Dtype>()) {}
+  virtual void SetUp() {
+    // create the blobs
+    vector<int> blob_shape;
+    //blob_shape.push_back(5);
+    blob_shape.push_back(2);
+    blob_shape.push_back(3);
+    blob_shape.push_back(6);
+    blob_shape.push_back(4);
+    blob_shape.push_back(5);
+    blob_bottom_->Reshape(blob_shape);
+    blob_bottom_2_->Reshape(blob_shape);
+    // fill the values
+    FillerParameter filler_param;
+    filler_param.set_value(1.);
+    GaussianFiller<Dtype> filler(filler_param);
+    filler.Fill(this->blob_bottom_);
+    filler.Fill(this->blob_bottom_2_);
+    blob_bottom_vec_.push_back(blob_bottom_);
+    blob_top_vec_.push_back(blob_top_);
+  }
+
+  virtual ~CuDNNConvolutionLayerTest3D() {
+    delete blob_bottom_;
+    delete blob_bottom_2_;
+    delete blob_top_;
+    delete blob_top_2_;
+  }
+
+  virtual Blob<Dtype>* MakeReferenceTop(Blob<Dtype>* top) {
+    this->ref_blob_top_.reset(new Blob<Dtype>());
+    this->ref_blob_top_->ReshapeLike(*top);
+    return this->ref_blob_top_.get();
+  }
+
+  Blob<Dtype>* const blob_bottom_;
+  Blob<Dtype>* const blob_bottom_2_;
+  Blob<Dtype>* const blob_top_;
+  Blob<Dtype>* const blob_top_2_;
+  shared_ptr<Blob<Dtype> > ref_blob_top_;
+  vector<Blob<Dtype>*> blob_bottom_vec_;
+  vector<Blob<Dtype>*> blob_top_vec_;
+};
+
+TYPED_TEST_CASE(CuDNNConvolutionLayerTest3D, TestDtypes);
+
 TYPED_TEST(CuDNNConvolutionLayerTest, TestSetupCuDNN) {
   this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
   this->blob_top_vec_.push_back(this->blob_top_2_);
@@ -893,6 +946,48 @@ TYPED_TEST(CuDNNConvolutionLayerTest, TestSetupCuDNN) {
   EXPECT_EQ(this->blob_top_2_->width(), 1);
 }
 
+TYPED_TEST(CuDNNConvolutionLayerTest3D, TestSetup3DCuDNN) {
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(4);
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNConvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_->shape(1), 4);
+  EXPECT_EQ(this->blob_top_->shape(2), 2);
+  EXPECT_EQ(this->blob_top_->shape(3), 1);
+  EXPECT_EQ(this->blob_top_->shape(4), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(1), 4);
+  EXPECT_EQ(this->blob_top_2_->shape(2), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(3), 1);
+  EXPECT_EQ(this->blob_top_2_->shape(4), 2);
+
+  // setting group should not change the shape
+  convolution_param->set_num_output(3);
+  convolution_param->set_group(3);
+  layer.reset(new CuDNNConvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_->shape(1), 3);
+  EXPECT_EQ(this->blob_top_->shape(2), 2);
+  EXPECT_EQ(this->blob_top_->shape(3), 1);
+  EXPECT_EQ(this->blob_top_->shape(4), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(1), 3);
+  EXPECT_EQ(this->blob_top_2_->shape(2), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(3), 1);
+  EXPECT_EQ(this->blob_top_2_->shape(4), 2);
+}
+
 TYPED_TEST(CuDNNConvolutionLayerTest, TestSimpleConvolutionCuDNN) {
   this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
   this->blob_top_vec_.push_back(this->blob_top_2_);
@@ -928,6 +1023,41 @@ TYPED_TEST(CuDNNConvolutionLayerTest, TestSimpleConvolutionCuDNN) {
   }
 }
 
+TYPED_TEST(CuDNNConvolutionLayerTest3D, TestSimpleConvolution3DCuDNN) {
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(4);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("constant");
+  convolution_param->mutable_bias_filler()->set_value(0.1);
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNConvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Check against reference convolution.
+  const TypeParam* top_data;
+  const TypeParam* ref_top_data;
+  caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
+      this->MakeReferenceTop(this->blob_top_));
+  top_data = this->blob_top_->cpu_data();
+  ref_top_data = this->ref_blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_top_->count(); ++i) {
+    EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
+  }
+  caffe_conv(this->blob_bottom_2_, convolution_param, layer->blobs(),
+      this->MakeReferenceTop(this->blob_top_2_));
+  top_data = this->blob_top_2_->cpu_data();
+  ref_top_data = this->ref_blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_top_->count(); ++i) {
+    EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
+  }
+}
+
 TYPED_TEST(CuDNNConvolutionLayerTest, TestSimpleConvolutionGroupCuDNN) {
   LayerParameter layer_param;
   ConvolutionParameter* convolution_param =
@@ -955,6 +1085,33 @@ TYPED_TEST(CuDNNConvolutionLayerTest, TestSimpleConvolutionGroupCuDNN) {
   }
 }
 
+ TYPED_TEST(CuDNNConvolutionLayerTest3D, TestSimpleConvolutionGroup3DCuDNN) {
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(3);
+  convolution_param->set_group(3);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("constant");
+  convolution_param->mutable_bias_filler()->set_value(0.1);
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNConvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Check against reference convolution.
+  const TypeParam* top_data;
+  const TypeParam* ref_top_data;
+  caffe_conv(this->blob_bottom_, convolution_param, layer->blobs(),
+      this->MakeReferenceTop(this->blob_top_));
+  top_data = this->blob_top_->cpu_data();
+  ref_top_data = this->ref_blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_top_->count(); ++i) {
+    EXPECT_NEAR(top_data[i], ref_top_data[i], 1e-4);
+  }
+}
+
 TYPED_TEST(CuDNNConvolutionLayerTest, TestSobelConvolutionCuDNN) {
   // Test separable convolution by computing the Sobel operator
   // as a single filter then comparing the result
@@ -1065,6 +1222,23 @@ TYPED_TEST(CuDNNConvolutionLayerTest, TestGradientCuDNN) {
       this->blob_top_vec_);
 }
 
+TYPED_TEST(CuDNNConvolutionLayerTest3D, TestGradient3DCuDNN) {
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(2);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("gaussian");
+  CuDNNConvolutionLayer<TypeParam> layer(layer_param);
+  GradientChecker<TypeParam> checker(1e-2, 1e-3);
+  checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
+      this->blob_top_vec_);
+}
+
 TYPED_TEST(CuDNNConvolutionLayerTest, TestGradientGroupCuDNN) {
   LayerParameter layer_param;
   ConvolutionParameter* convolution_param =
@@ -1081,6 +1255,22 @@ TYPED_TEST(CuDNNConvolutionLayerTest, TestGradientGroupCuDNN) {
       this->blob_top_vec_);
 }
 
+TYPED_TEST(CuDNNConvolutionLayerTest3D, TestGradientGroup3DCuDNN) {
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(3);
+  convolution_param->set_group(3);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("gaussian");
+  CuDNNConvolutionLayer<TypeParam> layer(layer_param);
+  GradientChecker<TypeParam> checker(1e-2, 1e-3);
+  checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
+      this->blob_top_vec_);
+}
+
 #endif
 
 }  // namespace caffe
diff --git a/src/caffe/test/test_create_deformation_layer.cpp b/src/caffe/test/test_create_deformation_layer.cpp
new file mode 100644
index 0000000..6ecba11
--- /dev/null
+++ b/src/caffe/test/test_create_deformation_layer.cpp
@@ -0,0 +1,508 @@
+#include <string>
+#include <vector>
+
+#include "gtest/gtest.h"
+
+#include "caffe/blob.hpp"
+#include "caffe/common.hpp"
+#include "caffe/proto/caffe.pb.h"
+#include "caffe/layers/create_deformation_layer.hpp"
+#include "caffe/util/vector_helper.hpp"
+
+#include "caffe/test/test_caffe_main.hpp"
+
+namespace caffe {
+
+template <typename Dtype>
+class CreateDeformationLayerTest : public ::testing::Test {
+ protected:
+  CreateDeformationLayerTest()
+      : blob_top_a_(new Blob<Dtype>()),
+        blob_top_b_(new Blob<Dtype>()),
+        blob_top_c_(new Blob<Dtype>()) {}
+
+  virtual void SetUp() {
+    blob_bottom_vec_.clear();
+    blob_top_vec_.clear();
+    blob_top_vec_.push_back(blob_top_a_);
+    blob_top_vec_.push_back(blob_top_b_);
+    blob_top_vec_.push_back(blob_top_c_);
+  }
+
+  virtual ~CreateDeformationLayerTest() {
+    delete blob_top_a_;
+    delete blob_top_b_;
+    delete blob_top_c_;
+  }
+
+  Blob<Dtype>* const blob_top_a_;
+  Blob<Dtype>* const blob_top_b_;
+  Blob<Dtype>* const blob_top_c_;
+  vector<Blob<Dtype>*> blob_bottom_vec_;
+  vector<Blob<Dtype>*> blob_top_vec_;
+};
+
+TYPED_TEST_CASE(CreateDeformationLayerTest, TestDtypes);
+
+TYPED_TEST(CreateDeformationLayerTest, Test3DIdentityTransform) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+  create_deformation_param->set_batch_size(1);
+  create_deformation_param->set_nz(3);
+  create_deformation_param->set_ny(4);
+  create_deformation_param->set_nx(5);
+  create_deformation_param->set_ncomponents(3);
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_a_->shape(0), 1);
+  EXPECT_EQ(this->blob_top_a_->shape(1), 3);
+  EXPECT_EQ(this->blob_top_a_->shape(2), 4);
+  EXPECT_EQ(this->blob_top_a_->shape(3), 5);
+  EXPECT_EQ(this->blob_top_a_->shape(4), 3);
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(
+      "0,0,0,0,0,1,0,0,2,0,0,3,0,0,4,\n"
+      "0,1,0,0,1,1,0,1,2,0,1,3,0,1,4,\n"
+      "0,2,0,0,2,1,0,2,2,0,2,3,0,2,4,\n"
+      "0,3,0,0,3,1,0,3,2,0,3,3,0,3,4,\n",
+      Array2DtoString( this->blob_top_vec_[0]->cpu_data(), 4,5*3));
+  EXPECT_EQ(
+      "1,0,0,1,0,1,1,0,2,1,0,3,1,0,4,\n"
+      "1,1,0,1,1,1,1,1,2,1,1,3,1,1,4,\n"
+      "1,2,0,1,2,1,1,2,2,1,2,3,1,2,4,\n"
+      "1,3,0,1,3,1,1,3,2,1,3,3,1,3,4,\n",
+      Array2DtoString( this->blob_top_vec_[0]->cpu_data() + 1*4*5*3, 4,5*3));
+  EXPECT_EQ(
+      "2,0,0,2,0,1,2,0,2,2,0,3,2,0,4,\n"
+      "2,1,0,2,1,1,2,1,2,2,1,3,2,1,4,\n"
+      "2,2,0,2,2,1,2,2,2,2,2,3,2,2,4,\n"
+      "2,3,0,2,3,1,2,3,2,2,3,3,2,3,4,\n",
+      Array2DtoString( this->blob_top_vec_[0]->cpu_data() + 2*4*5*3, 4,5*3));
+
+//  for (int z = 0; z < 10; ++z) {
+//    for (int y = 0; y < 15; ++y) {
+//      for (int x = 0; x < 20; ++x) {
+//        EXPECT_EQ( z, this->blob_top_vec_[0]->data_at( make_vec(0,z,y,x,0)));
+//        EXPECT_EQ( y, this->blob_top_vec_[0]->data_at( make_vec(0,z,y,x,1)));
+//        EXPECT_EQ( x, this->blob_top_vec_[0]->data_at( make_vec(0,z,y,x,2)));
+//      }
+//    }
+//  }
+}
+
+TYPED_TEST(CreateDeformationLayerTest, Test2DElasticTransform) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+  //  X - - - X - - - X - - - X - - - X - - - X - - - X
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  - - - - # # # # # # # # # # # # # # # - - - - - -
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  X - - - X - - - X - - - X - - - X - - - X - - - X
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  - - - - - - - - - - - - - - - - - - - - - - - - -
+  //  X - - - X - - - X - - - X - - - X - - - X - - - X
+  //
+  //
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+  //  X - - - X # # # X # # # X # # # X # # - X - - - X
+
+
+  create_deformation_param->set_batch_size(3);
+  create_deformation_param->set_ny(10);
+  create_deformation_param->set_nx(15);
+  create_deformation_param->set_ncomponents(2);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(4);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(4);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(10);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(10);
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill blob with 42
+  for (int i = 0; i < this->blob_top_vec_[0]->count(); ++i) {
+    this->blob_top_vec_[0]->mutable_cpu_data()[i] = 42;
+  }
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // every should have been altered
+  for (int i = 0; i < this->blob_top_vec_[0]->count(); ++i) {
+    EXPECT_NE( 42, this->blob_top_vec_[0]->cpu_data()[i])
+        << "at index i=" << i;
+  }
+}
+
+TYPED_TEST(CreateDeformationLayerTest, Test3DElasticTransform) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  create_deformation_param->set_batch_size(3);
+  create_deformation_param->set_nz(5);  // 5 control points
+  create_deformation_param->set_ny(10); // 6 control points
+  create_deformation_param->set_nx(15); // 7 control points
+  create_deformation_param->set_ncomponents(3);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(3);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(4);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(4);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(5);  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(10);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(10);
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill blob with 42
+  for (int i = 0; i < this->blob_top_vec_[0]->count(); ++i) {
+    this->blob_top_vec_[0]->mutable_cpu_data()[i] = 42;
+  }
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // every should have been altered
+  for (int i = 0; i < this->blob_top_vec_[0]->count(); ++i) {
+    EXPECT_NE( 42, this->blob_top_vec_[0]->cpu_data()[i])
+        << "at index i=" << i;
+  }
+}
+
+TYPED_TEST(CreateDeformationLayerTest, TestUnitTransform) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  create_deformation_param->set_batch_size(1);
+  create_deformation_param->set_nz(3);
+  create_deformation_param->set_ny(4);
+  create_deformation_param->set_nx(5);
+  create_deformation_param->set_ncomponents(3);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(1);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(1);
+  create_deformation_param->mutable_random_elastic_grid_spacing()->add_v(1);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(1e-30);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(1e-30);
+  create_deformation_param->mutable_random_elastic_deform_magnitude()->add_v(1e-30);
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill blob with 42
+  for (int i = 0; i < this->blob_top_vec_[0]->count(); ++i) {
+    this->blob_top_vec_[0]->mutable_cpu_data()[i] = 42;
+  }
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // check for unity
+  EXPECT_EQ(
+      "0,0,0,0,0,1,0,0,2,0,0,3,0,0,4,\n"
+      "0,1,0,0,1,1,0,1,2,0,1,3,0,1,4,\n"
+      "0,2,0,0,2,1,0,2,2,0,2,3,0,2,4,\n"
+      "0,3,0,0,3,1,0,3,2,0,3,3,0,3,4,\n",
+      Array2DtoString( this->blob_top_vec_[0]->cpu_data(), 4, 5*3));
+  EXPECT_EQ(
+      "1,0,0,1,0,1,1,0,2,1,0,3,1,0,4,\n"
+      "1,1,0,1,1,1,1,1,2,1,1,3,1,1,4,\n"
+      "1,2,0,1,2,1,1,2,2,1,2,3,1,2,4,\n"
+      "1,3,0,1,3,1,1,3,2,1,3,3,1,3,4,\n",
+      Array2DtoString( this->blob_top_vec_[0]->cpu_data() + 1*4*5*3, 4,5*3));
+  EXPECT_EQ(
+      "2,0,0,2,0,1,2,0,2,2,0,3,2,0,4,\n"
+      "2,1,0,2,1,1,2,1,2,2,1,3,2,1,4,\n"
+      "2,2,0,2,2,1,2,2,2,2,2,3,2,2,4,\n"
+      "2,3,0,2,3,1,2,3,2,2,3,3,2,3,4,\n",
+      Array2DtoString( this->blob_top_vec_[0]->cpu_data() + 2*4*5*3, 4,5*3));
+}
+
+
+TYPED_TEST(CreateDeformationLayerTest, TestAffineTransform) {
+  vector<TypeParam> M = make_vec<TypeParam>( 3, 0, 0,
+                                             2, 0, 0,
+                                             1, 0, 0);
+  vector<TypeParam> v = make_vec<TypeParam>( 1, 0, 0);
+  vector<TypeParam> out(3);
+
+  caffe_cpu_gemv<TypeParam>(CblasNoTrans, 3, 3, 1, M.data(), v.data(), 1, out.data());
+  EXPECT_EQ( 3, out[0]);
+  EXPECT_EQ( 2, out[1]);
+  EXPECT_EQ( 1, out[2]);
+
+  // TODO: continue this test
+
+}
+
+TYPED_TEST(CreateDeformationLayerTest, TestProbMapSampling) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  create_deformation_param->set_nz(7);
+  create_deformation_param->set_ny(8);
+  create_deformation_param->set_nx(9);
+  create_deformation_param->set_ncomponents(3);
+  create_deformation_param->set_random_offset_range_from_pdf(true);
+
+  Blob<TypeParam> probMap( make_vec( 3,1,7,8,9));
+  caffe_set( probMap.count(), TypeParam(0), probMap.mutable_cpu_data());
+
+  this->blob_bottom_vec_.clear();
+  this->blob_bottom_vec_.push_back( &probMap);
+
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(0,0,3,2,6))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(1,0,0,0,0))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(2,0,6,7,8))] = 1;
+
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill output blob with 42
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  const TypeParam* data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(0,-1.5,2)", toString( data, 3));
+  EXPECT_EQ( "(-3,-3.5,-4)", toString( data+7*8*9*3, 3));
+  EXPECT_EQ( "(3,3.5,4)", toString( data+2*7*8*9*3, 3));
+
+  // other positions
+  caffe_set( probMap.count(), TypeParam(0), probMap.mutable_cpu_data());
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(0,0,2,5,3))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(1,0,3,2,1))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(2,0,0,0,0))] = 1;
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(-1,1.5,-1)", toString( data, 3));
+  EXPECT_EQ( "(0,-1.5,-3)", toString( data+7*8*9*3, 3));
+  EXPECT_EQ( "(-3,-3.5,-4)", toString( data+2*7*8*9*3, 3));
+}
+
+TYPED_TEST(CreateDeformationLayerTest, TestProbMapSampling2) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  // same as test above, but for a smaller output
+  create_deformation_param->set_nz(1);
+  create_deformation_param->set_ny(5);
+  create_deformation_param->set_nx(3);
+  create_deformation_param->set_ncomponents(3);
+  create_deformation_param->set_random_offset_range_from_pdf(true);
+
+  Blob<TypeParam> probMap( make_vec( 3,1,7,8,9));
+  caffe_set( probMap.count(), TypeParam(0), probMap.mutable_cpu_data());
+
+  this->blob_bottom_vec_.clear();
+  this->blob_bottom_vec_.push_back( &probMap);
+
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(0,0,3,2,6))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(1,0,0,0,0))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(2,0,6,7,8))] = 1;
+
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill output blob with 42
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  const TypeParam* data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(3,0,5)", toString( data, 3));
+  EXPECT_EQ( "(0,-2,-1)", toString( data+1*5*3*3, 3));
+  EXPECT_EQ( "(6,5,7)", toString( data+2*1*5*3*3, 3));
+
+  // other positions
+  caffe_set( probMap.count(), TypeParam(0), probMap.mutable_cpu_data());
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(0,0,2,5,3))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(1,0,3,2,1))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(2,0,0,0,0))] = 1;
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(2,3,2)", toString( data, 3));
+  EXPECT_EQ( "(3,0,0)", toString( data+1*5*3*3, 3));
+  EXPECT_EQ( "(0,-2,-1)", toString( data+2*1*5*3*3, 3));
+}
+
+
+TYPED_TEST(CreateDeformationLayerTest, TestProbMapSampling3) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  // now for 2D data
+  create_deformation_param->set_ny(5);
+  create_deformation_param->set_nx(3);
+  create_deformation_param->set_ncomponents(2);
+  create_deformation_param->set_random_offset_range_from_pdf(true);
+
+  Blob<TypeParam> probMap( make_vec( 3,1,8,9));
+  caffe_set( probMap.count(), TypeParam(0), probMap.mutable_cpu_data());
+
+  this->blob_bottom_vec_.clear();
+  this->blob_bottom_vec_.push_back( &probMap);
+
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(0,0,2,6))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(1,0,0,0))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(2,0,7,8))] = 1;
+
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill output blob with 42
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  const TypeParam* data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(0,5)", toString( data, 2));
+  EXPECT_EQ( "(-2,-1)", toString( data+1*5*3*2, 2));
+  EXPECT_EQ( "(5,7)", toString( data+2*1*5*3*2, 2));
+
+  // other positions
+  caffe_set( probMap.count(), TypeParam(0), probMap.mutable_cpu_data());
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(0,0,5,3))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(1,0,2,1))] = 1;
+  probMap.mutable_cpu_data()[ probMap.offset( make_vec(2,0,0,0))] = 1;
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(3,2)", toString( data, 2));
+  EXPECT_EQ( "(0,0)", toString( data+1*5*3*2, 2));
+  EXPECT_EQ( "(-2,-1)", toString( data+2*1*5*3*2, 2));
+}
+
+TYPED_TEST(CreateDeformationLayerTest, TestIgnoreLabelSampling) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  create_deformation_param->set_nz(1);
+  create_deformation_param->set_ny(5);
+  create_deformation_param->set_nx(3);
+  create_deformation_param->set_ncomponents(3);
+  create_deformation_param->set_random_offset_range_from_ignore_label(7);
+
+  Blob<TypeParam> labelMap( make_vec( 3,1,7,8,9));
+  caffe_set( labelMap.count(), TypeParam(7), labelMap.mutable_cpu_data());
+
+  this->blob_bottom_vec_.clear();
+  this->blob_bottom_vec_.push_back( &labelMap);
+
+  labelMap.mutable_cpu_data()[ labelMap.offset( make_vec(0,0,3,2,6))] = 2;
+  labelMap.mutable_cpu_data()[ labelMap.offset( make_vec(1,0,0,0,0))] = 3;
+  labelMap.mutable_cpu_data()[ labelMap.offset( make_vec(2,0,6,7,8))] = 4;
+
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill output blob with 42
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  const TypeParam* data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(3,0,5)", toString( data, 3));
+  EXPECT_EQ( "(0,-2,-1)", toString( data+1*5*3*3, 3));
+  EXPECT_EQ( "(6,5,7)", toString( data+2*1*5*3*3, 3));
+
+  // other positions
+  caffe_set( labelMap.count(), TypeParam(7), labelMap.mutable_cpu_data());
+  labelMap.mutable_cpu_data()[ labelMap.offset( make_vec(0,0,2,5,3))] = 1;
+  labelMap.mutable_cpu_data()[ labelMap.offset( make_vec(1,0,3,2,1))] = 6;
+  labelMap.mutable_cpu_data()[ labelMap.offset( make_vec(2,0,0,0,0))] = 5;
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  data = this->blob_top_vec_[0]->cpu_data();
+  EXPECT_EQ( "(2,3,2)", toString( data, 3));
+  EXPECT_EQ( "(3,0,0)", toString( data+1*5*3*3, 3));
+  EXPECT_EQ( "(0,-2,-1)", toString( data+2*1*5*3*3, 3));
+}
+
+TYPED_TEST(CreateDeformationLayerTest, TestSamplingInBlobShape) {
+  Caffe::set_mode(Caffe::CPU);
+  LayerParameter param;
+  CreateDeformationParameter* create_deformation_param = param.mutable_create_deformation_param();
+
+  int out_nz = 5;
+  int out_ny = 7;
+  int out_nx = 3;
+  int out_ncomp = 3;
+
+  create_deformation_param->set_nz(out_nz);
+  create_deformation_param->set_ny(out_ny);
+  create_deformation_param->set_nx(out_nx);
+  create_deformation_param->set_ncomponents(out_ncomp);
+  create_deformation_param->set_random_offset_range_from_in_blob_shape(true);
+
+  int in_nz = 7;
+  int in_ny = 8;
+  int in_nx = 9;
+  Blob<TypeParam> inBlob( make_vec( 3, 1, in_nz, in_ny, in_nx));
+  this->blob_bottom_vec_.clear();
+  this->blob_bottom_vec_.push_back( &inBlob);
+
+  this->blob_top_vec_.resize(1);
+  CreateDeformationLayer<TypeParam> layer(param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // fill output blob with 42
+  caffe_set(this->blob_top_vec_[0]->count(), TypeParam(42),
+            this->blob_top_vec_[0]->mutable_cpu_data());
+
+  // check for several iterations, if the central pixel of the output
+  // blob is always within the input blob
+  const TypeParam* centralOutPixel = this->blob_top_vec_[0]->cpu_data()
+      + ( ( ( (out_nz-1)/2 * out_ny)
+            + (out_ny-1)/2) * out_nx
+          + (out_nx-1)/2) * out_ncomp;
+  for(int iter = 0; iter < 1000; ++iter) {
+    layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+    //   std::cout << "pos: " << toString( centralOutPixel, 3) << std::endl;
+    EXPECT_GE( centralOutPixel[0], 0);
+    EXPECT_LT( centralOutPixel[0], in_nz);
+    EXPECT_GE( centralOutPixel[1], 0);
+    EXPECT_LT( centralOutPixel[1], in_ny);
+    EXPECT_GE( centralOutPixel[2], 0);
+    EXPECT_LT( centralOutPixel[2], in_nx);
+  }
+}
+
+
+
+
+}  // namespace caffe
diff --git a/src/caffe/test/test_deconvolution_layer.cpp b/src/caffe/test/test_deconvolution_layer.cpp
index c4b09ad..37b4884 100644
--- a/src/caffe/test/test_deconvolution_layer.cpp
+++ b/src/caffe/test/test_deconvolution_layer.cpp
@@ -6,6 +6,7 @@
 #include "caffe/common.hpp"
 #include "caffe/filler.hpp"
 #include "caffe/layers/deconv_layer.hpp"
+#include "caffe/layers/cudnn_deconv_layer.hpp"
 
 #include "caffe/test/test_caffe_main.hpp"
 #include "caffe/test/test_gradient_check_util.hpp"
@@ -292,7 +293,7 @@ TYPED_TEST(DeconvolutionLayerTest, TestGradient3D) {
   convolution_param->add_kernel_size(2);
   convolution_param->add_stride(2);
   convolution_param->add_pad(1);
-  convolution_param->set_num_output(2);
+  convolution_param->set_num_output(1);
   convolution_param->mutable_weight_filler()->set_type("gaussian");
   convolution_param->mutable_bias_filler()->set_type("gaussian");
   DeconvolutionLayer<Dtype> layer(layer_param);
@@ -301,4 +302,289 @@ TYPED_TEST(DeconvolutionLayerTest, TestGradient3D) {
       this->blob_top_vec_);
 }
 
+#ifdef USE_CUDNN
+
+template <typename Dtype>
+class CuDNNDeconvolutionLayerTest : public GPUDeviceTest<Dtype> {
+ protected:
+  CuDNNDeconvolutionLayerTest()
+      : blob_bottom_(new Blob<Dtype>(2, 3, 2, 4)),
+        blob_bottom_2_(new Blob<Dtype>(2, 3, 2, 4)),
+        blob_top_(new Blob<Dtype>()),
+        blob_top_2_(new Blob<Dtype>()) {}
+  virtual void SetUp() {
+    // fill the values
+    FillerParameter filler_param;
+    filler_param.set_value(1.);
+    GaussianFiller<Dtype> filler(filler_param);
+    filler.Fill(this->blob_bottom_);
+    filler.Fill(this->blob_bottom_2_);
+    blob_bottom_vec_.push_back(blob_bottom_);
+    blob_top_vec_.push_back(blob_top_);
+  }
+
+  virtual ~CuDNNDeconvolutionLayerTest() {
+    delete blob_bottom_;
+    delete blob_bottom_2_;
+    delete blob_top_;
+    delete blob_top_2_;
+  }
+
+  virtual Blob<Dtype>* MakeReferenceTop(Blob<Dtype>* top) {
+    this->ref_blob_top_.reset(new Blob<Dtype>());
+    this->ref_blob_top_->ReshapeLike(*top);
+    return this->ref_blob_top_.get();
+  }
+
+  Blob<Dtype>* const blob_bottom_;
+  Blob<Dtype>* const blob_bottom_2_;
+  Blob<Dtype>* const blob_top_;
+  Blob<Dtype>* const blob_top_2_;
+  shared_ptr<Blob<Dtype> > ref_blob_top_;
+  vector<Blob<Dtype>*> blob_bottom_vec_;
+  vector<Blob<Dtype>*> blob_top_vec_;
+};
+
+TYPED_TEST_CASE(CuDNNDeconvolutionLayerTest, TestDtypes);
+
+template <typename Dtype>
+class CuDNNDeconvolutionLayerTest3D : public GPUDeviceTest<Dtype> {
+ protected:
+  CuDNNDeconvolutionLayerTest3D()
+      : blob_bottom_(new Blob<Dtype>(2,3,2,4)),
+        blob_bottom_2_(new Blob<Dtype>(2,3,2,4)),
+        blob_top_(new Blob<Dtype>()),
+        blob_top_2_(new Blob<Dtype>()) {}
+  virtual void SetUp() {
+    // create the blobs
+    vector<int> blob_shape;
+    //blob_shape.push_back(5);
+    blob_shape.push_back(2);
+    blob_shape.push_back(3);
+    blob_shape.push_back(2);
+    blob_shape.push_back(4);
+    blob_shape.push_back(3);
+    blob_bottom_->Reshape(blob_shape);
+    blob_bottom_2_->Reshape(blob_shape);
+    // fill the values
+    FillerParameter filler_param;
+    filler_param.set_value(1.);
+    GaussianFiller<Dtype> filler(filler_param);
+    filler.Fill(this->blob_bottom_);
+    filler.Fill(this->blob_bottom_2_);
+    blob_bottom_vec_.push_back(blob_bottom_);
+    blob_top_vec_.push_back(blob_top_);
+  }
+
+  virtual ~CuDNNDeconvolutionLayerTest3D() {
+    delete blob_bottom_;
+    delete blob_bottom_2_;
+    delete blob_top_;
+    delete blob_top_2_;
+  }
+
+  virtual Blob<Dtype>* MakeReferenceTop(Blob<Dtype>* top) {
+    this->ref_blob_top_.reset(new Blob<Dtype>());
+    this->ref_blob_top_->ReshapeLike(*top);
+    return this->ref_blob_top_.get();
+  }
+
+  Blob<Dtype>* const blob_bottom_;
+  Blob<Dtype>* const blob_bottom_2_;
+  Blob<Dtype>* const blob_top_;
+  Blob<Dtype>* const blob_top_2_;
+  shared_ptr<Blob<Dtype> > ref_blob_top_;
+  vector<Blob<Dtype>*> blob_bottom_vec_;
+  vector<Blob<Dtype>*> blob_top_vec_;
+};
+
+TYPED_TEST_CASE(CuDNNDeconvolutionLayerTest3D, TestDtypes);
+
+TYPED_TEST(CuDNNDeconvolutionLayerTest, TestSetupCuDNN) {
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(2);
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNDeconvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_->num(), 2);
+  EXPECT_EQ(this->blob_top_->channels(), 2);
+  EXPECT_EQ(this->blob_top_->height(), 5);
+  EXPECT_EQ(this->blob_top_->width(), 9);
+  EXPECT_EQ(this->blob_top_2_->num(), 2);
+  EXPECT_EQ(this->blob_top_2_->channels(), 2);
+  EXPECT_EQ(this->blob_top_2_->height(), 5);
+  EXPECT_EQ(this->blob_top_2_->width(), 9);
+  // setting group should not change the shape
+  convolution_param->set_num_output(3);
+  convolution_param->set_group(3);
+  layer.reset(new CuDNNDeconvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_->num(), 2);
+  EXPECT_EQ(this->blob_top_->channels(), 3);
+  EXPECT_EQ(this->blob_top_->height(), 5);
+  EXPECT_EQ(this->blob_top_->width(), 9);
+  EXPECT_EQ(this->blob_top_2_->num(), 2);
+  EXPECT_EQ(this->blob_top_2_->channels(), 3);
+  EXPECT_EQ(this->blob_top_2_->height(), 5);
+  EXPECT_EQ(this->blob_top_2_->width(), 9);
+}
+
+TYPED_TEST(CuDNNDeconvolutionLayerTest3D, TestSetup3DCuDNN) {
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(2);
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNDeconvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_->shape(1), 2);
+  EXPECT_EQ(this->blob_top_->shape(2), 5);
+  EXPECT_EQ(this->blob_top_->shape(3), 9);
+  EXPECT_EQ(this->blob_top_->shape(4), 7);
+  EXPECT_EQ(this->blob_top_2_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(1), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(2), 5);
+  EXPECT_EQ(this->blob_top_2_->shape(3), 9);
+  EXPECT_EQ(this->blob_top_2_->shape(4), 7);
+
+  // setting group should not change the shape
+  convolution_param->set_num_output(3);
+  convolution_param->set_group(3);
+  layer.reset(new CuDNNDeconvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  EXPECT_EQ(this->blob_top_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_->shape(1), 3);
+  EXPECT_EQ(this->blob_top_->shape(2), 5);
+  EXPECT_EQ(this->blob_top_->shape(3), 9);
+  EXPECT_EQ(this->blob_top_->shape(4), 7);
+  EXPECT_EQ(this->blob_top_2_->shape(0), 2);
+  EXPECT_EQ(this->blob_top_2_->shape(1), 3);
+  EXPECT_EQ(this->blob_top_2_->shape(2), 5);
+  EXPECT_EQ(this->blob_top_2_->shape(3), 9);
+  EXPECT_EQ(this->blob_top_2_->shape(4), 7);
+}
+
+TYPED_TEST(CuDNNDeconvolutionLayerTest, TestSimpleDeconvolutionCuDNN) {
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(4);
+  convolution_param->mutable_weight_filler()->set_type("constant");
+  convolution_param->mutable_weight_filler()->set_value(1.);
+  convolution_param->mutable_bias_filler()->set_type("constant");
+  convolution_param->mutable_bias_filler()->set_value(0.1);
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNDeconvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  // constant-fill the bottom blobs
+  FillerParameter filler_param;
+  filler_param.set_value(1.);
+  ConstantFiller<TypeParam> filler(filler_param);
+  filler.Fill(this->blob_bottom_);
+  filler.Fill(this->blob_bottom_2_);
+  layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+
+
+  // simply check that accumulation works with overlapping filters
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+  for (int n = 0; n < this->blob_top_->num(); ++n) {
+    for (int c = 0; c < this->blob_top_->channels(); ++c) {
+      for (int h = 0; h < this->blob_top_->height(); ++h) {
+        for (int w = 0; w < this->blob_top_->width(); ++w) {
+          TypeParam expected = 3.1;
+          bool h_overlap = h % 2 == 0 && h > 0
+            && h < this->blob_top_->height() - 1;
+          bool w_overlap = w % 2 == 0 && w > 0
+            && w < this->blob_top_->width() - 1;
+          if (h_overlap && w_overlap) {
+            expected += 9;
+          } else if (h_overlap || w_overlap) {
+            expected += 3;
+          }
+          EXPECT_NEAR(top_data[this->blob_top_->offset(n, c, h, w)],
+              expected, 1e-4);
+        }
+      }
+    }
+  }
+}
+
+TYPED_TEST(CuDNNDeconvolutionLayerTest3D, TestSimpleDeconvolution3DCuDNN) {
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  convolution_param->add_kernel_size(3);
+  convolution_param->add_stride(2);
+  convolution_param->set_num_output(4);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("gaussian");
+  shared_ptr<Layer<TypeParam> > layer(
+      new CuDNNDeconvolutionLayer<TypeParam>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer->Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+
+//TODO: ....
+
+}
+
+TYPED_TEST(CuDNNDeconvolutionLayerTest, TestGradientCuDNN) {
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  convolution_param->add_kernel_size(2);
+  convolution_param->add_stride(1);
+  convolution_param->add_pad(0);
+  convolution_param->set_num_output(2);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("gaussian");
+  CuDNNDeconvolutionLayer<TypeParam> layer(layer_param);
+  GradientChecker<TypeParam> checker(1e-2, 1e-3);
+  checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
+      this->blob_top_vec_);
+}
+
+TYPED_TEST(CuDNNDeconvolutionLayerTest3D, TestGradient3DCuDNN) {
+  LayerParameter layer_param;
+  ConvolutionParameter* convolution_param =
+      layer_param.mutable_convolution_param();
+  this->blob_bottom_vec_.push_back(this->blob_bottom_2_);
+  this->blob_top_vec_.push_back(this->blob_top_2_);
+  convolution_param->add_kernel_size(2);
+  convolution_param->add_stride(1);
+  convolution_param->add_pad(1);
+  convolution_param->set_num_output(1);
+  convolution_param->mutable_weight_filler()->set_type("gaussian");
+  convolution_param->mutable_bias_filler()->set_type("gaussian");
+  CuDNNDeconvolutionLayer<TypeParam> layer(layer_param);
+  GradientChecker<TypeParam> checker(1e-2, 1e-3);
+  checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_,
+      this->blob_top_vec_);
+}
+
+#endif
+
 }  // namespace caffe
diff --git a/src/caffe/test/test_hdf5data_layer.cpp b/src/caffe/test/test_hdf5data_layer.cpp
index 8884ce9..5a8316e 100644
--- a/src/caffe/test/test_hdf5data_layer.cpp
+++ b/src/caffe/test/test_hdf5data_layer.cpp
@@ -9,7 +9,8 @@
 #include "caffe/common.hpp"
 #include "caffe/layers/hdf5_data_layer.hpp"
 #include "caffe/proto/caffe.pb.h"
-
+#include "caffe/util/vector_helper.hpp"
+#include "caffe/util/hdf5.hpp"
 #include "caffe/test/test_caffe_main.hpp"
 
 namespace caffe {
@@ -133,4 +134,18 @@ TYPED_TEST(HDF5DataLayerTest, TestRead) {
   }
 }
 
+TYPED_TEST(HDF5DataLayerTest, Test_hdf5_get_dataset_shape) {
+  std::string filename = std::string(
+      CMAKE_SOURCE_DIR "caffe/test/test_data/sample_data.h5" CMAKE_EXT);
+  hid_t file_id = H5Fopen(filename.c_str(), H5F_ACC_RDONLY, H5P_DEFAULT);
+  EXPECT_NE( file_id, 0) << "file not found " << filename;
+  std::vector<hsize_t> shape;
+  shape = hdf5_get_dataset_shape(file_id, "data");
+  EXPECT_EQ( "(10,8,6,5)" , toString(shape));
+  shape = hdf5_get_dataset_shape(file_id, "label");
+  EXPECT_EQ( "(10,1)" , toString(shape));
+  herr_t status = H5Fclose(file_id);
+  CHECK_GE(status, 0) << "Failed to close HDF5 file: " << filename;
+
+}
 }  // namespace caffe
diff --git a/src/caffe/test/test_maxpool_dropout_layers.cpp b/src/caffe/test/test_maxpool_dropout_layers.cpp
index 4f0e20a..2f163ce 100644
--- a/src/caffe/test/test_maxpool_dropout_layers.cpp
+++ b/src/caffe/test/test_maxpool_dropout_layers.cpp
@@ -44,8 +44,10 @@ TYPED_TEST(MaxPoolingDropoutTest, TestSetup) {
   typedef typename TypeParam::Dtype Dtype;
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   PoolingLayer<Dtype> max_layer(layer_param);
   max_layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
   DropoutLayer<Dtype> dropout_layer(layer_param);
@@ -61,8 +63,10 @@ TYPED_TEST(MaxPoolingDropoutTest, TestForward) {
   typedef typename TypeParam::Dtype Dtype;
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   PoolingLayer<Dtype> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
   layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
@@ -91,8 +95,10 @@ TYPED_TEST(MaxPoolingDropoutTest, TestBackward) {
   LayerParameter layer_param;
   layer_param.set_phase(TRAIN);
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   PoolingLayer<Dtype> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
   layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
diff --git a/src/caffe/test/test_net.cpp b/src/caffe/test/test_net.cpp
index 92fd317..3697a76 100644
--- a/src/caffe/test/test_net.cpp
+++ b/src/caffe/test/test_net.cpp
@@ -617,6 +617,36 @@ class NetTest : public MultiDeviceTest<TypeParam> {
     InitNetFromProtoString(proto);
   }
 
+  virtual void InitReshapableNet2() {
+    const string& proto =
+        "name: 'ReshapableNetwork' "
+        "layer {"
+        "name: 'data'"
+        "type: 'Input'"
+        "top: 'data'"
+        "input_param {"
+        "        shape {"
+        "        dim: 1"
+        "        dim: 3"
+        "        dim: 100"
+        "        dim: 100"
+        "        }"
+        "    }"
+        "}"
+        "layer { "
+        "  name: 'pool1' "
+        "  type: 'Pooling' "
+        "  bottom: 'data' "
+        "  top: 'pool1' "
+        "  pooling_param { "
+        "    pool: MAX "
+        "    kernel_size: 2 "
+        "    stride: 2 "
+        "  } "
+        "} ";
+    InitNetFromProtoString(proto);
+  }
+
   virtual void InitSkipPropNet(bool test_skip_true) {
     string proto =
       "name: 'SkipPropTestNetwork' "
@@ -2378,6 +2408,78 @@ TYPED_TEST(NetTest, TestReshape) {
   EXPECT_FALSE(same_spatial_shape);
 }
 
+TYPED_TEST(NetTest, TestReshape2) {
+  typedef typename TypeParam::Dtype Dtype;
+  // We set up bottom blobs of two different sizes, switch between
+  // them, check that forward and backward both run and the results
+  // are the same, and check that the output shapes change.
+  Caffe::set_random_seed(this->seed_);
+  Caffe::set_mode(Caffe::CPU);
+  FillerParameter filler_param;
+  filler_param.set_std(1);
+  GaussianFiller<Dtype> filler(filler_param);
+  // Check smaller shape first as larger first could hide realloc failures.
+  Blob<Dtype> blob1(2, 3, 12, 10);
+  Blob<Dtype> blob2(4, 3, 9, 11);
+  ASSERT_LT(blob1.count(), blob2.count());
+  filler.Fill(&blob1);
+  filler.Fill(&blob2);
+
+  this->InitReshapableNet2();
+  Blob<Dtype>* input_blob = this->net_->input_blobs()[0];
+  Blob<Dtype>* output_blob = this->net_->output_blobs()[0];
+  input_blob->Reshape(blob1.num(), blob1.channels(), blob1.height(),
+      blob1.width());
+  caffe_copy(blob1.count(), blob1.cpu_data(), input_blob->mutable_cpu_data());
+  this->net_->ForwardPrefilled();
+  // call backward just to make sure it runs
+  this->net_->Backward();
+  Blob<Dtype> output1(output_blob->num(), output_blob->channels(),
+      output_blob->height(), output_blob->width());
+  caffe_copy(output1.count(), output_blob->cpu_data(),
+      output1.mutable_cpu_data());
+
+  input_blob->Reshape(blob2.num(), blob2.channels(), blob2.height(),
+      blob2.width());
+  caffe_copy(blob2.count(), blob2.cpu_data(), input_blob->mutable_cpu_data());
+  this->net_->ForwardPrefilled();
+  this->net_->Backward();
+  Blob<Dtype> output2(output_blob->num(), output_blob->channels(),
+      output_blob->height(), output_blob->width());
+  caffe_copy(output2.count(), output_blob->cpu_data(),
+      output2.mutable_cpu_data());
+
+  input_blob->Reshape(blob1.num(), blob1.channels(), blob1.height(),
+      blob1.width());
+  caffe_copy(blob1.count(), blob1.cpu_data(), input_blob->mutable_cpu_data());
+  this->net_->ForwardPrefilled();
+  this->net_->Backward();
+  for (int i = 0; i < output1.count(); ++i) {
+    EXPECT_FLOAT_EQ(*(output1.cpu_data() + i), *(output_blob->cpu_data() + i));
+  }
+
+  input_blob->Reshape(blob2.num(), blob2.channels(), blob2.height(),
+      blob2.width());
+  caffe_copy(blob2.count(), blob2.cpu_data(), input_blob->mutable_cpu_data());
+  this->net_->ForwardPrefilled();
+  this->net_->Backward();
+  for (int i = 0; i < output2.count(); ++i) {
+    EXPECT_FLOAT_EQ(*(output2.cpu_data() + i), *(output_blob->cpu_data() + i));
+  }
+
+  EXPECT_EQ(output1.num(), blob1.num());
+  EXPECT_EQ(output2.num(), blob2.num());
+  bool same_spatial_shape = true;
+  const int kFirstSpatialAxis = 2;
+  for (int i = kFirstSpatialAxis; i < output1.num_axes(); ++i) {
+    if (output1.shape(i) != output2.shape(i)) {
+      same_spatial_shape = false;
+      break;
+    }
+  }
+  EXPECT_FALSE(same_spatial_shape);
+}
+
 TYPED_TEST(NetTest, TestSkipPropagateDown) {
   // check bottom_need_backward if propagate_down is true
   this->InitSkipPropNet(false);
diff --git a/src/caffe/test/test_neuron_layer.cpp b/src/caffe/test/test_neuron_layer.cpp
index 342f825..0d7af3d 100644
--- a/src/caffe/test/test_neuron_layer.cpp
+++ b/src/caffe/test/test_neuron_layer.cpp
@@ -851,6 +851,61 @@ TYPED_TEST(CuDNNNeuronLayerTest, TestReLUGradientCuDNN) {
       this->blob_top_vec_);
 }
 
+template <typename Dtype>
+class CuDNN3DNeuronLayerTest : public GPUDeviceTest<Dtype> {
+ protected:
+  CuDNN3DNeuronLayerTest()
+      : blob_bottom_(new Blob<Dtype>()),
+        blob_top_(new Blob<Dtype>()) {
+      vector<int> blob_size;
+      blob_size.push_back(6);
+      blob_size.push_back(5);
+      blob_size.push_back(4);
+      blob_size.push_back(3);
+      blob_size.push_back(2);
+      blob_bottom_->Reshape(blob_size);
+      Caffe::set_random_seed(1701);
+      // fill the values
+      FillerParameter filler_param;
+      GaussianFiller<Dtype> filler(filler_param);
+      filler.Fill(this->blob_bottom_);
+      blob_bottom_vec_.push_back(blob_bottom_);
+      blob_top_vec_.push_back(blob_top_);
+  }
+  virtual ~CuDNN3DNeuronLayerTest() { delete blob_bottom_; delete blob_top_; }
+  Blob<Dtype>* const blob_bottom_;
+  Blob<Dtype>* const blob_top_;
+  vector<Blob<Dtype>*> blob_bottom_vec_;
+  vector<Blob<Dtype>*> blob_top_vec_;
+};
+
+TYPED_TEST_CASE(CuDNN3DNeuronLayerTest, TestDtypes);
+
+TYPED_TEST(CuDNN3DNeuronLayerTest, TestReLU3DCuDNN) {
+  LayerParameter layer_param;
+  CuDNNReLULayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Now, check values
+  const TypeParam* bottom_data = this->blob_bottom_->cpu_data();
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
+    if ( bottom_data[i] <= 0. ) {
+        EXPECT_EQ(top_data[i],0.);
+    } else {
+        EXPECT_EQ(top_data[i], bottom_data[i]);
+    }
+  }
+}
+
+TYPED_TEST(CuDNN3DNeuronLayerTest, TestReLUGradient3DCuDNN) {
+  LayerParameter layer_param;
+  CuDNNReLULayer<TypeParam> layer(layer_param);
+  GradientChecker<TypeParam> checker(1e-2, 1e-3, 1701, 0., 0.01);
+  checker.CheckGradientEltwise(&layer, this->blob_bottom_vec_,
+                               this->blob_top_vec_);
+}
+
 TYPED_TEST(CuDNNNeuronLayerTest, TestReLUWithNegativeSlopeCuDNN) {
   LayerParameter layer_param;
   CHECK(google::protobuf::TextFormat::ParseFromString(
@@ -880,6 +935,35 @@ TYPED_TEST(CuDNNNeuronLayerTest, TestReLUGradientWithNegativeSlopeCuDNN) {
       this->blob_top_vec_);
 }
 
+TYPED_TEST(CuDNN3DNeuronLayerTest, TestReLUWithNegativeSlope3DCuDNN) {
+  LayerParameter layer_param;
+  CHECK(google::protobuf::TextFormat::ParseFromString(
+      "relu_param { negative_slope: 0.01 }", &layer_param));
+  CuDNNReLULayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Now, check values
+  const TypeParam* bottom_data = this->blob_bottom_->cpu_data();
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
+    if (top_data[i] >= 0) {
+      EXPECT_FLOAT_EQ(top_data[i], bottom_data[i]);
+    } else {
+      EXPECT_FLOAT_EQ(top_data[i], bottom_data[i] * 0.01);
+    }
+  }
+}
+
+TYPED_TEST(CuDNN3DNeuronLayerTest, TestReLUGradientWithNegativeSlope3DCuDNN) {
+  LayerParameter layer_param;
+  CHECK(google::protobuf::TextFormat::ParseFromString(
+      "relu_param { negative_slope: 0.01 }", &layer_param));
+  CuDNNReLULayer<TypeParam> layer(layer_param);
+  GradientChecker<TypeParam> checker(1e-2, 1e-3, 1701, 0., 0.01);
+  checker.CheckGradientEltwise(&layer, this->blob_bottom_vec_,
+      this->blob_top_vec_);
+}
+
 TYPED_TEST(CuDNNNeuronLayerTest, TestSigmoidCuDNN) {
   LayerParameter layer_param;
   CuDNNSigmoidLayer<TypeParam> layer(layer_param);
diff --git a/src/caffe/test/test_pooling_layer.cpp b/src/caffe/test/test_pooling_layer.cpp
index bb95cae..1ddfa16 100644
--- a/src/caffe/test/test_pooling_layer.cpp
+++ b/src/caffe/test/test_pooling_layer.cpp
@@ -49,7 +49,8 @@ class PoolingLayerTest : public MultiDeviceTest<TypeParam> {
   void TestForwardSquare() {
     LayerParameter layer_param;
     PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-    pooling_param->set_kernel_size(2);
+    pooling_param->clear_kernel_size();
+    pooling_param->add_kernel_size(2);
     pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
     const int num = 2;
     const int channels = 2;
@@ -377,8 +378,10 @@ TYPED_TEST(PoolingLayerTest, TestSetup) {
   typedef typename TypeParam::Dtype Dtype;
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->clear_stride();
+  pooling_param->add_kernel_size(3);
+  pooling_param->add_stride(2);
   PoolingLayer<Dtype> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
   EXPECT_EQ(this->blob_top_->num(), this->blob_bottom_->num());
@@ -391,9 +394,12 @@ TYPED_TEST(PoolingLayerTest, TestSetupPadded) {
   typedef typename TypeParam::Dtype Dtype;
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
-  pooling_param->set_pad(1);
+  pooling_param->clear_kernel_size();
+  pooling_param->clear_stride();
+  pooling_param->clear_pad();
+  pooling_param->add_kernel_size(3);
+  pooling_param->add_stride(2);
+  pooling_param->add_pad(1);
   pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
   PoolingLayer<Dtype> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
@@ -464,8 +470,10 @@ TYPED_TEST(PoolingLayerTest, TestGradientMax) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
-      pooling_param->set_pad(1);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
+      pooling_param->clear_pad();
+      pooling_param->add_pad(1);
       pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
       PoolingLayer<Dtype> layer(layer_param);
       GradientChecker<Dtype> checker(1e-4, 1e-2);
@@ -479,9 +487,12 @@ TYPED_TEST(PoolingLayerTest, TestForwardMaxPadded) {
   typedef typename TypeParam::Dtype Dtype;
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
-  pooling_param->set_pad(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->clear_stride();
+  pooling_param->clear_pad();
+  pooling_param->add_kernel_size(3);
+  pooling_param->add_stride(2);
+  pooling_param->add_pad(2);
   pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
   this->blob_bottom_->Reshape(1, 1, 3, 3);
   // Input:
@@ -528,7 +539,8 @@ TYPED_TEST(PoolingLayerTest, TestGradientMaxTopMask) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
       pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
       this->blob_top_vec_.push_back(this->blob_top_mask_);
       PoolingLayer<Dtype> layer(layer_param);
@@ -544,9 +556,12 @@ TYPED_TEST(PoolingLayerTest, TestForwardAve) {
   typedef typename TypeParam::Dtype Dtype;
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(1);
-  pooling_param->set_pad(1);
+  pooling_param->clear_kernel_size();
+  pooling_param->clear_stride();
+  pooling_param->clear_pad();
+  pooling_param->add_kernel_size(3);
+  pooling_param->add_stride(1);
+  pooling_param->add_pad(1);
   pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
   this->blob_bottom_->Reshape(1, 1, 3, 3);
   FillerParameter filler_param;
@@ -580,7 +595,8 @@ TYPED_TEST(PoolingLayerTest, TestGradientAve) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
       pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
       PoolingLayer<Dtype> layer(layer_param);
       GradientChecker<Dtype> checker(1e-2, 1e-2);
@@ -598,8 +614,10 @@ TYPED_TEST(PoolingLayerTest, TestGradientAvePadded) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
-      pooling_param->set_pad(2);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
+      pooling_param->clear_pad();
+      pooling_param->add_pad(2);
       pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
       PoolingLayer<Dtype> layer(layer_param);
       GradientChecker<Dtype> checker(1e-2, 1e-2);
@@ -641,7 +659,8 @@ class CuDNNPoolingLayerTest : public GPUDeviceTest<Dtype> {
   void TestForwardSquare() {
     LayerParameter layer_param;
     PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-    pooling_param->set_kernel_size(2);
+    pooling_param->clear_kernel_size();
+    pooling_param->add_kernel_size(2);
     pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
     const int num = 2;
     const int channels = 2;
@@ -968,8 +987,10 @@ TYPED_TEST_CASE(CuDNNPoolingLayerTest, TestDtypes);
 TYPED_TEST(CuDNNPoolingLayerTest, TestSetupCuDNN) {
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   CuDNNPoolingLayer<TypeParam> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
   EXPECT_EQ(this->blob_top_->num(), this->blob_bottom_->num());
@@ -981,9 +1002,12 @@ TYPED_TEST(CuDNNPoolingLayerTest, TestSetupCuDNN) {
 TYPED_TEST(CuDNNPoolingLayerTest, TestSetupPaddedCuDNN) {
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
-  pooling_param->set_pad(1);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
+  pooling_param->clear_pad();
+  pooling_param->add_pad(1);
   pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
   CuDNNPoolingLayer<TypeParam> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
@@ -1043,9 +1067,11 @@ TYPED_TEST(CuDNNPoolingLayerTest, TestGradientMaxCuDNN) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
       // currenty, cuDNN pooling does not support padding
-      pooling_param->set_pad(0);
+      pooling_param->clear_pad();
+      pooling_param->add_pad(0);
       pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
       CuDNNPoolingLayer<TypeParam> layer(layer_param);
       GradientChecker<TypeParam> checker(1e-4, 1e-2);
@@ -1058,9 +1084,12 @@ TYPED_TEST(CuDNNPoolingLayerTest, TestGradientMaxCuDNN) {
 TYPED_TEST(CuDNNPoolingLayerTest, TestForwardMaxPaddedCuDNN) {
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
-  pooling_param->set_pad(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
+  pooling_param->clear_pad();
+  pooling_param->add_pad(2);
   pooling_param->set_pool(PoolingParameter_PoolMethod_MAX);
   this->blob_bottom_->Reshape(1, 1, 3, 3);
   // Input:
@@ -1123,11 +1152,14 @@ TYPED_TEST(CuDNNPoolingLayerTest, TestGradientMaxTopMaskCuDNN) {
 TYPED_TEST(CuDNNPoolingLayerTest, TestForwardAveCuDNN) {
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(1);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(1);
   // Currently, cuDNN pooling does not support padding, so we use
   // a simplified version of this test.
-  pooling_param->set_pad(0);
+  pooling_param->clear_pad();
+  pooling_param->add_pad(0);
   pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
   this->blob_bottom_->Reshape(1, 1, 3, 3);
   FillerParameter filler_param;
@@ -1152,7 +1184,8 @@ TYPED_TEST(CuDNNPoolingLayerTest, TestGradientAveCuDNN) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
       pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
       CuDNNPoolingLayer<TypeParam> layer(layer_param);
       GradientChecker<TypeParam> checker(1e-2, 1e-2);
@@ -1169,8 +1202,10 @@ TYPED_TEST(CuDNNPoolingLayerTest, TestGradientAvePaddedCuDNN) {
       PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
       pooling_param->set_kernel_h(kernel_h);
       pooling_param->set_kernel_w(kernel_w);
-      pooling_param->set_stride(2);
-      pooling_param->set_pad(2);
+      pooling_param->clear_stride();
+      pooling_param->add_stride(2);
+      pooling_param->clear_pad();
+      pooling_param->add_pad(2);
       pooling_param->set_pool(PoolingParameter_PoolMethod_AVE);
       CuDNNPoolingLayer<TypeParam> layer(layer_param);
       GradientChecker<TypeParam> checker(1e-2, 1e-2);
diff --git a/src/caffe/test/test_softmax_with_loss_layer.cpp b/src/caffe/test/test_softmax_with_loss_layer.cpp
index c67f3e0..4951ee0 100644
--- a/src/caffe/test/test_softmax_with_loss_layer.cpp
+++ b/src/caffe/test/test_softmax_with_loss_layer.cpp
@@ -24,6 +24,7 @@ class SoftmaxWithLossLayerTest : public MultiDeviceTest<TypeParam> {
   SoftmaxWithLossLayerTest()
       : blob_bottom_data_(new Blob<Dtype>(10, 5, 2, 3)),
         blob_bottom_label_(new Blob<Dtype>(10, 1, 2, 3)),
+        blob_bottom_pixel_loss_weight_(new Blob<Dtype>(10, 1, 2, 3)),
         blob_top_loss_(new Blob<Dtype>()) {
     // fill the values
     FillerParameter filler_param;
@@ -36,6 +37,17 @@ class SoftmaxWithLossLayerTest : public MultiDeviceTest<TypeParam> {
     }
     blob_bottom_vec_.push_back(blob_bottom_label_);
     blob_top_vec_.push_back(blob_top_loss_);
+    // bottom Blobs for pixel wise loss weight
+    blob_bottom_vec_3_.push_back(blob_bottom_data_);
+    blob_bottom_vec_3_.push_back(blob_bottom_label_);
+    // fill weights with positive gaussian distributed random numbers
+    filler.Fill(this->blob_bottom_pixel_loss_weight_);
+    for (int i = 0; i < blob_bottom_pixel_loss_weight_->count(); ++i) {
+      blob_bottom_pixel_loss_weight_->mutable_cpu_data()[i] =
+          abs(blob_bottom_pixel_loss_weight_->cpu_data()[i]);
+    }
+    blob_bottom_vec_3_.push_back(blob_bottom_pixel_loss_weight_);
+
   }
   virtual ~SoftmaxWithLossLayerTest() {
     delete blob_bottom_data_;
@@ -44,8 +56,10 @@ class SoftmaxWithLossLayerTest : public MultiDeviceTest<TypeParam> {
   }
   Blob<Dtype>* const blob_bottom_data_;
   Blob<Dtype>* const blob_bottom_label_;
+  Blob<Dtype>* const blob_bottom_pixel_loss_weight_;
   Blob<Dtype>* const blob_top_loss_;
   vector<Blob<Dtype>*> blob_bottom_vec_;
+  vector<Blob<Dtype>*> blob_bottom_vec_3_;
   vector<Blob<Dtype>*> blob_top_vec_;
 };
 
@@ -105,4 +119,61 @@ TYPED_TEST(SoftmaxWithLossLayerTest, TestGradientUnnormalized) {
       this->blob_top_vec_, 0);
 }
 
+TYPED_TEST(SoftmaxWithLossLayerTest, TestForwardPixelWiseLossWeight) {
+  typedef typename TypeParam::Dtype Dtype;
+  LayerParameter layer_param;
+  layer_param.add_loss_weight(3);
+  SoftmaxWithLossLayer<Dtype> layer(layer_param);
+  GradientChecker<Dtype> checker(1e-2, 1e-2, 1701);
+  checker.CheckGradientExhaustive(&layer, this->blob_bottom_vec_3_,
+      this->blob_top_vec_, 0);
+}
+
+TYPED_TEST(SoftmaxWithLossLayerTest, TestForwardPixelWiseLossWeight2) {
+  // simulate ignore label test using PixelWiseLossWeight
+  typedef typename TypeParam::Dtype Dtype;
+  LayerParameter layer_param;
+  layer_param.mutable_loss_param()->set_normalize(false);
+  // First, compute the loss with all labels
+  scoped_ptr<SoftmaxWithLossLayer<Dtype> > layer(
+      new SoftmaxWithLossLayer<Dtype>(layer_param));
+  layer->SetUp(this->blob_bottom_vec_3_, this->blob_top_vec_);
+  layer->Forward(this->blob_bottom_vec_3_, this->blob_top_vec_);
+  Dtype full_loss = this->blob_top_loss_->cpu_data()[0];
+
+  Blob<Dtype> backup;
+  backup.CopyFrom( *(this->blob_bottom_pixel_loss_weight_), false, true);
+
+  // Now, accumulate the loss, ignoring each label in {0, ..., 4} in turn.
+  Dtype accum_loss = 0;
+  for (int label = 0; label < 5; ++label) {
+    this->blob_bottom_pixel_loss_weight_->CopyFrom( backup);
+    for (int i = 0; i < this->blob_bottom_pixel_loss_weight_->count(); ++i) {
+      if( this->blob_bottom_label_->cpu_data()[i] == label) {
+        this->blob_bottom_pixel_loss_weight_->mutable_cpu_data()[i] = 0;
+      }
+    }
+    layer->SetUp(this->blob_bottom_vec_3_, this->blob_top_vec_);
+    layer->Forward(this->blob_bottom_vec_3_, this->blob_top_vec_);
+    accum_loss += this->blob_top_loss_->cpu_data()[0];
+  }
+  // Check that each label was included all but once.
+  EXPECT_NEAR(4 * full_loss, accum_loss, 1e-3);
+}
+
+TYPED_TEST(SoftmaxWithLossLayerTest, TestForwardPixelWiseLossWeightZero) {
+  // fill weights all with zero and check if loss is zero
+  typedef typename TypeParam::Dtype Dtype;
+  LayerParameter layer_param;
+  layer_param.add_loss_weight(3);
+  SoftmaxWithLossLayer<Dtype> layer(layer_param);
+  for (int i = 0; i < this->blob_bottom_pixel_loss_weight_->count(); ++i) {
+    this->blob_bottom_pixel_loss_weight_->mutable_cpu_data()[i] = 0;
+  }
+  layer.SetUp(this->blob_bottom_vec_3_, this->blob_top_vec_);
+  layer.Forward(this->blob_bottom_vec_3_, this->blob_top_vec_);
+  EXPECT_NEAR(this->blob_top_loss_->cpu_data()[0], 0, 1e-10);
+}
+
+
 }  // namespace caffe
diff --git a/src/caffe/test/test_stochastic_pooling.cpp b/src/caffe/test/test_stochastic_pooling.cpp
index cd5db83..e270027 100644
--- a/src/caffe/test/test_stochastic_pooling.cpp
+++ b/src/caffe/test/test_stochastic_pooling.cpp
@@ -56,8 +56,10 @@ TYPED_TEST_CASE(CPUStochasticPoolingLayerTest, TestDtypes);
 TYPED_TEST(CPUStochasticPoolingLayerTest, TestSetup) {
   LayerParameter layer_param;
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   PoolingLayer<TypeParam> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
   EXPECT_EQ(this->blob_top_->num(), this->blob_bottom_->num());
@@ -79,8 +81,10 @@ TYPED_TEST(GPUStochasticPoolingLayerTest, TestStochastic) {
   LayerParameter layer_param;
   layer_param.set_phase(TRAIN);
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   pooling_param->set_pool(PoolingParameter_PoolMethod_STOCHASTIC);
   PoolingLayer<TypeParam> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
@@ -122,8 +126,10 @@ TYPED_TEST(GPUStochasticPoolingLayerTest, TestStochasticTestPhase) {
   LayerParameter layer_param;
   layer_param.set_phase(TEST);
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   pooling_param->set_pool(PoolingParameter_PoolMethod_STOCHASTIC);
   PoolingLayer<TypeParam> layer(layer_param);
   layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
@@ -159,8 +165,10 @@ TYPED_TEST(GPUStochasticPoolingLayerTest, TestGradient) {
   LayerParameter layer_param;
   layer_param.set_phase(TRAIN);
   PoolingParameter* pooling_param = layer_param.mutable_pooling_param();
-  pooling_param->set_kernel_size(3);
-  pooling_param->set_stride(2);
+  pooling_param->clear_kernel_size();
+  pooling_param->add_kernel_size(3);
+  pooling_param->clear_stride();
+  pooling_param->add_stride(2);
   pooling_param->set_pool(PoolingParameter_PoolMethod_STOCHASTIC);
   PoolingLayer<TypeParam> layer(layer_param);
   GradientChecker<TypeParam> checker(1e-4, 1e-2);
diff --git a/src/caffe/test/test_value_augmentation_layer.cpp b/src/caffe/test/test_value_augmentation_layer.cpp
new file mode 100644
index 0000000..41ef84e
--- /dev/null
+++ b/src/caffe/test/test_value_augmentation_layer.cpp
@@ -0,0 +1,215 @@
+#include <algorithm>
+#include <vector>
+
+#include "gtest/gtest.h"
+
+#include "caffe/blob.hpp"
+#include "caffe/layers/value_augmentation_layer.hpp"
+#include "caffe/filler.hpp"
+
+#include "caffe/test/test_caffe_main.hpp"
+#include "caffe/util/vector_helper.hpp"
+
+namespace caffe {
+
+
+template <typename TypeParam>
+class ValueAugmentationLayerTest : public ::testing::Test  {
+
+ protected:
+  ValueAugmentationLayerTest()
+    : blob_bottom_(new Blob<TypeParam>(2, 3, 4, 5)),
+      blob_top_(new Blob<TypeParam>()) {
+    Caffe::set_random_seed(1701);
+    FillerParameter filler_param;
+    blob_bottom_vec_.push_back(blob_bottom_);
+    blob_top_vec_.push_back(blob_top_);
+  }
+  virtual ~ValueAugmentationLayerTest() { delete blob_bottom_; delete blob_top_; }
+
+  Blob<TypeParam>* const blob_bottom_;
+  Blob<TypeParam>* const blob_top_;
+  vector<Blob<TypeParam>*> blob_bottom_vec_;
+  vector<Blob<TypeParam>*> blob_top_vec_;
+};
+
+TYPED_TEST_CASE(ValueAugmentationLayerTest, TestDtypes);
+
+TYPED_TEST(ValueAugmentationLayerTest, TestLinearInterpExtrapMatrix) {
+  LayerParameter layer_param;
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+
+  int n_in         = 5;
+  TypeParam dx_in  = 0.25;
+  int n_out        = 101;
+  TypeParam dx_out = 0.01;
+  int n_extrapol   = 50;
+
+  TypeParam* lin_mat = new TypeParam[n_in * (n_out + 2 * n_extrapol)];
+  layer.CreateLinearInterpExtrapMatrix(n_in, dx_in, n_out, dx_out,
+                                       n_extrapol, lin_mat);
+  std::vector<TypeParam> lut_cp(5);
+  for (int i = 0; i < lut_cp.size(); ++i) {
+    lut_cp[i] = 0.25 * i;
+  }
+
+  std::vector<TypeParam> lut(201);
+  caffe_cpu_gemv<TypeParam>( CblasNoTrans,
+                             201, 5,
+                             TypeParam(1), lin_mat, lut_cp.data(),
+                             TypeParam(0), lut.data());
+
+  for (int i = 0; i < lut.size(); ++i) {
+    EXPECT_NEAR( lut[i], 0.01 * (i - n_extrapol), 1e-6);
+  }
+}
+
+TYPED_TEST(ValueAugmentationLayerTest, TestRandomControlPoints) {
+  LayerParameter layer_param;
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+
+  std::vector<TypeParam> lut_cp = layer.random_lut_controlpoints( 0,0,
+                                                                  1,1,
+                                                                  1,1, 2);
+  EXPECT_EQ( 5, lut_cp.size());
+
+  for (int i = 0; i < lut_cp.size(); ++i) {
+    EXPECT_NEAR( lut_cp[i], 0.25 * i, 1e-6);
+  }
+
+  for (int iter = 0; iter < 10; ++iter) {
+    lut_cp = layer.random_lut_controlpoints( 0, 0, 1, 1, 0.5, 2, 2);
+    EXPECT_NEAR( lut_cp[0], 0, 1e-6);
+    EXPECT_NEAR( lut_cp[4], 1, 1e-6);
+
+    // test slopes
+    for (int i = 0; i < lut_cp.size() - 1; ++i) {
+      EXPECT_GE( (lut_cp[i+1] - lut_cp[i]) / 0.25, 0.5);
+      EXPECT_LE( (lut_cp[i+1] - lut_cp[i]) / 0.25, 2);
+    }
+  }
+}
+
+TYPED_TEST(ValueAugmentationLayerTest, TestInterpolationAndSmoothing) {
+  LayerParameter layer_param;
+  layer_param.mutable_value_augmentation_param()->set_lut_size(101);
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  std::vector<TypeParam> lut_cp(5);
+  for (int i = 0; i < lut_cp.size(); ++i) {
+    lut_cp[i] = 0.25 * i;
+  }
+
+  std::vector<TypeParam> lut = layer.dense_lut( lut_cp);
+
+  EXPECT_EQ( 101, lut.size());
+
+  for (int i = 0; i < lut.size(); ++i) {
+    EXPECT_NEAR( lut[i], 0.01 * i, 1e-6);
+  }
+}
+
+TYPED_TEST(ValueAugmentationLayerTest, TestIdentityMapping) {
+  FillerParameter filler_param;
+  filler_param.set_min(0);
+  filler_param.set_max(1);
+  UniformFiller<TypeParam> filler(filler_param);
+  filler.Fill(this->blob_bottom_);
+
+  LayerParameter layer_param;
+  layer_param.mutable_value_augmentation_param()->set_slope_min(1);
+  layer_param.mutable_value_augmentation_param()->set_slope_max(1);
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Now, check values
+  const TypeParam* bottom_data = this->blob_bottom_->cpu_data();
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
+    EXPECT_NEAR(top_data[i], bottom_data[i], 1e-6);
+  }
+}
+
+TYPED_TEST(ValueAugmentationLayerTest, TestScale) {
+  FillerParameter filler_param;
+  filler_param.set_min(0);
+  filler_param.set_max(1);
+  UniformFiller<TypeParam> filler(filler_param);
+  filler.Fill(this->blob_bottom_);
+
+  LayerParameter layer_param;
+  layer_param.mutable_value_augmentation_param()->set_white_from(2);
+  layer_param.mutable_value_augmentation_param()->set_white_to(2);
+  layer_param.mutable_value_augmentation_param()->set_slope_min(2);
+  layer_param.mutable_value_augmentation_param()->set_slope_max(2);
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Now, check values
+  const TypeParam* bottom_data = this->blob_bottom_->cpu_data();
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
+    EXPECT_NEAR(top_data[i], 2 * bottom_data[i], 1e-4);
+  }
+}
+
+#if 0
+TYPED_TEST(ValueAugmentationLayerTest, TestSCurve) {
+  FillerParameter filler_param;
+  filler_param.set_min(0);
+  filler_param.set_max(1);
+  UniformFiller<TypeParam> filler(filler_param);
+  filler.Fill(this->blob_bottom_);
+
+  LayerParameter layer_param;
+  layer_param.mutable_value_augmentation_param()->set_s_curve_contrast_max(10);
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  for (int i = 0; i < this->blob_top_->count(); ++i) {
+    this->blob_top_->mutable_cpu_data()[i] = 42;
+  }
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Now, check values
+  const TypeParam* bottom_data = this->blob_bottom_->cpu_data();
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+
+  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
+    EXPECT_GE( top_data[i], 0);
+    EXPECT_LE( top_data[i], 1);
+    EXPECT_NE( top_data[i], bottom_data[i]);
+  }
+}
+
+TYPED_TEST(ValueAugmentationLayerTest, TestGamma) {
+  FillerParameter filler_param;
+  filler_param.set_min(0);
+  filler_param.set_max(1);
+  UniformFiller<TypeParam> filler(filler_param);
+  filler.Fill(this->blob_bottom_);
+
+  LayerParameter layer_param;
+  layer_param.mutable_value_augmentation_param()->set_gamma_max(10);
+  ValueAugmentationLayer<TypeParam> layer(layer_param);
+  layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+
+  for (int i = 0; i < this->blob_top_->count(); ++i) {
+    this->blob_top_->mutable_cpu_data()[i] = 42;
+  }
+
+  layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+  // Now, check values
+  const TypeParam* bottom_data = this->blob_bottom_->cpu_data();
+  const TypeParam* top_data = this->blob_top_->cpu_data();
+
+  for (int i = 0; i < this->blob_bottom_->count(); ++i) {
+    EXPECT_GE( top_data[i], 0);
+    EXPECT_LE( top_data[i], 1);
+    EXPECT_NE( top_data[i], bottom_data[i]);
+  }
+}
+#endif
+
+}  // namespace caffe
diff --git a/src/caffe/test/test_value_transformation_layer.cpp b/src/caffe/test/test_value_transformation_layer.cpp
new file mode 100644
index 0000000..289aed4
--- /dev/null
+++ b/src/caffe/test/test_value_transformation_layer.cpp
@@ -0,0 +1,325 @@
+#include <algorithm>
+#include <vector>
+
+#include "gtest/gtest.h"
+
+#include "caffe/blob.hpp"
+#include "caffe/common.hpp"
+#include "caffe/filler.hpp"
+#include "caffe/layers/value_transformation_layer.hpp"
+
+#include "caffe/test/test_caffe_main.hpp"
+#include "caffe/test/test_gradient_check_util.hpp"
+
+namespace caffe {
+
+  template <typename TypeParam>
+  class ValueTransformationLayerTest : public MultiDeviceTest<TypeParam> {
+    typedef typename TypeParam::Dtype Dtype;
+
+  protected:
+    ValueTransformationLayerTest()
+            : blob_bottom_(new Blob<Dtype>(2, 3, 4, 5)),
+              blob_top_(new Blob<Dtype>()) {
+      Caffe::set_random_seed(1527);
+      // fill the values
+      FillerParameter filler_param;
+      GaussianFiller<Dtype> filler(filler_param);
+      filler.Fill(this->blob_bottom_);
+      blob_bottom_vec_.push_back(blob_bottom_);
+      blob_top_vec_.push_back(blob_top_);
+
+      std::vector<int> shape_3d(5);
+      shape_3d[0] = 2; // nsamples
+      shape_3d[1] = 3; // nchannels
+      shape_3d[2] = 4; // zsize (d)
+      shape_3d[3] = 5; // ysize (h)
+      shape_3d[4] = 6; // xsize (w)
+      blob_bottom_3d_ = new Blob<Dtype>(shape_3d);
+      blob_top_3d_ = new Blob<Dtype>(shape_3d);
+      blob_bottom_vec_3d_.push_back(blob_bottom_3d_);
+      blob_top_vec_3d_.push_back(blob_top_3d_);
+    }
+    virtual ~ValueTransformationLayerTest() {
+      delete blob_bottom_; delete blob_top_;
+      delete blob_bottom_3d_; delete blob_top_3d_;
+    }
+
+    void TestForward(std::vector<Dtype> const &scale,
+                     std::vector<Dtype> const &offset) {
+      LayerParameter layer_param;
+      ValueTransformationParameter *value_transformation_param =
+          layer_param.mutable_value_transformation_param();
+      int nsamples = this->blob_bottom_->shape(0);
+      int nchannels = this->blob_bottom_->shape(1);
+      int count = this->blob_bottom_->count() / (nsamples * nchannels);
+      for (size_t ch = 0; ch < offset.size(); ++ch) {
+        value_transformation_param->mutable_offset()->add_v(offset[ch]);
+      }
+      for (size_t ch = 0; ch < scale.size(); ++ch) {
+        value_transformation_param->mutable_scale()->add_v(scale[ch]);
+      }
+
+      std::vector<Dtype> offs(nchannels), sc(nchannels);
+      for (size_t ch = 0; ch < offset.size(); ++ch) {
+        offs[ch] = offset[ch];
+      }
+      for (size_t ch = offset.size(); ch < nchannels; ++ch) {
+        offs[ch] = offset[offset.size() - 1];
+      }
+      for (size_t ch = 0; ch < scale.size(); ++ch) {
+        sc[ch] = scale[ch];
+      }
+      for (size_t ch = scale.size(); ch < nchannels; ++ch) {
+        sc[ch] = scale[scale.size() - 1];
+      }
+
+      ValueTransformationLayer<Dtype> layer(layer_param);
+      layer.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
+      layer.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
+      // Now, check values
+      const Dtype* bottom_data = this->blob_bottom_->cpu_data();
+      const Dtype* top_data = this->blob_top_->cpu_data();
+      const Dtype min_precision = 1e-5;
+      for (int num = 0; num < nsamples; ++num) {
+        for (int ch = 0; ch < nchannels; ++ch) {
+          for (int i = 0; i < count; ++i) {
+            Dtype expected_value = sc[ch] *
+                (bottom_data[(num * nchannels + ch) * count + i] + offs[ch]);
+            Dtype precision = std::max(
+                Dtype(std::abs(expected_value * Dtype(1e-4))), min_precision);
+            EXPECT_NEAR(
+                expected_value, top_data[(num * nchannels + ch) * count + i],
+                precision);
+          }
+        }
+      }
+    }
+
+    void TestForward3d(std::vector<Dtype> const &scale,
+                       std::vector<Dtype> const &offset) {
+      LayerParameter layer_param;
+      ValueTransformationParameter *value_transformation_param =
+          layer_param.mutable_value_transformation_param();
+      int nsamples = this->blob_bottom_3d_->shape(0);
+      int nchannels = this->blob_bottom_3d_->shape(1);
+      int count = this->blob_bottom_3d_->count() / (nsamples * nchannels);
+      for (size_t ch = 0; ch < offset.size(); ++ch) {
+        value_transformation_param->mutable_offset()->add_v(offset[ch]);
+      }
+      for (size_t ch = 0; ch < scale.size(); ++ch) {
+        value_transformation_param->mutable_scale()->add_v(scale[ch]);
+      }
+
+      std::vector<Dtype> offs(nchannels), sc(nchannels);
+      for (size_t ch = 0; ch < offset.size(); ++ch) {
+        offs[ch] = offset[ch];
+      }
+      for (size_t ch = offset.size(); ch < nchannels; ++ch) {
+        offs[ch] = offset[offset.size() - 1];
+      }
+      for (size_t ch = 0; ch < scale.size(); ++ch) {
+        sc[ch] = scale[ch];
+      }
+      for (size_t ch = scale.size(); ch < nchannels; ++ch) {
+        sc[ch] = scale[scale.size() - 1];
+      }
+
+      ValueTransformationLayer<Dtype> layer(layer_param);
+      layer.SetUp(this->blob_bottom_vec_3d_, this->blob_top_vec_3d_);
+      layer.Forward(this->blob_bottom_vec_3d_, this->blob_top_vec_3d_);
+      // Now, check values
+      const Dtype* bottom_data = this->blob_bottom_3d_->cpu_data();
+      const Dtype* top_data = this->blob_top_3d_->cpu_data();
+      const Dtype min_precision = 1e-5;
+      for (int num = 0; num < nsamples; ++num) {
+        for (int ch = 0; ch < nchannels; ++ch) {
+          for (int i = 0; i < count; ++i) {
+            Dtype expected_value = sc[ch] *
+                (bottom_data[(num * nchannels + ch) * count + i] + offs[ch]);
+            Dtype precision = std::max(
+                Dtype(std::abs(expected_value * Dtype(1e-4))), min_precision);
+            EXPECT_NEAR(
+                expected_value, top_data[(num * nchannels + ch) * count + i],
+                precision);
+          }
+        }
+      }
+    }
+
+    void TestBackward(std::vector<Dtype> const &scale,
+                      std::vector<Dtype> const &offset) {
+      LayerParameter layer_param;
+      ValueTransformationParameter *value_transformation_param =
+          layer_param.mutable_value_transformation_param();
+      for (size_t ch = 0; ch < offset.size(); ++ch) {
+        value_transformation_param->mutable_offset()->add_v(offset[ch]);
+      }
+      for (size_t ch = 0; ch < scale.size(); ++ch) {
+        value_transformation_param->mutable_scale()->add_v(scale[ch]);
+      }
+      ValueTransformationLayer<Dtype> layer(layer_param);
+      GradientChecker<Dtype> checker(1e-3, 1e-2, 1527, 0., 0.01);
+      checker.CheckGradientEltwise(&layer, this->blob_bottom_vec_,
+                                   this->blob_top_vec_);
+    }
+
+    void TestBackward3d(std::vector<Dtype> const &scale,
+                        std::vector<Dtype> const &offset) {
+      LayerParameter layer_param;
+      ValueTransformationParameter *value_transformation_param =
+          layer_param.mutable_value_transformation_param();
+      for (size_t ch = 0; ch < offset.size(); ++ch) {
+        value_transformation_param->mutable_offset()->add_v(offset[ch]);
+      }
+      for (size_t ch = 0; ch < scale.size(); ++ch) {
+        value_transformation_param->mutable_scale()->add_v(scale[ch]);
+      }
+      ValueTransformationLayer<Dtype> layer(layer_param);
+      GradientChecker<Dtype> checker(1e-3, 1e-2, 1527, 0., 0.01);
+      checker.CheckGradientEltwise(&layer, this->blob_bottom_vec_3d_,
+                                   this->blob_top_vec_3d_);
+    }
+
+    Blob<Dtype>* const blob_bottom_;
+    Blob<Dtype>* const blob_top_;
+    vector<Blob<Dtype>*> blob_bottom_vec_;
+    vector<Blob<Dtype>*> blob_top_vec_;
+
+    Blob<Dtype>* blob_bottom_3d_;
+    Blob<Dtype>* blob_top_3d_;
+    vector<Blob<Dtype>*> blob_bottom_vec_3d_;
+    vector<Blob<Dtype>*> blob_top_vec_3d_;
+  };
+
+  TYPED_TEST_CASE(ValueTransformationLayerTest, TestDtypesAndDevices);
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformation) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(3);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestForward(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformation3d) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(3);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestForward3d(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationGradient) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(3);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestBackward(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationGradient3d) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(3);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestBackward3d(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneOffset) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(1);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    this->TestForward(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneOffset3d) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(1);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    this->TestForward3d(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneOffsetGradient) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(1);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    this->TestBackward(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneOffsetGradient3d) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(3), offset(1);
+    scale[0] = 0.62;
+    scale[1] = 1.35;
+    scale[2] = -1.5;
+    offset[0] = -0.25;
+    this->TestBackward3d(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneScale) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(1), offset(3);
+    scale[0] = 0.62;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestForward(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneScale3d) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(1), offset(3);
+    scale[0] = 0.62;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestForward3d(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneScaleGradient) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(1), offset(3);
+    scale[0] = 0.62;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestBackward(scale, offset);
+  }
+
+  TYPED_TEST(ValueTransformationLayerTest, TestValueTransformationOneScaleGradient3d) {
+    typedef typename TypeParam::Dtype Dtype;
+    std::vector<Dtype> scale(1), offset(3);
+    scale[0] = 0.62;
+    offset[0] = -0.25;
+    offset[1] = 1.8;
+    offset[2] = -25.05;
+    this->TestBackward3d(scale, offset);
+  }
+
+}  // namespace caffe
diff --git a/src/caffe/test/test_vector_helper.cpp b/src/caffe/test/test_vector_helper.cpp
new file mode 100644
index 0000000..1fb5cc8
--- /dev/null
+++ b/src/caffe/test/test_vector_helper.cpp
@@ -0,0 +1,562 @@
+#include <string>
+#include <vector>
+
+#include "gtest/gtest.h"
+#include "caffe/util/vector_helper.hpp"
+#include "caffe/test/test_caffe_main.hpp"
+
+#include "caffe/test/test_caffe_main.hpp"
+
+namespace caffe {
+
+template<typename Dtype>
+class VectorHelperTest : public ::testing::Test {
+ protected:
+  VectorHelperTest(){
+  }
+
+  virtual void SetUp() {
+  }
+
+  virtual ~VectorHelperTest() {
+  }
+
+};
+
+TYPED_TEST_CASE(VectorHelperTest, TestDtypes);
+
+TYPED_TEST(VectorHelperTest, TestBasics) {
+  vector<TypeParam> A = make_vec<TypeParam>(5,4,3,2,1);
+  EXPECT_EQ( "(5,4,3,2,1)", toString(A));
+}
+
+TYPED_TEST(VectorHelperTest, TestShift3D) {
+  vector<TypeParam> A = make_vec<TypeParam>(
+      3,3,2,3,
+      1,2,5,4,
+      2,1,1,2,
+      0,0,0,1);
+  vector<TypeParam> B = m_shift3D<TypeParam>(7, 4, 12, A);
+
+  vector<TypeParam> R = make_vec<TypeParam>(
+      3,3,2,10,
+      1,2,5,8,
+      2,1,1,14,
+      0,0,0,1);
+  EXPECT_EQ( toString(R), toString(B));
+}
+
+TYPED_TEST(VectorHelperTest, TestScale3D) {
+  // test scaling of unit matrix
+  vector<TypeParam> A = make_vec<TypeParam>(
+      1,0,0,0,
+      0,1,0,0,
+      0,0,1,0,
+      0,0,0,1);
+  vector<TypeParam> B = m_scale3D<TypeParam>(4, 3, 2, A);
+  EXPECT_EQ( "(4,0,0,0,"
+             "0,3,0,0,"
+             "0,0,2,0,"
+             "0,0,0,1)", toString(B));
+
+  // test scaling forward and inverse
+   vector<TypeParam> C = make_vec<TypeParam>(
+      3,3,2,3,
+      1,2,5,4,
+      2,1,1,2,
+      0,0,0,1);
+
+   vector<TypeParam> D = m_scale3D<TypeParam>(4, 3, 2, C);
+   vector<TypeParam> E = m_scale3D<TypeParam>(1.0/4, 1.0/3, 1.0/2, D);
+
+   EXPECT_EQ( toString(E), toString(C));
+}
+
+TYPED_TEST(VectorHelperTest, TestRotate3D) {
+  vector<TypeParam> A = make_vec<TypeParam>(
+      4,0,0,0,
+      0,3,0,0,
+      0,0,2,0,
+      0,0,0,1);
+
+  // rotation around first axis
+  vector<TypeParam> B = m_rotate3D<TypeParam>(90, 0, 0, A);
+  for (int i = 0; i < 16; ++i) {
+    B[i] = std::floor( B[i] * 100000 + 0.5) / 100000;
+  }
+
+  EXPECT_EQ( "(4,0,0,0,"
+             "0,0,-2,0,"
+             "0,3,0,0,"
+             "0,0,0,1)", toString(B));
+
+  // rotation around second axis
+  B = m_rotate3D<TypeParam>(0, 90, 0, A);
+  for (int i = 0; i < 16; ++i) {
+    B[i] = std::floor( B[i] * 100000 + 0.5) / 100000;
+  }
+
+  EXPECT_EQ( "(0,0,-2,0,"
+             "0,3,0,0,"
+             "4,0,0,0,"
+             "0,0,0,1)", toString(B));
+
+  // rotation around third axis
+  B = m_rotate3D<TypeParam>(0, 0, 90, A);
+  for (int i = 0; i < 16; ++i) {
+    B[i] = std::floor( B[i] * 100000 + 0.5) / 100000;
+  }
+
+  EXPECT_EQ( "(0,-3,0,0,"
+             "4,0,0,0,"
+             "0,0,2,0,"
+             "0,0,0,1)", toString(B));
+
+  // rotate forward backward
+  vector<TypeParam> C = make_vec<TypeParam>(
+      3,3,2,3,
+      1,2,5,4,
+      2,1,1,2,
+      0,0,0,1);
+  B = m_rotate3D<TypeParam>(27.5, 0, 0, C);
+  B = m_rotate3D<TypeParam>(-27.5, 0, 0, B);
+
+  for (int i = 0; i < 16; ++i) {
+    B[i] = std::floor( B[i] * 100000 + 0.5) / 100000;
+  }
+
+  EXPECT_EQ( toString(B), toString(C));
+
+  B = m_rotate3D<TypeParam>(0, 13.9, 0, C);
+  B = m_rotate3D<TypeParam>(0, -13.9, 0, B);
+
+  for (int i = 0; i < 16; ++i) {
+    B[i] = std::floor( B[i] * 100000 + 0.5) / 100000;
+  }
+
+  EXPECT_EQ( toString(B), toString(C));
+
+  B = m_rotate3D<TypeParam>(0, 0, 42.14, C);
+  B = m_rotate3D<TypeParam>(0, 0, -42.14, B);
+
+  for (int i = 0; i < 16; ++i) {
+    B[i] = std::floor( B[i] * 100000 + 0.5) / 100000;
+  }
+
+  EXPECT_EQ( toString(B), toString(C));
+
+}
+
+TYPED_TEST(VectorHelperTest, TestFlip2D) {
+  vector<TypeParam> A = make_vec<TypeParam>(
+      3,3,2,3,
+      1,2,5,4,
+      2,7,1,2);
+  vector<TypeParam> B = make_vec<TypeParam>(
+	  3,2,3,3,
+	  4,5,2,1,
+	  2,1,7,2);
+  vector<TypeParam> C = make_vec<TypeParam>(
+	  2,7,1,2,
+	  1,2,5,4,
+	  3,3,2,3);
+  vector<TypeParam> D = make_vec<TypeParam>(
+	  2,1,7,2,
+	  4,5,2,1,
+	  3,2,3,3);
+  vector<TypeParam> B2(A.size(), 0);
+  vector<TypeParam> C2(A.size(), 0);
+  vector<TypeParam> D2(A.size(), 0);
+  vector<TypeParam> A2(A.size(), 0);
+
+  const TypeParam* in = A.data();
+  const int inNb = 1;
+  const int inNc = 1;
+  const int inNz = 1;
+  const int inNy = 3;
+  const int inNx = 4;
+
+  TypeParam* out = B2.data();
+  const int outNb = inNb;
+  const int outNc = inNc;
+  const int outNz = inNz;
+  const int outNy = inNy;
+  const int outNx = inNx;
+  flip2D_x( in, inNb, inNc, inNz, inNy, inNx,
+			out,outNb, outNc, outNz, outNy, outNx);
+
+  EXPECT_EQ( toString(B), toString(B2));
+
+  out = C2.data();
+  flip2D_y( in, inNb, inNc, inNz, inNy, inNx,
+			out,outNb, outNc, outNz, outNy, outNx);
+
+  EXPECT_EQ( toString(C), toString(C2));
+
+  out = D2.data();
+  flip2D_xy( in, inNb, inNc, inNz, inNy, inNx,
+			 out,outNb, outNc, outNz, outNy, outNx);
+
+  EXPECT_EQ( toString(D), toString(D2));
+
+  const TypeParam* in2 = B2.data();
+  out = A2.data();
+  flip2D_x( in2, inNb, inNc, inNz, inNy, inNx,
+			out,outNb, outNc, outNz, outNy, outNx);
+
+  EXPECT_EQ( toString(A), toString(A2));
+
+}
+
+TYPED_TEST(VectorHelperTest, TestCropAndFlip) {
+
+  // 1D tests
+  {
+    // Crop within data range without flipping 1D
+    int inSize = 14, outSize = 7, offset = 3;
+    vector<TypeParam> in(inSize);
+    for (int i = 0; i < in.size(); ++i) in[i] = i;
+    vector<int> inShape(1, in.size());
+    vector<int> offs(1, offset);
+    vector<bool> flip(1, false);
+
+    vector<TypeParam> expectedOut(outSize);
+    for (int i = 0; i < expectedOut.size(); ++i)
+        expectedOut[i] = in[i + offset];
+
+    vector<TypeParam> out(expectedOut.size(), 0);
+    vector<int> outShape(1, out.size());
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop within data range with flipping 1D
+    for (int i = 0; i < expectedOut.size(); ++i)
+        expectedOut[i] = in[outShape[0] - i - 1 + offset];
+    flip[0] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range (left) without flipping 1D
+    offs[0] = -2;
+    expectedOut[0] = 0;
+    expectedOut[1] = 0;
+    expectedOut[2] = 0;
+    expectedOut[3] = 1;
+    expectedOut[4] = 2;
+    expectedOut[5] = 3;
+    expectedOut[6] = 4;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range (right) without flipping 1D
+    offs[0] = 10;
+    expectedOut[0] = 10;
+    expectedOut[1] = 11;
+    expectedOut[2] = 12;
+    expectedOut[3] = 13;
+    expectedOut[4] = 0;
+    expectedOut[5] = 0;
+    expectedOut[6] = 0;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range (left) without flipping 1D (mirror)
+    offs[0] = -2;
+    expectedOut[0] = 2;
+    expectedOut[1] = 1;
+    expectedOut[2] = 0;
+    expectedOut[3] = 1;
+    expectedOut[4] = 2;
+    expectedOut[5] = 3;
+    expectedOut[6] = 4;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range (right) without flipping 1D (mirror)
+    offs[0] = 10;
+    expectedOut[0] = 10;
+    expectedOut[1] = 11;
+    expectedOut[2] = 12;
+    expectedOut[3] = 13;
+    expectedOut[4] = 12;
+    expectedOut[5] = 11;
+    expectedOut[6] = 10;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (left) without flipping 1D
+    offs[0] = -20;
+    expectedOut[0] = 0;
+    expectedOut[1] = 0;
+    expectedOut[2] = 0;
+    expectedOut[3] = 0;
+    expectedOut[4] = 0;
+    expectedOut[5] = 0;
+    expectedOut[6] = 0;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (right) without flipping 1D
+    offs[0] = 50;
+    expectedOut[0] = 0;
+    expectedOut[1] = 0;
+    expectedOut[2] = 0;
+    expectedOut[3] = 0;
+    expectedOut[4] = 0;
+    expectedOut[5] = 0;
+    expectedOut[6] = 0;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (left) without flipping 1D (mirror)
+    offs[0] = -30;
+    expectedOut[0] = 4;
+    expectedOut[1] = 3;
+    expectedOut[2] = 2;
+    expectedOut[3] = 1;
+    expectedOut[4] = 0;
+    expectedOut[5] = 1;
+    expectedOut[6] = 2;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (right) without flipping 1D (mirror)
+    offs[0] = 50;
+    expectedOut[0] = 2;
+    expectedOut[1] = 1;
+    expectedOut[2] = 0;
+    expectedOut[3] = 1;
+    expectedOut[4] = 2;
+    expectedOut[5] = 3;
+    expectedOut[6] = 4;
+    flip[0] = false;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (left) with flipping 1D
+    offs[0] = -20;
+    expectedOut[0] = 0;
+    expectedOut[1] = 0;
+    expectedOut[2] = 0;
+    expectedOut[3] = 0;
+    expectedOut[4] = 0;
+    expectedOut[5] = 0;
+    expectedOut[6] = 0;
+    flip[0] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (right) with flipping 1D
+    offs[0] = 50;
+    expectedOut[0] = 0;
+    expectedOut[1] = 0;
+    expectedOut[2] = 0;
+    expectedOut[3] = 0;
+    expectedOut[4] = 0;
+    expectedOut[5] = 0;
+    expectedOut[6] = 0;
+    flip[0] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (left) with flipping 1D (mirror)
+    offs[0] = -30;
+    expectedOut[0] = 2;
+    expectedOut[1] = 1;
+    expectedOut[2] = 0;
+    expectedOut[3] = 1;
+    expectedOut[4] = 2;
+    expectedOut[5] = 3;
+    expectedOut[6] = 4;
+    flip[0] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop out of data range (right) with flipping 1D (mirror)
+    offs[0] = 50;
+    expectedOut[0] = 4;
+    expectedOut[1] = 3;
+    expectedOut[2] = 2;
+    expectedOut[3] = 1;
+    expectedOut[4] = 0;
+    expectedOut[5] = 1;
+    expectedOut[6] = 2;
+    flip[0] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+  }
+
+  // 2D tests
+  {
+    // Crop within data range without flipping 2D
+    std::vector<TypeParam> in(4 * 5);
+    for (int i = 0; i < 4 * 5; ++i) in[i] = i;
+    vector<int> inShape(2);
+    inShape[0] = 4;
+    inShape[1] = 5;
+    vector<int> offs(2);
+    offs[0] = 1;
+    offs[1] = 2;
+    vector<bool> flip(2, false);
+
+    vector<TypeParam> expectedOut(2 * 3);
+    expectedOut[0] = 7;
+    expectedOut[1] = 8;
+    expectedOut[2] = 9;
+    expectedOut[3] = 12;
+    expectedOut[4] = 13;
+    expectedOut[5] = 14;
+
+    vector<TypeParam> out(expectedOut.size(), 0);
+    vector<int> outShape(2);
+    outShape[0] = 2;
+    outShape[1] = 3;
+
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop within data range with flipping about dimension 0 2D
+    expectedOut[0] = 12;
+    expectedOut[1] = 13;
+    expectedOut[2] = 14;
+    expectedOut[3] = 7;
+    expectedOut[4] = 8;
+    expectedOut[5] = 9;
+    flip[0] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop within data range with flipping 2D
+    expectedOut[0] = 14;
+    expectedOut[1] = 13;
+    expectedOut[2] = 12;
+    expectedOut[3] = 9;
+    expectedOut[4] = 8;
+    expectedOut[5] = 7;
+    flip[0] = true;
+    flip[1] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop within data range with flipping about dimension 1 2D
+    expectedOut[0] = 9;
+    expectedOut[1] = 8;
+    expectedOut[2] = 7;
+    expectedOut[3] = 14;
+    expectedOut[4] = 13;
+    expectedOut[5] = 12;
+    flip[0] = false;
+    flip[1] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range with flipping about dimension 1 2D
+    offs[0] = 3;
+    offs[1] = 4;
+    expectedOut[0] = 0;
+    expectedOut[1] = 0;
+    expectedOut[2] = 19;
+    expectedOut[3] = 0;
+    expectedOut[4] = 0;
+    expectedOut[5] = 0;
+    flip[0] = false;
+    flip[1] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, false);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range with flipping about dimension 1 2D
+    // (mirror)
+    offs[0] = 3;
+    offs[1] = 4;
+    expectedOut[0] = 17;
+    expectedOut[1] = 18;
+    expectedOut[2] = 19;
+    expectedOut[3] = 12;
+    expectedOut[4] = 13;
+    expectedOut[5] = 14;
+    flip[0] = false;
+    flip[1] = true;
+    cropAndFlip(
+        in.data(), 1, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range with flipping about dimension 0 2D
+    // multi-channel (mirror)
+    for (int i = 0; i < 20; ++i) in.push_back(i + 20);
+    out.resize(12, 0);
+    expectedOut.resize(12, 0);
+    offs[0] = -1;
+    offs[1] = 4;
+    expectedOut[0] = 4;
+    expectedOut[1] = 3;
+    expectedOut[2] = 2;
+    expectedOut[3] = 9;
+    expectedOut[4] = 8;
+    expectedOut[5] = 7;
+    expectedOut[6] = 24;
+    expectedOut[7] = 23;
+    expectedOut[8] = 22;
+    expectedOut[9] = 29;
+    expectedOut[10] = 28;
+    expectedOut[11] = 27;
+    flip[0] = true;
+    flip[1] = false;
+    cropAndFlip(
+        in.data(), 1, 2, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+
+    // Crop partially within data range with flipping about dimension 0 2D
+    // multi-sample (mirror)
+    for (int i = 0; i < 20; ++i) in.push_back(i + 20);
+    out.resize(12, 0);
+    expectedOut.resize(12, 0);
+    offs[0] = -1;
+    offs[1] = 4;
+    expectedOut[0] = 4;
+    expectedOut[1] = 3;
+    expectedOut[2] = 2;
+    expectedOut[3] = 9;
+    expectedOut[4] = 8;
+    expectedOut[5] = 7;
+    expectedOut[6] = 24;
+    expectedOut[7] = 23;
+    expectedOut[8] = 22;
+    expectedOut[9] = 29;
+    expectedOut[10] = 28;
+    expectedOut[11] = 27;
+    flip[0] = true;
+    flip[1] = false;
+    cropAndFlip(
+        in.data(), 2, 1, inShape, out.data(), outShape, offs, flip, true);
+    EXPECT_EQ(toString(expectedOut), toString(out));
+  }
+
+}
+
+}  // end namespace caffe
diff --git a/src/caffe/util/hdf5.cpp b/src/caffe/util/hdf5.cpp
index 7730e76..f1673c8 100644
--- a/src/caffe/util/hdf5.cpp
+++ b/src/caffe/util/hdf5.cpp
@@ -82,6 +82,15 @@ void hdf5_load_nd_dataset<double>(hid_t file_id, const char* dataset_name_,
 }
 
 template <>
+void hdf5_load_nd_dataset<int>(hid_t file_id, const char* dataset_name_,
+        int min_dim, int max_dim, Blob<int>* blob) {
+  hdf5_load_nd_dataset_helper(file_id, dataset_name_, min_dim, max_dim, blob);
+  herr_t status = H5LTread_dataset_int(
+    file_id, dataset_name_, blob->mutable_cpu_data());
+  CHECK_GE(status, 0) << "Failed to read int dataset " << dataset_name_;
+}
+
+template <>
 void hdf5_save_nd_dataset<float>(
     const hid_t file_id, const string& dataset_name, const Blob<float>& blob,
     bool write_diff) {
@@ -157,12 +166,34 @@ int hdf5_load_int(hid_t loc_id, const string& dataset_name) {
 
 void hdf5_save_int(hid_t loc_id, const string& dataset_name, int i) {
   hsize_t one = 1;
-  herr_t status = \
+  herr_t status =
     H5LTmake_dataset_int(loc_id, dataset_name.c_str(), 1, &one, &i);
   CHECK_GE(status, 0)
     << "Failed to save int dataset with name " << dataset_name;
 }
 
+std::vector<int> hdf5_load_int_vec(hid_t loc_id, const string &dataset_name) {
+  std::vector<hsize_t> dsShape(
+      hdf5_get_dataset_shape(loc_id, dataset_name.c_str()));
+  CHECK_EQ(dsShape.size(), 1)
+      << "Could not load " << dataset_name << " into 1-D vector";
+  std::vector<int> res(dsShape[0]);
+  herr_t status =
+      H5LTread_dataset_int(loc_id, dataset_name.c_str(), res.data());
+  CHECK_GE(status, 0)
+    << "Failed to load vectorial int dataset with name " << dataset_name;
+  return res;
+}
+
+void hdf5_save_int_vec(
+    hid_t loc_id, const string &dataset_name, std::vector<int> vec) {
+  hsize_t size = vec.size();
+  herr_t status = H5LTmake_dataset_int(
+      loc_id, dataset_name.c_str(), 1, &size, vec.data());
+  CHECK_GE(status, 0)
+      << "Failed to save vectorial int dataset with name " << dataset_name;
+}
+
 int hdf5_get_num_links(hid_t loc_id) {
   H5G_info_t info;
   herr_t status = H5Gget_info(loc_id, &info);
@@ -184,4 +215,18 @@ string hdf5_get_name_by_idx(hid_t loc_id, int idx) {
   return result;
 }
 
+std::vector<hsize_t> hdf5_get_dataset_shape(
+    hid_t file_id, const char* dataset_name) {
+  // get number of dimensions
+  herr_t status;
+  int ndims;
+  status = H5LTget_dataset_ndims(file_id, dataset_name, &ndims);
+  std::vector<hsize_t> dims(ndims);
+  status = H5LTget_dataset_info(
+      file_id, dataset_name, dims.data(), NULL, NULL);
+  CHECK_GE(status, 0) << "Failed to get dataset info for " << dataset_name;
+  return dims;
+}
+
+
 }  // namespace caffe
diff --git a/src/caffe/util/math_functions.cpp b/src/caffe/util/math_functions.cpp
index 71c0227..85c92de 100644
--- a/src/caffe/util/math_functions.cpp
+++ b/src/caffe/util/math_functions.cpp
@@ -65,6 +65,7 @@ void caffe_set(const int N, const Dtype alpha, Dtype* Y) {
 }
 
 template void caffe_set<int>(const int N, const int alpha, int* Y);
+template void caffe_set<unsigned int>(const int N, const unsigned int alpha, unsigned int* Y);
 template void caffe_set<float>(const int N, const float alpha, float* Y);
 template void caffe_set<double>(const int N, const double alpha, double* Y);
 
@@ -97,13 +98,92 @@ void caffe_copy(const int N, const Dtype* X, Dtype* Y) {
     }
   }
 }
-
 template void caffe_copy<int>(const int N, const int* X, int* Y);
 template void caffe_copy<unsigned int>(const int N, const unsigned int* X,
     unsigned int* Y);
 template void caffe_copy<float>(const int N, const float* X, float* Y);
 template void caffe_copy<double>(const int N, const double* X, double* Y);
 
+
+template <typename Dtype>
+void caffe_copy_subarray(const Dtype* src_p, const vector<int>& src_shape,
+                         Dtype*       trg_p, const vector<int>& trg_shape,
+                         const vector<int>& src_offset,
+                         const vector<int>& copy_shape,
+                         const vector<int>& trg_offset) {
+//  std::cout << "copy_subarray called with \n"
+//            << "src_shape=" << toString( src_shape) << "\n"
+//            << "trg_shape=" << toString( trg_shape) << "\n"
+//            << "src_offset=" << toString( src_offset) << "\n"
+//            << "copy_shape=" << toString( copy_shape) << "\n"
+//            << "trg_offset=" << toString( trg_offset) << "\n";
+  int num_axes = src_shape.size();
+  CHECK_LT(num_axes, 10) << "only 10 axes are supported";
+  CHECK_EQ(src_shape.size(), trg_shape.size()) << "target must have same number of axes";
+  CHECK_EQ(src_shape.size(), src_offset.size());
+  CHECK_EQ(src_shape.size(), copy_shape.size());
+  CHECK_EQ(src_shape.size(), trg_offset.size());
+
+  int N[10];   // copy shape
+  int so[10];  // src offset
+  int to[10];  // trg offset
+  int ss[10];  // src stride
+  int ts[10];  // trg stride
+  int axes_offset = 10 - num_axes;
+  for (int i = 0; i < axes_offset; ++i) {
+    N[i] = 1;
+    so[i] = 0;
+    to[i] = 0;
+    ss[i] = 0;  // dummy value, will be multiplied with zero anyway
+    ts[i] = 0;  // dummy value, will be multiplied with zero anyway
+  }
+
+  for (int i = 0; i < num_axes; ++i) {
+    N[ axes_offset + i] = copy_shape[i];
+    so[axes_offset + i] = src_offset[i];
+    to[axes_offset + i] = trg_offset[i];
+  }
+
+  ss[9] = 1;
+  ts[9] = 1;
+  for (int i = num_axes-1; i > 0; --i) {
+    ss[axes_offset + i - 1] = src_shape[i] * ss[axes_offset + i];
+    ts[axes_offset + i - 1] = trg_shape[i] * ts[axes_offset + i];
+  }
+//  std::cout << "resulting 10d vectors\n"
+//            << "N=" << toString(N,10) << "\n"
+//            << "so=" << toString(so,10) << "\n"
+//            << "to=" << toString(to,10) << "\n"
+//            << "ss=" << toString(ss,10) << "\n"
+//            << "ts=" << toString(ts,10) << "\n";
+
+  int copy_nelem = N[9];
+  for (                int i0 = 0; i0 < N[0]; ++i0) { int s0  =      ss[0] * (i0 + so[0]); int t0 =      ts[0] * (i0 + to[0]);
+    for (              int i1 = 0; i1 < N[1]; ++i1) { int s1  = s0 + ss[1] * (i1 + so[1]); int t1 = t0 + ts[1] * (i1 + to[1]);
+      for (            int i2 = 0; i2 < N[2]; ++i2) { int s2  = s1 + ss[2] * (i2 + so[2]); int t2 = t1 + ts[2] * (i2 + to[2]);
+        for (          int i3 = 0; i3 < N[3]; ++i3) { int s3  = s2 + ss[3] * (i3 + so[3]); int t3 = t2 + ts[3] * (i3 + to[3]);
+          for (        int i4 = 0; i4 < N[4]; ++i4) { int s4  = s3 + ss[4] * (i4 + so[4]); int t4 = t3 + ts[4] * (i4 + to[4]);
+            for (      int i5 = 0; i5 < N[5]; ++i5) { int s5  = s4 + ss[5] * (i5 + so[5]); int t5 = t4 + ts[5] * (i5 + to[5]);
+              for (    int i6 = 0; i6 < N[6]; ++i6) { int s6  = s5 + ss[6] * (i6 + so[6]); int t6 = t5 + ts[6] * (i6 + to[6]);
+                for (  int i7 = 0; i7 < N[7]; ++i7) { int s7  = s6 + ss[7] * (i7 + so[7]); int t7 = t6 + ts[7] * (i7 + to[7]);
+                  for (int i8 = 0; i8 < N[8]; ++i8) { int s8  = s7 + ss[8] * (i8 + so[8]); int t8 = t7 + ts[8] * (i8 + to[8]);
+                    caffe_copy(copy_nelem, src_p + s8 + so[9], trg_p + t8 + to[9]);
+                  }
+                }
+              }
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+template void caffe_copy_subarray<int>(         const int*          src_p, const vector<int>& src_shape, int*          trg_p, const vector<int>& trg_shape, const vector<int>& src_offset, const vector<int>& copy_shape, const vector<int>& trg_offset);
+template void caffe_copy_subarray<unsigned int>(const unsigned int* src_p, const vector<int>& src_shape, unsigned int* trg_p, const vector<int>& trg_shape, const vector<int>& src_offset, const vector<int>& copy_shape, const vector<int>& trg_offset);
+template void caffe_copy_subarray<float>(       const float*        src_p, const vector<int>& src_shape, float*        trg_p, const vector<int>& trg_shape, const vector<int>& src_offset, const vector<int>& copy_shape, const vector<int>& trg_offset);
+template void caffe_copy_subarray<double>(      const double*       src_p, const vector<int>& src_shape, double*       trg_p, const vector<int>& trg_shape, const vector<int>& src_offset, const vector<int>& copy_shape, const vector<int>& trg_offset);
+
 template <>
 void caffe_scal<float>(const int N, const float alpha, float *X) {
   cblas_sscal(N, alpha, X, 1);
@@ -325,6 +405,41 @@ void caffe_rng_bernoulli<double>(const int n, const double p, unsigned int* r);
 template
 void caffe_rng_bernoulli<float>(const int n, const float p, unsigned int* r);
 
+template <typename Dtype>
+size_t caffe_randi_arbitrary_cdf(const size_t n, const Dtype* cdf) {
+  CHECK_GT(n, 0);
+  CHECK(cdf);
+  Dtype maxValue = cdf[n-1];
+  Dtype r;
+  caffe_rng_uniform( 1, Dtype(0), maxValue, &r);
+  const Dtype* p = std::lower_bound( cdf, cdf + n, r);
+  return p - cdf;
+}
+
+template
+size_t caffe_randi_arbitrary_cdf(const size_t n, const float* cdf);
+
+template
+size_t caffe_randi_arbitrary_cdf(const size_t n, const double* cdf);
+
+template <typename Dtype>
+void caffe_rand_pos_arbitrary_cdf(const Dtype* cdf, int nz, int ny, int nx,
+                                  int* z, int* y, int* x) {
+  // sample a random index and map it to coordinates
+  size_t idx = caffe_randi_arbitrary_cdf( nz * ny * nx, cdf);
+  *z = idx / (ny * nx);
+  idx = idx - *z * ny * nx;
+  *y = idx / nx;
+  *x = idx - *y * nx;
+}
+
+template
+void caffe_rand_pos_arbitrary_cdf(const float* cdf, int nz, int ny, int nx,
+                                  int* z, int* y, int* x);
+template
+void caffe_rand_pos_arbitrary_cdf(const double* cdf, int nz, int ny, int nx,
+                                  int* z, int* y, int* x);
+
 template <>
 float caffe_cpu_strided_dot<float>(const int n, const float* x, const int incx,
     const float* y, const int incy) {
@@ -358,6 +473,25 @@ double caffe_cpu_asum<double>(const int n, const double* x) {
   return cblas_dasum(n, x, 1);
 }
 
+template <typename Dtype>
+void caffe_cpu_cumsum(const size_t n, const Dtype* x, Dtype* y) {
+  CHECK_GE(n, 0);
+  CHECK(x);
+  CHECK(y);
+  if( n == 0) return;
+  Dtype cumsum = 0;
+  for (size_t i = 0; i < n; ++i) {
+    cumsum += x[i];
+    y[i] = cumsum;
+  }
+}
+
+template
+void caffe_cpu_cumsum(const size_t n, const float* x, float* y);
+
+template
+void caffe_cpu_cumsum(const size_t n, const double* x, double* y);
+
 template <>
 void caffe_cpu_scale<float>(const int n, const float alpha, const float *x,
                             float* y) {
diff --git a/src/caffe/util/math_functions.cu b/src/caffe/util/math_functions.cu
index 4c58753..9511758 100644
--- a/src/caffe/util/math_functions.cu
+++ b/src/caffe/util/math_functions.cu
@@ -159,6 +159,7 @@ void caffe_gpu_set(const int N, const Dtype alpha, Dtype* Y) {
 }
 
 template void caffe_gpu_set<int>(const int N, const int alpha, int* Y);
+template void caffe_gpu_set<unsigned int>(const int N, const unsigned int alpha, unsigned int* Y);
 template void caffe_gpu_set<float>(const int N, const float alpha, float* Y);
 template void caffe_gpu_set<double>(const int N, const double alpha, double* Y);
 
diff --git a/src/caffe/util/upgrade_proto.cpp b/src/caffe/util/upgrade_proto.cpp
index 9e18691..b974661 100644
--- a/src/caffe/util/upgrade_proto.cpp
+++ b/src/caffe/util/upgrade_proto.cpp
@@ -267,7 +267,7 @@ bool UpgradeV0LayerParameter(const V1LayerParameter& v0_layer_connection,
       if (type == "conv") {
         layer_param->mutable_convolution_param()->add_pad(v0_layer_param.pad());
       } else if (type == "pool") {
-        layer_param->mutable_pooling_param()->set_pad(v0_layer_param.pad());
+        layer_param->mutable_pooling_param()->add_pad(v0_layer_param.pad());
       } else {
         LOG(ERROR) << "Unknown parameter pad for layer type " << type;
         is_fully_compatible = false;
@@ -278,7 +278,7 @@ bool UpgradeV0LayerParameter(const V1LayerParameter& v0_layer_connection,
         layer_param->mutable_convolution_param()->add_kernel_size(
             v0_layer_param.kernelsize());
       } else if (type == "pool") {
-        layer_param->mutable_pooling_param()->set_kernel_size(
+        layer_param->mutable_pooling_param()->add_kernel_size(
             v0_layer_param.kernelsize());
       } else {
         LOG(ERROR) << "Unknown parameter kernelsize for layer type " << type;
@@ -299,7 +299,7 @@ bool UpgradeV0LayerParameter(const V1LayerParameter& v0_layer_connection,
         layer_param->mutable_convolution_param()->add_stride(
             v0_layer_param.stride());
       } else if (type == "pool") {
-        layer_param->mutable_pooling_param()->set_stride(
+        layer_param->mutable_pooling_param()->add_stride(
             v0_layer_param.stride());
       } else {
         LOG(ERROR) << "Unknown parameter stride for layer type " << type;
diff --git a/tools/CMakeLists.txt b/tools/CMakeLists.txt
index 02fbd5c..c43841a 100644
--- a/tools/CMakeLists.txt
+++ b/tools/CMakeLists.txt
@@ -9,6 +9,10 @@ foreach(source ${srcs})
   if(name MATCHES "caffe")
     set(name ${name}.bin)
   endif()
+  # caffe_unet target already exits
+  if(name MATCHES "caffe_unet")
+    set(name ${name}.bin)
+  endif()
 
   # target
   add_executable(${name} ${source})
@@ -23,6 +27,9 @@ foreach(source ${srcs})
   if(name MATCHES "caffe.bin")
     set_target_properties(${name} PROPERTIES OUTPUT_NAME caffe)
   endif()
+  if(name MATCHES "caffe_unet.bin")
+    set_target_properties(${name} PROPERTIES OUTPUT_NAME caffe_unet)
+  endif()
 
   # Install
   install(TARGETS ${name} DESTINATION bin)
