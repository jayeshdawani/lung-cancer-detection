{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a training set from the LUNA 2016 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.109882169963817627559804568094.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.112767175295249119452142211437.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.114914167428485563471327801935.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.121108220866971173712229588402.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.121805476976020513950614465787.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.124656777236468248920498636247.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.124822907934319930841506266464.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.129650136453746261130135157590.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.134519406153127654901640638633.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.138674679709964033277400089532.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.138813197521718693188313387015.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.139577698050713461261415990027.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.141345499716190654505508410197.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.145510611155363050427743946446.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.148935306123327835217659769212.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.150097650621090951325113116280.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.153985109349433321657655488650.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.167661207884826429102690781600.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.170706757615202213033480003264.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.173931884906244951746140865701.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.174449669706458092793093760291.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.176869045992276345870480098568.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.179683407589764683292800449011.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.182192086929819295877506541021.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.187694838527128312070807533473.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.188385286346390202873004762827.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.188619674701053082195613114069.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.193721075067404532739943086458.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.193964947698259739624715468431.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.194632613233275988184244485809.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.195557219224169985110295082004.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.196251645377731223510086726530.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.199261544234308780356714831537.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.212608679077007918190529579976.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.215104063467523905369326175410.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.215785045378334625097907422785.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.217754016294471278921686508169.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.220596530836092324070084384692.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.222052723822248889877676736332.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.227968442353440630355230778531.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.229096941293122177107846044795.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.229860476925100292554329427970.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.229960820686439513664996214638.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.230491296081537726468075344411.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.237215747217294006286437405216.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.237915456403882324748189195892.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.250481236093201801255751845296.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.254929810944557499537650429296.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.259453428008507791234730686014.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.265570697208310960298668720669.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.265780642925621389994857727416.mhd\n",
      "Getting mask for image file 1.3.6.1.4.1.14519.5.2.1.6279.6001.268030488196493755113553009785.mhd\n",
      "73.79496797\n",
      "69.55764009\n",
      "-35.17353835\n",
      "8.158102396\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "luna_path = '../luna_2016_data/CSVFILES/'\n",
    "luna_subset_path = '../luna_2016_data/subset9/'\n",
    "file_list=glob(luna_subset_path+\"*.mhd\")\n",
    "\n",
    "#####################\n",
    "#\n",
    "# Helper function to get rows in data frame associated \n",
    "# with each file\n",
    "def get_filename(case):\n",
    "    global file_list\n",
    "    for f in file_list:\n",
    "        if case in f:\n",
    "            return(f)\n",
    "#\n",
    "# The locations of the nodes\n",
    "df_node = pd.read_csv(luna_path+\"annotations.csv\")\n",
    "df_node[\"file\"] = df_node[\"seriesuid\"].apply(get_filename)\n",
    "df_node = df_node.dropna()\n",
    "\n",
    "#####\n",
    "#\n",
    "# Looping over the image files\n",
    "#\n",
    "fcount = 0\n",
    "for img_file in file_list:\n",
    "    print \"Getting mask for image file %s\" % img_file.replace(luna_subset_path,\"\")\n",
    "    mini_df = df_node[df_node[\"file\"]==img_file] #get all nodules associate with file\n",
    "    if len(mini_df)>0:       # some files may not have a nodule--skipping those \n",
    "        biggest_node = np.argsort(mini_df[\"diameter_mm\"].values)[-1]   # just using the biggest node\n",
    "        node_x = mini_df[\"coordX\"].values[biggest_node]\n",
    "        node_y = mini_df[\"coordY\"].values[biggest_node]\n",
    "        node_z = mini_df[\"coordZ\"].values[biggest_node]\n",
    "        diam = mini_df[\"diameter_mm\"].values[biggest_node]\n",
    "print(node_x)\n",
    "print(node_y)\n",
    "print(node_z)\n",
    "print(diam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the nodule position in the mhd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x7fa5b2e52b80)\n",
      "  RTTI typeinfo:   itk::Image<short, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 1450\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 1425\n",
      "  UpdateMTime: 1449\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 445]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 445]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 445]\n",
      "  Spacing: [0.644531, 0.644531, 0.625]\n",
      "  Origin: [-170.2, -150.5, -248.115]\n",
      "  Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0.644531 0 0\n",
      "0 0.644531 0\n",
      "0 0 0.625\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "1.55152 0 0\n",
      "0 1.55152 0\n",
      "0 0 1.6\n",
      "\n",
      "  Inverse Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x7fa5b2e4d740)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, short>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 1446\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x11f30c000\n",
      "      Container manages memory: true\n",
      "      Size: 116654080\n",
      "      Capacity: 116654080\n",
      "\n",
      "[[[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " ..., \n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]\n",
      "\n",
      " [[-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  ..., \n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]\n",
      "  [-3024 -3024 -3024 ..., -3024 -3024 -3024]]]\n",
      "[ 73.79496797  69.55764009 -35.17353835]\n",
      "[-170.199997 -150.5      -248.115005]\n",
      "[ 0.64453101  0.64453101  0.625     ]\n",
      "[ 379.  341.  341.]\n"
     ]
    }
   ],
   "source": [
    "itk_img = sitk.ReadImage(img_file) \n",
    "img_array = sitk.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n",
    "center = np.array([node_x,node_y,node_z])   # nodule center\n",
    "origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "v_center =np.rint((center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering)\n",
    "\n",
    "print itk_img\n",
    "print img_array\n",
    "print center\n",
    "print origin\n",
    "print spacing\n",
    "print v_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_xrange = range(1, 512)\n",
    "v_yrange = range(1, 512)\n",
    "\n",
    "def make_mask(center,diam,z,spacing,origin): # width, height?\n",
    "    mask = np.zeros([512,512,256])\n",
    "    for v_x in v_xrange:\n",
    "        for v_y in v_yrange:\n",
    "            p_x = spacing[0]*v_x + origin[0]\n",
    "            p_y = spacing[1]*v_y + origin[1]\n",
    "            if np.linalg.norm(center-np.array([p_x,p_y,z]))<=diam:\n",
    "                mask[int((p_y-origin[1])/spacing[1]),int((p_x-origin[0])/spacing[0])] = 1.0\n",
    "    return(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix2int16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-acb064fefa13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_z\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mspacing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspacing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# width, height?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix2int16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_z\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"images_%d.npy\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix2int16' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "masks = []\n",
    "for i_z in range(int(v_center[2]) - 1, int(v_center[2]) + 2):\n",
    "    mask = make_mask(center,diam,i_z*spacing[2]+origin[2],spacing,origin) # width, height?\n",
    "    masks.append(mask)\n",
    "    imgs[i] = matrix2int16(img_array[i_z])\n",
    "    i += 1\n",
    "np.save(output_path + \"images_%d.npy\" % (fcount) ,imgs)\n",
    "np.save(output_path + \"masks_%d.npy\" % (fcount) ,masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation of the Lung Region of Interest to Narrow Our Nodule Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = imgs_to_process[i]\n",
    "#Standardize the pixel values\n",
    "mean = np.mean(img)\n",
    "std = np.std(img)\n",
    "img = img-mean\n",
    "img = img/std\n",
    "plt.hist(img.flatten(),bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "middle = img[100:400,100:400] \n",
    "mean = np.mean(middle)  \n",
    "max = np.max(img)\n",
    "min = np.min(img)\n",
    "#move the underflow bins\n",
    "img[img==max]=mean\n",
    "img[img==min]=mean\n",
    "\n",
    "kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1]))\n",
    "centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "threshold = np.mean(centers)\n",
    "thresh_img = np.where(img<threshold,1.0,0.0)  # threshold the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cutting non-ROI Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = measure.label(dilation)\n",
    "label_vals = np.unique(labels)\n",
    "regions = measure.regionprops(labels)\n",
    "good_labels = []\n",
    "for prop in regions:\n",
    "    B = prop.bbox\n",
    "    if B[2]-B[0]<475 and B[3]-B[1]<475 and B[0]>40 and B[2]<472:\n",
    "        good_labels.append(prop.label)\n",
    "mask = np.ndarray([512,512],dtype=np.int8)\n",
    "mask[:] = 0\n",
    "#\n",
    "#  The mask here is the mask for the lungs--not the nodes\n",
    "#  After just the lungs are left, we do another large dilation\n",
    "#  in order to fill in and out the lung mask \n",
    "#\n",
    "for N in good_labels:\n",
    "    mask = mask + np.where(labels==N,1,0)\n",
    "mask = morphology.dilation(mask,np.ones([10,10])) # one last dilation\n",
    "plt.imshow(mask,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the ROI Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masks = np.load(working_path+\"lungmask_0.py\")\n",
    "imgs = np.load(working_path+\"images_0.py\")\n",
    "imgs = masks*imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# renormalizing the masked image (in the mask region)\n",
    "#\n",
    "new_mean = np.mean(img[mask>0])  \n",
    "new_std = np.std(img[mask>0])\n",
    "#\n",
    "#  Pushing the background color up to the lower end\n",
    "#  of the pixel range for the lungs\n",
    "#\n",
    "old_min = np.min(img)       # background color\n",
    "img[img==old_min] = new_mean-1.2*new_std   # resetting backgound color\n",
    "img = img-new_mean\n",
    "img = img/new_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#  Writing out images and masks as 1 channel arrays for input into network\n",
    "#\n",
    "final_images = np.ndarray([num_images,1,512,512],dtype=np.float32)\n",
    "final_masks = np.ndarray([num_images,1,512,512],dtype=np.float32)\n",
    "for i in range(num_images):\n",
    "    final_images[i,0] = out_images[i]\n",
    "    final_masks[i,0] = out_nodemasks[i]\n",
    "\n",
    "rand_i = np.random.choice(range(num_images),size=num_images,replace=False)\n",
    "test_i = int(0.2*num_images)\n",
    "np.save(working_path+\"trainImages.npy\",final_images[rand_i[test_i:]])\n",
    "np.save(working_path+\"trainMasks.npy\",final_masks[rand_i[test_i:]])\n",
    "np.save(working_path+\"testImages.npy\",final_images[rand_i[:test_i]])\n",
    "np.save(working_path+\"testMasks.npy\",final_masks[rand_i[:test_i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = np.load(working path+'images_0.npy')\n",
    "lungmask = np.load(working_path+'lungmask_0.npy')\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    print \"image %d\" % i\n",
    "    fig,ax = plt.subplots(2,2,figsize=[8,8])\n",
    "    ax[0,0].imshow(imgs[i],cmap='gray')\n",
    "    ax[0,1].imshow(lungmask[i],cmap='gray')\n",
    "    ax[1,0].imshow(imgs[i]*lungmask[i],cmap='gray')\n",
    "    plt.show()\n",
    "    raw_input(\"hit enter to cont : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dice Ceofficient Cost function for Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "# Tensorflow version for the model\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_unet() \n",
    "model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Load previously saved weights)\n",
    "# model.load_weights('unet.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(imgs_train, imgs_mask_train, batch_size=2, nb_epoch=20, \n",
    "           verbose=1, shuffle=True,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test = len(imgs_test)\n",
    "imgs_mask_test = np.ndarray([num_test,1,512,512],dtype=np.float32)\n",
    "for i in range(num_test):\n",
    "    imgs_mask_test[i] = model.predict([imgs_test[i:i+1]], verbose=0)[0]\n",
    "np.save('masksTestPredicted.npy', imgs_mask_test)\n",
    "mean = 0.0\n",
    "for i in range(num_test):\n",
    "    mean+=dice_coef_np(imgs_mask_test_true[i,0], imgs_mask_test[i,0])\n",
    "mean/=num_test\n",
    "print(\"Mean Dice Coeff : \",mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Classifier for Identifying Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dicom\n",
    "dc = dicom.read_file(filename)\n",
    "img = dc.pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRegionMetricRow(fname = \"nodules.npy\"):\n",
    "    seg = np.load(fname)\n",
    "    nslices = seg.shape[0]\n",
    "\n",
    "    #metrics\n",
    "    totalArea = 0.\n",
    "    avgArea = 0.\n",
    "    maxArea = 0.\n",
    "    avgEcc = 0.\n",
    "    avgEquivlentDiameter = 0.\n",
    "    stdEquivlentDiameter = 0.\n",
    "    weightedX = 0.\n",
    "    weightedY = 0.\n",
    "    numNodes = 0.\n",
    "    numNodesperSlice = 0.\n",
    "    # do not allow any nodes to be larger than 10% of the pixels to eliminate background regions\n",
    "    maxAllowedArea = 0.10 * 512 * 512 \n",
    "\n",
    "    areas = []\n",
    "    eqDiameters = []\n",
    "    for slicen in range(nslices):\n",
    "        regions = getRegionFromMap(seg[slicen,0,:,:])\n",
    "        for region in regions:\n",
    "            if region.area > maxAllowedArea:\n",
    "                continue\n",
    "            totalArea += region.area\n",
    "            areas.append(region.area)\n",
    "            avgEcc += region.eccentricity\n",
    "            avgEquivlentDiameter += region.equivalent_diameter\n",
    "            eqDiameters.append(region.equivalent_diameter)\n",
    "            weightedX += region.centroid[0]*region.area\n",
    "            weightedY += region.centroid[1]*region.area\n",
    "            numNodes += 1\n",
    "\n",
    "    weightedX = weightedX / totalArea \n",
    "    weightedY = weightedY / totalArea\n",
    "    avgArea = totalArea / numNodes\n",
    "    avgEcc = avgEcc / numNodes\n",
    "    avgEquivlentDiameter = avgEquivlentDiameter / numNodes\n",
    "    stdEquivlentDiameter = np.std(eqDiameters)\n",
    "\n",
    "    maxArea = max(areas)\n",
    "\n",
    "\n",
    "    numNodesperSlice = numNodes*1. / nslices\n",
    "\n",
    "\n",
    "    return np.array([avgArea,maxArea,avgEcc,avgEquivlentDiameter,\\\n",
    "                     stdEquivlentDiameter, weightedX, weightedY, numNodes, numNodesperSlice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRegionFromMap(slice_npy):\n",
    "    thr = np.where(slice_npy > np.mean(slice_npy),0.,1.0)\n",
    "    label_image = label(thr)\n",
    "    labels = label_image.astype(int)\n",
    "    regions = regionprops(labels)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def createFeatureDataset(nodfiles=None):\n",
    "    if nodfiles == None:\n",
    "        noddir = \"nodulesdir/\"\n",
    "        nodfiles = glob(noddir +\"*npy\")\n",
    "    # dict with mapping between truth and \n",
    "    truthdata = pickle.load(open(\"truthdict.pkl\",'r'))\n",
    "    numfeatures = 9\n",
    "    feature_array = np.zeros((len(nodfiles),numfeatures))\n",
    "    truth_metric = np.zeros((len(nodfiles)))\n",
    "\n",
    "    for i,nodfile in enumerate(nodfiles):\n",
    "        patID = nodfile.split(\"_\")[2]\n",
    "        truth_metric[i] = truthdata[int(patID)]\n",
    "        feature_array[i] = getRegionMetricRow(nodfile)\n",
    "\n",
    "    np.save(\"dataY.npy\", truth_metric)\n",
    "    np.save(\"dataX.npy\", feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import StratifiedKFold as KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import xgboost as xgb\n",
    "\n",
    "X = np.load(\"dataX.npy\")\n",
    "Y = np.load(\"dataY.npy\")\n",
    "\n",
    "#Random Forest\n",
    "kf = KFold(Y, n_folds=3)\n",
    "y_pred = Y * 0\n",
    "y_pred_prob = Y * 0\n",
    "for train, test in kf:\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], Y[train], Y[test]\n",
    "    clf = RF(n_estimators=100, n_jobs=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred[test] = clf.predict(X_test)\n",
    "    y_pred_prob[test] = clf.predict_proba(X_test)[:,1]\n",
    "print ('Random Forest')\n",
    "print classification_report(Y, y_pred, target_names=[\"No Cancer\", \"Cancer\"])\n",
    "print(\"logloss\",logloss(Y, y_pred_prob))\n",
    "\n",
    "#XGBoost\n",
    "print (\"XGBoost\")\n",
    "kf = KFold(Y, n_folds=3)\n",
    "y_pred = Y * 0\n",
    "y_pred_prob = Y * 0\n",
    "for train, test in kf:\n",
    "    X_train, X_test, y_train, y_test = X[train,:], X[test,:], Y[train], Y[test]\n",
    "    clf = xgb.XGBClassifier(objective=\"binary:logistic\", scale_pos_weight=3 )\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred[test] = clf.predict(X_test)\n",
    "    y_pred_prob[test] = clf.predict_proba(X_test)[:,1]\n",
    "print classification_report(Y, y_pred, target_names=[\"No Cancer\", \"Cancer\"])\n",
    "print(\"logloss\",logloss(Y, y_pred_prob))\n",
    "\n",
    "# All Cancer\n",
    "print \"Predicting all positive\"\n",
    "y_pred = np.ones(Y.shape)\n",
    "print classification_report(Y, y_pred, target_names=[\"No Cancer\", \"Cancer\"])\n",
    "print(\"logloss\",logloss(Y, y_pred))\n",
    "\n",
    "# No Cancer\n",
    "print \"Predicting all negative\"\n",
    "y_pred = Y*0\n",
    "print classification_report(Y, y_pred, target_names=[\"No Cancer\", \"Cancer\"])\n",
    "print(\"logloss\",logloss(Y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
